{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8296,"status":"ok","timestamp":1649980980504,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"Sknnn2xs-AHi","outputId":"80551ecd-5a8e-4fc5-fab5-74699c879c18"},"outputs":[{"name":"stdout","output_type":"stream","text":["System version: 3.8.9 (tags/v3.8.9:a743f81, Apr  6 2021, 14:02:34) [MSC v.1928 64 bit (AMD64)]\n","Tensorflow version: 2.8.0\n"]}],"source":["import sys\n","import os\n","import logging\n","import papermill as pm\n","import scrapbook as sb\n","from tempfile import TemporaryDirectory\n","import numpy as np\n","import tensorflow.compat.v1 as tf\n","tf.get_logger().setLevel('ERROR') # only show error messages\n","\n","from recommenders.utils.timer import Timer\n","from recommenders.utils.constants import SEED\n","from recommenders.models.deeprec.deeprec_utils import (\n","    prepare_hparams\n",")\n","\n","from resources.data_preprocessing import data_preprocessing\n","# from recommenders.datasets.amazon_reviews import download_and_extract, data_preprocessing\n","from recommenders.datasets.download_utils import maybe_download\n","\n","\n","from recommenders.models.deeprec.models.sequential.sli_rec import SLI_RECModel as SeqModel\n","####  to use the other model, use one of the following lines:\n","#from recommenders.models.deeprec.models.sequential.asvd import A2SVDModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.caser import CaserModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.gru4rec import GRU4RecModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.sum import SUMModel as SeqModel\n","\n","#from recommenders.models.deeprec.models.sequential.nextitnet import NextItNetModel\n","\n","from recommenders.models.deeprec.io.sequential_iterator import SequentialIterator\n","#from recommenders.models.deeprec.io.nextitnet_iterator import NextItNetIterator\n","\n","print(\"System version: {}\".format(sys.version))\n","print(\"Tensorflow version: {}\".format(tf.__version__))"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":424,"status":"ok","timestamp":1649980983686,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"sxtfUZfP-ZWR"},"outputs":[],"source":["##  ATTENTION: change to the corresponding config file, e.g., caser.yaml for CaserModel, sum.yaml for SUMModel\n","# yaml_file = '../../recommenders/models/deeprec/config/sli_rec.yaml'  \n","yaml_file = './sli_rec.yaml'  "]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":415,"status":"ok","timestamp":1649981001550,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"_NnzhN4h_rI5"},"outputs":[],"source":["EPOCHS = 10\n","BATCH_SIZE = 400\n","RANDOM_SEED = SEED  # Set None for non-deterministic result\n","\n","data_path = os.path.join(\"resources/\")"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":419,"status":"ok","timestamp":1649981009184,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"0RAMNcI3AClc"},"outputs":[],"source":["# for test\n","train_file = os.path.join(data_path, r'train_data')\n","valid_file = os.path.join(data_path, r'valid_data')\n","test_file = os.path.join(data_path, r'test_data')\n","user_vocab = os.path.join(data_path, r'user_vocab.pkl')\n","item_vocab = os.path.join(data_path, r'item_vocab.pkl')\n","cate_vocab = os.path.join(data_path, r'cate_vocab.pkl')\n","output_file = os.path.join(data_path, r'output_sli_rec.txt')\n","\n","# reviews_name = 'json'\n","# meta_name = 'json'\n","# reviews_file = os.path.join(data_path, reviews_name)\n","# meta_file = os.path.join(data_path, meta_name)\n","train_num_ngs = 4 # number of negative instances with a positive instance for training\n","valid_num_ngs = 4 # number of negative instances with a positive instance for validation\n","test_num_ngs = 9 # number of negative instances with a positive instance for testing\n","sample_rate = 0.01 # sample a small item set for training and testing here for fast example\n","\n","input_files = [data_path, train_file, valid_file, test_file, user_vocab, item_vocab, cate_vocab]\n","\n","if not os.path.exists(train_file):\n","    # download_and_extract(reviews_name, reviews_file)\n","    # download_and_extract(meta_name, meta_file)\n","    data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs)\n","    #### uncomment this for the NextItNet model, because it does not need to unfold the user history\n","    # data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs, is_history_expanding=False)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1013,"status":"ok","timestamp":1649981039553,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"rwTMO3WEWaCu"},"outputs":[],"source":["### NOTE:  \n","### remember to use `_create_vocab(train_file, user_vocab, item_vocab, cate_vocab)` to generate the user_vocab, item_vocab and cate_vocab files, if you are using your own dataset rather than using our demo Amazon dataset.\n","hparams = prepare_hparams(yaml_file, \n","                          embed_l2=0., \n","                          layer_l2=0., \n","                          learning_rate=0.001,  # set to 0.01 if batch normalization is disable\n","                          epochs=EPOCHS,\n","                          batch_size=BATCH_SIZE,\n","                          show_step=20,\n","                          MODEL_DIR=os.path.join(data_path, \"model\", \"sli_rec/\"),\n","                          SUMMARIES_DIR=os.path.join(data_path, \"summary\", \"sli_rec/\"),\n","                          user_vocab=user_vocab,\n","                          item_vocab=item_vocab,\n","                          cate_vocab=cate_vocab,\n","                          need_sample=True,\n","                          train_num_ngs=train_num_ngs, # provides the number of negative instances for each positive instance for loss computation.\n","            )"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":420,"status":"ok","timestamp":1649981043565,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"4Rvq7gFluVPq"},"outputs":[],"source":["input_creator = SequentialIterator\n","#### uncomment this for the NextItNet model, because it needs a special data iterator for training\n","#input_creator = NextItNetIterator"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11139,"status":"ok","timestamp":1649981057379,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"VFNfgcKNuaVv","outputId":"2f195cde-2963-41ff-aa84-0a17d9a9cd3d"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\base_model.py:701: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n","  curr_hidden_nn_layer = tf.compat.v1.layers.batch_normalization(\n","C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs, training=training)\n"]}],"source":["model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n","\n","## sometimes we don't want to train a model from scratch\n","## then we can load a pre-trained model like this: \n","#model.load_model(r'your_model_path')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63766,"status":"ok","timestamp":1649981126167,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"8AQxPlk-uheU","outputId":"23ee2335-3935-437b-c4f2-0c01fee93d8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'auc': 0.5161, 'logloss': 0.6931, 'mean_mrr': 0.2977, 'ndcg@2': 0.1728, 'ndcg@4': 0.2585, 'ndcg@6': 0.3297, 'group_auc': 0.5165}\n"]}],"source":["# test_num_ngs is the number of negative lines after each positive line in your test_file\n","print(model.run_eval(test_file, num_ngs=test_num_ngs)) "]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19408573,"status":"ok","timestamp":1650000544829,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"QFKQu9rGu0jq","outputId":"68371df4-d8f1-4844-8f13-d634505f1b33"},"outputs":[{"name":"stdout","output_type":"stream","text":["step 20 , total_loss: 1.4931, data_loss: 1.4931\n","step 40 , total_loss: 1.4084, data_loss: 1.4084\n","step 60 , total_loss: 1.3375, data_loss: 1.3375\n","step 80 , total_loss: 1.3148, data_loss: 1.3148\n","step 100 , total_loss: 1.3378, data_loss: 1.3378\n","step 120 , total_loss: 1.2143, data_loss: 1.2143\n","step 140 , total_loss: 1.2697, data_loss: 1.2697\n","step 160 , total_loss: 1.3446, data_loss: 1.3446\n","step 180 , total_loss: 1.2210, data_loss: 1.2210\n","step 200 , total_loss: 1.2459, data_loss: 1.2459\n","step 220 , total_loss: 1.2491, data_loss: 1.2491\n","step 240 , total_loss: 1.2684, data_loss: 1.2684\n","step 260 , total_loss: 1.2599, data_loss: 1.2599\n","step 280 , total_loss: 1.2101, data_loss: 1.2101\n","step 300 , total_loss: 1.2197, data_loss: 1.2197\n","step 320 , total_loss: 1.2073, data_loss: 1.2073\n","step 340 , total_loss: 1.1671, data_loss: 1.1671\n","step 360 , total_loss: 1.2359, data_loss: 1.2359\n","step 380 , total_loss: 1.2049, data_loss: 1.2049\n","step 400 , total_loss: 1.2051, data_loss: 1.2051\n","step 420 , total_loss: 1.1396, data_loss: 1.1396\n","step 440 , total_loss: 1.1779, data_loss: 1.1779\n","step 460 , total_loss: 1.2398, data_loss: 1.2398\n","step 480 , total_loss: 1.1450, data_loss: 1.1450\n","step 500 , total_loss: 1.1172, data_loss: 1.1172\n","step 520 , total_loss: 1.1141, data_loss: 1.1141\n","step 540 , total_loss: 1.1754, data_loss: 1.1754\n","step 560 , total_loss: 1.1587, data_loss: 1.1587\n","step 580 , total_loss: 1.1430, data_loss: 1.1430\n","step 600 , total_loss: 1.1571, data_loss: 1.1571\n","step 620 , total_loss: 1.1316, data_loss: 1.1316\n","step 640 , total_loss: 1.1330, data_loss: 1.1330\n","step 660 , total_loss: 1.1148, data_loss: 1.1148\n","step 680 , total_loss: 1.1536, data_loss: 1.1536\n","step 700 , total_loss: 1.0588, data_loss: 1.0588\n","step 720 , total_loss: 1.1172, data_loss: 1.1172\n","step 740 , total_loss: 1.1047, data_loss: 1.1047\n","step 760 , total_loss: 1.0506, data_loss: 1.0506\n","eval valid at epoch 1: auc:0.7675,logloss:0.5047,mean_mrr:0.6859,ndcg@2:0.6459,ndcg@4:0.7573,ndcg@6:0.7653,group_auc:0.7776\n","step 20 , total_loss: 1.0634, data_loss: 1.0634\n","step 40 , total_loss: 1.0637, data_loss: 1.0637\n","step 60 , total_loss: 1.1391, data_loss: 1.1391\n","step 80 , total_loss: 1.1147, data_loss: 1.1147\n","step 100 , total_loss: 1.0587, data_loss: 1.0587\n","step 120 , total_loss: 1.0552, data_loss: 1.0552\n","step 140 , total_loss: 1.0491, data_loss: 1.0491\n","step 160 , total_loss: 1.0964, data_loss: 1.0964\n","step 180 , total_loss: 1.0055, data_loss: 1.0055\n","step 200 , total_loss: 1.0417, data_loss: 1.0417\n","step 220 , total_loss: 1.0808, data_loss: 1.0808\n","step 240 , total_loss: 0.9810, data_loss: 0.9810\n","step 260 , total_loss: 1.0081, data_loss: 1.0081\n","step 280 , total_loss: 1.0364, data_loss: 1.0364\n","step 300 , total_loss: 1.0174, data_loss: 1.0174\n","step 320 , total_loss: 0.9352, data_loss: 0.9352\n","step 340 , total_loss: 1.0335, data_loss: 1.0335\n","step 360 , total_loss: 0.9725, data_loss: 0.9725\n","step 380 , total_loss: 1.1109, data_loss: 1.1109\n","step 400 , total_loss: 0.9533, data_loss: 0.9533\n","step 420 , total_loss: 1.0523, data_loss: 1.0523\n","step 440 , total_loss: 0.9328, data_loss: 0.9328\n","step 460 , total_loss: 0.9224, data_loss: 0.9224\n","step 480 , total_loss: 0.9809, data_loss: 0.9809\n","step 500 , total_loss: 0.9889, data_loss: 0.9889\n","step 520 , total_loss: 0.9716, data_loss: 0.9716\n","step 540 , total_loss: 0.9107, data_loss: 0.9107\n","step 560 , total_loss: 0.8750, data_loss: 0.8750\n","step 580 , total_loss: 0.9057, data_loss: 0.9057\n","step 600 , total_loss: 0.9686, data_loss: 0.9686\n","step 620 , total_loss: 0.9801, data_loss: 0.9801\n","step 640 , total_loss: 0.9016, data_loss: 0.9016\n","step 660 , total_loss: 0.8677, data_loss: 0.8677\n","step 680 , total_loss: 0.8713, data_loss: 0.8713\n","step 700 , total_loss: 0.8889, data_loss: 0.8889\n","step 720 , total_loss: 0.9333, data_loss: 0.9333\n","step 740 , total_loss: 0.9134, data_loss: 0.9134\n","step 760 , total_loss: 0.9023, data_loss: 0.9023\n","eval valid at epoch 2: auc:0.8364,logloss:0.4611,mean_mrr:0.7617,ndcg@2:0.7498,ndcg@4:0.8202,ndcg@6:0.8225,group_auc:0.8455\n","step 20 , total_loss: 0.8566, data_loss: 0.8566\n","step 40 , total_loss: 0.8692, data_loss: 0.8692\n","step 60 , total_loss: 0.8856, data_loss: 0.8856\n","step 80 , total_loss: 0.9075, data_loss: 0.9075\n","step 100 , total_loss: 0.8484, data_loss: 0.8484\n","step 120 , total_loss: 0.8609, data_loss: 0.8609\n","step 140 , total_loss: 0.8926, data_loss: 0.8926\n","step 160 , total_loss: 0.8789, data_loss: 0.8789\n","step 180 , total_loss: 0.8961, data_loss: 0.8961\n","step 200 , total_loss: 0.9136, data_loss: 0.9136\n","step 220 , total_loss: 0.8684, data_loss: 0.8684\n","step 240 , total_loss: 0.8508, data_loss: 0.8508\n","step 260 , total_loss: 0.8242, data_loss: 0.8242\n","step 280 , total_loss: 0.9076, data_loss: 0.9076\n","step 300 , total_loss: 0.7966, data_loss: 0.7966\n","step 320 , total_loss: 0.8497, data_loss: 0.8497\n","step 340 , total_loss: 0.9194, data_loss: 0.9194\n","step 360 , total_loss: 0.7583, data_loss: 0.7583\n","step 380 , total_loss: 0.8794, data_loss: 0.8794\n","step 400 , total_loss: 0.8406, data_loss: 0.8406\n","step 420 , total_loss: 0.8687, data_loss: 0.8687\n","step 440 , total_loss: 0.9248, data_loss: 0.9248\n","step 460 , total_loss: 0.8135, data_loss: 0.8135\n","step 480 , total_loss: 0.8788, data_loss: 0.8788\n","step 500 , total_loss: 0.8721, data_loss: 0.8721\n","step 520 , total_loss: 0.8643, data_loss: 0.8643\n","step 540 , total_loss: 0.8511, data_loss: 0.8511\n","step 560 , total_loss: 0.8534, data_loss: 0.8534\n","step 580 , total_loss: 0.8885, data_loss: 0.8885\n","step 600 , total_loss: 0.8950, data_loss: 0.8950\n","step 620 , total_loss: 0.8343, data_loss: 0.8343\n","step 640 , total_loss: 0.8464, data_loss: 0.8464\n","step 660 , total_loss: 0.8286, data_loss: 0.8286\n","step 680 , total_loss: 0.9042, data_loss: 0.9042\n","step 700 , total_loss: 0.9041, data_loss: 0.9041\n","step 720 , total_loss: 0.8126, data_loss: 0.8126\n","step 740 , total_loss: 0.8431, data_loss: 0.8431\n","step 760 , total_loss: 0.8684, data_loss: 0.8684\n","eval valid at epoch 3: auc:0.8516,logloss:0.4317,mean_mrr:0.7758,ndcg@2:0.7674,ndcg@4:0.8312,ndcg@6:0.8332,group_auc:0.8569\n","step 20 , total_loss: 0.7862, data_loss: 0.7862\n","step 40 , total_loss: 0.8203, data_loss: 0.8203\n","step 60 , total_loss: 0.8536, data_loss: 0.8536\n","step 80 , total_loss: 0.8484, data_loss: 0.8484\n","step 100 , total_loss: 0.8438, data_loss: 0.8438\n","step 120 , total_loss: 0.8520, data_loss: 0.8520\n","step 140 , total_loss: 0.9551, data_loss: 0.9551\n","step 160 , total_loss: 0.9583, data_loss: 0.9583\n","step 180 , total_loss: 0.8012, data_loss: 0.8012\n","step 200 , total_loss: 0.8022, data_loss: 0.8022\n","step 220 , total_loss: 0.8697, data_loss: 0.8697\n","step 240 , total_loss: 0.7799, data_loss: 0.7799\n","step 260 , total_loss: 0.8496, data_loss: 0.8496\n","step 280 , total_loss: 0.8354, data_loss: 0.8354\n","step 300 , total_loss: 0.8380, data_loss: 0.8380\n","step 320 , total_loss: 0.8947, data_loss: 0.8947\n","step 340 , total_loss: 0.8916, data_loss: 0.8916\n","step 360 , total_loss: 0.9139, data_loss: 0.9139\n","step 380 , total_loss: 0.8214, data_loss: 0.8214\n","step 400 , total_loss: 0.8835, data_loss: 0.8835\n","step 420 , total_loss: 0.8608, data_loss: 0.8608\n","step 440 , total_loss: 0.8464, data_loss: 0.8464\n","step 460 , total_loss: 0.8903, data_loss: 0.8903\n","step 480 , total_loss: 0.7463, data_loss: 0.7463\n","step 500 , total_loss: 0.8166, data_loss: 0.8166\n","step 520 , total_loss: 0.8561, data_loss: 0.8561\n","step 540 , total_loss: 0.8955, data_loss: 0.8955\n","step 560 , total_loss: 0.8210, data_loss: 0.8210\n","step 580 , total_loss: 0.7349, data_loss: 0.7349\n","step 600 , total_loss: 0.8030, data_loss: 0.8030\n","step 620 , total_loss: 0.8402, data_loss: 0.8402\n","step 640 , total_loss: 0.7599, data_loss: 0.7599\n","step 660 , total_loss: 0.7705, data_loss: 0.7705\n","step 680 , total_loss: 0.7725, data_loss: 0.7725\n","step 700 , total_loss: 0.8367, data_loss: 0.8367\n","step 720 , total_loss: 0.7550, data_loss: 0.7550\n","step 740 , total_loss: 0.8338, data_loss: 0.8338\n","step 760 , total_loss: 0.8459, data_loss: 0.8459\n","eval valid at epoch 4: auc:0.8641,logloss:0.4217,mean_mrr:0.8019,ndcg@2:0.8016,ndcg@4:0.8513,ndcg@6:0.8527,group_auc:0.877\n","step 20 , total_loss: 0.7569, data_loss: 0.7569\n","step 40 , total_loss: 0.8416, data_loss: 0.8416\n","step 60 , total_loss: 0.8061, data_loss: 0.8061\n","step 80 , total_loss: 0.8523, data_loss: 0.8523\n","step 100 , total_loss: 0.7542, data_loss: 0.7542\n","step 120 , total_loss: 0.7300, data_loss: 0.7300\n","step 140 , total_loss: 0.8239, data_loss: 0.8239\n","step 160 , total_loss: 0.8026, data_loss: 0.8026\n","step 180 , total_loss: 0.7893, data_loss: 0.7893\n","step 200 , total_loss: 0.7736, data_loss: 0.7736\n","step 220 , total_loss: 0.8341, data_loss: 0.8341\n","step 240 , total_loss: 0.7670, data_loss: 0.7670\n","step 260 , total_loss: 0.8545, data_loss: 0.8545\n","step 280 , total_loss: 0.8166, data_loss: 0.8166\n","step 300 , total_loss: 0.8146, data_loss: 0.8146\n","step 320 , total_loss: 0.7960, data_loss: 0.7960\n","step 340 , total_loss: 0.8840, data_loss: 0.8840\n","step 360 , total_loss: 0.7824, data_loss: 0.7824\n","step 380 , total_loss: 0.7642, data_loss: 0.7642\n","step 400 , total_loss: 0.7461, data_loss: 0.7461\n","step 420 , total_loss: 0.7618, data_loss: 0.7618\n","step 440 , total_loss: 0.8296, data_loss: 0.8296\n","step 460 , total_loss: 0.8121, data_loss: 0.8121\n","step 480 , total_loss: 0.7978, data_loss: 0.7978\n","step 500 , total_loss: 0.7968, data_loss: 0.7968\n","step 520 , total_loss: 0.8176, data_loss: 0.8176\n","step 540 , total_loss: 0.8381, data_loss: 0.8381\n","step 560 , total_loss: 0.7484, data_loss: 0.7484\n","step 580 , total_loss: 0.8478, data_loss: 0.8478\n","step 600 , total_loss: 0.8381, data_loss: 0.8381\n","step 620 , total_loss: 0.7446, data_loss: 0.7446\n","step 640 , total_loss: 0.7739, data_loss: 0.7739\n","step 660 , total_loss: 0.8287, data_loss: 0.8287\n","step 680 , total_loss: 0.7975, data_loss: 0.7975\n","step 700 , total_loss: 0.8025, data_loss: 0.8025\n","step 720 , total_loss: 0.7545, data_loss: 0.7545\n","step 740 , total_loss: 0.7918, data_loss: 0.7918\n","step 760 , total_loss: 0.8365, data_loss: 0.8365\n","eval valid at epoch 5: auc:0.8794,logloss:0.4032,mean_mrr:0.814,ndcg@2:0.8148,ndcg@4:0.8605,ndcg@6:0.8617,group_auc:0.885\n","step 20 , total_loss: 0.8345, data_loss: 0.8345\n","step 40 , total_loss: 0.7592, data_loss: 0.7592\n","step 60 , total_loss: 0.8262, data_loss: 0.8262\n","step 80 , total_loss: 0.8084, data_loss: 0.8084\n","step 100 , total_loss: 0.7732, data_loss: 0.7732\n","step 120 , total_loss: 0.8330, data_loss: 0.8330\n","step 140 , total_loss: 0.8203, data_loss: 0.8203\n","step 160 , total_loss: 0.7645, data_loss: 0.7645\n","step 180 , total_loss: 0.6922, data_loss: 0.6922\n","step 200 , total_loss: 0.7593, data_loss: 0.7593\n","step 220 , total_loss: 0.7361, data_loss: 0.7361\n","step 240 , total_loss: 0.8384, data_loss: 0.8384\n","step 260 , total_loss: 0.7635, data_loss: 0.7635\n","step 280 , total_loss: 0.8025, data_loss: 0.8025\n","step 300 , total_loss: 0.7589, data_loss: 0.7589\n","step 320 , total_loss: 0.7836, data_loss: 0.7836\n","step 340 , total_loss: 0.7838, data_loss: 0.7838\n","step 360 , total_loss: 0.7970, data_loss: 0.7970\n","step 380 , total_loss: 0.7324, data_loss: 0.7324\n","step 400 , total_loss: 0.7909, data_loss: 0.7909\n","step 420 , total_loss: 0.7504, data_loss: 0.7504\n","step 440 , total_loss: 0.7852, data_loss: 0.7852\n","step 460 , total_loss: 0.7514, data_loss: 0.7514\n","step 480 , total_loss: 0.7815, data_loss: 0.7815\n","step 500 , total_loss: 0.8213, data_loss: 0.8213\n","step 520 , total_loss: 0.7387, data_loss: 0.7387\n","step 540 , total_loss: 0.7966, data_loss: 0.7966\n","step 560 , total_loss: 0.7395, data_loss: 0.7395\n","step 580 , total_loss: 0.6692, data_loss: 0.6692\n","step 600 , total_loss: 0.7218, data_loss: 0.7218\n","step 620 , total_loss: 0.7566, data_loss: 0.7566\n","step 640 , total_loss: 0.7859, data_loss: 0.7859\n","step 660 , total_loss: 0.7711, data_loss: 0.7711\n","step 680 , total_loss: 0.8120, data_loss: 0.8120\n","step 700 , total_loss: 0.7415, data_loss: 0.7415\n","step 720 , total_loss: 0.7328, data_loss: 0.7328\n","step 740 , total_loss: 0.8083, data_loss: 0.8083\n","step 760 , total_loss: 0.7642, data_loss: 0.7642\n","eval valid at epoch 6: auc:0.88,logloss:0.386,mean_mrr:0.8188,ndcg@2:0.8185,ndcg@4:0.8641,ndcg@6:0.8653,group_auc:0.8879\n","step 20 , total_loss: 0.7677, data_loss: 0.7677\n","step 40 , total_loss: 0.7819, data_loss: 0.7819\n","step 60 , total_loss: 0.8092, data_loss: 0.8092\n","step 80 , total_loss: 0.7438, data_loss: 0.7438\n","step 100 , total_loss: 0.7440, data_loss: 0.7440\n","step 120 , total_loss: 0.7628, data_loss: 0.7628\n","step 140 , total_loss: 0.8060, data_loss: 0.8060\n","step 160 , total_loss: 0.7195, data_loss: 0.7195\n","step 180 , total_loss: 0.7305, data_loss: 0.7305\n","step 200 , total_loss: 0.7539, data_loss: 0.7539\n","step 220 , total_loss: 0.8118, data_loss: 0.8118\n","step 240 , total_loss: 0.8353, data_loss: 0.8353\n","step 260 , total_loss: 0.7363, data_loss: 0.7363\n","step 280 , total_loss: 0.7406, data_loss: 0.7406\n","step 300 , total_loss: 0.8032, data_loss: 0.8032\n","step 320 , total_loss: 0.7589, data_loss: 0.7589\n","step 340 , total_loss: 0.7826, data_loss: 0.7826\n","step 360 , total_loss: 0.6532, data_loss: 0.6532\n","step 380 , total_loss: 0.7357, data_loss: 0.7357\n","step 400 , total_loss: 0.8368, data_loss: 0.8368\n","step 420 , total_loss: 0.7887, data_loss: 0.7887\n","step 440 , total_loss: 0.7321, data_loss: 0.7321\n","step 460 , total_loss: 0.8219, data_loss: 0.8219\n","step 480 , total_loss: 0.8437, data_loss: 0.8437\n","step 500 , total_loss: 0.7695, data_loss: 0.7695\n","step 520 , total_loss: 0.8225, data_loss: 0.8225\n","step 540 , total_loss: 0.7738, data_loss: 0.7738\n","step 560 , total_loss: 0.8745, data_loss: 0.8745\n","step 580 , total_loss: 0.8136, data_loss: 0.8136\n","step 600 , total_loss: 0.7340, data_loss: 0.7340\n","step 620 , total_loss: 0.7090, data_loss: 0.7090\n","step 640 , total_loss: 0.7218, data_loss: 0.7218\n","step 660 , total_loss: 0.7854, data_loss: 0.7854\n","step 680 , total_loss: 0.7639, data_loss: 0.7639\n","step 700 , total_loss: 0.8477, data_loss: 0.8477\n","step 720 , total_loss: 0.8138, data_loss: 0.8138\n","step 740 , total_loss: 0.8316, data_loss: 0.8316\n","step 760 , total_loss: 0.7765, data_loss: 0.7765\n","eval valid at epoch 7: auc:0.8843,logloss:0.3969,mean_mrr:0.8213,ndcg@2:0.822,ndcg@4:0.866,ndcg@6:0.8671,group_auc:0.8898\n","step 20 , total_loss: 0.8548, data_loss: 0.8548\n","step 40 , total_loss: 0.7437, data_loss: 0.7437\n","step 60 , total_loss: 0.7226, data_loss: 0.7226\n","step 80 , total_loss: 0.7955, data_loss: 0.7955\n","step 100 , total_loss: 0.7155, data_loss: 0.7155\n","step 120 , total_loss: 0.7270, data_loss: 0.7270\n","step 140 , total_loss: 0.7432, data_loss: 0.7432\n","step 160 , total_loss: 0.7386, data_loss: 0.7386\n","step 180 , total_loss: 0.8343, data_loss: 0.8343\n","step 200 , total_loss: 0.8154, data_loss: 0.8154\n","step 220 , total_loss: 0.7496, data_loss: 0.7496\n","step 240 , total_loss: 0.7782, data_loss: 0.7782\n","step 260 , total_loss: 0.7009, data_loss: 0.7009\n","step 280 , total_loss: 0.8080, data_loss: 0.8080\n","step 300 , total_loss: 0.7110, data_loss: 0.7110\n","step 320 , total_loss: 0.7352, data_loss: 0.7352\n","step 340 , total_loss: 0.8110, data_loss: 0.8110\n","step 360 , total_loss: 0.7280, data_loss: 0.7280\n","step 380 , total_loss: 0.7867, data_loss: 0.7867\n","step 400 , total_loss: 0.6637, data_loss: 0.6637\n","step 420 , total_loss: 0.8097, data_loss: 0.8097\n","step 440 , total_loss: 0.7744, data_loss: 0.7744\n","step 460 , total_loss: 0.7128, data_loss: 0.7128\n","step 480 , total_loss: 0.7611, data_loss: 0.7611\n","step 500 , total_loss: 0.6943, data_loss: 0.6943\n","step 520 , total_loss: 0.7603, data_loss: 0.7603\n","step 540 , total_loss: 0.7923, data_loss: 0.7923\n","step 560 , total_loss: 0.7600, data_loss: 0.7600\n","step 580 , total_loss: 0.7405, data_loss: 0.7405\n","step 600 , total_loss: 0.8338, data_loss: 0.8338\n","step 620 , total_loss: 0.7316, data_loss: 0.7316\n","step 640 , total_loss: 0.7560, data_loss: 0.7560\n","step 660 , total_loss: 0.8123, data_loss: 0.8123\n","step 680 , total_loss: 0.7383, data_loss: 0.7383\n","step 700 , total_loss: 0.7586, data_loss: 0.7586\n","step 720 , total_loss: 0.7898, data_loss: 0.7898\n","step 740 , total_loss: 0.7378, data_loss: 0.7378\n","step 760 , total_loss: 0.7336, data_loss: 0.7336\n","eval valid at epoch 8: auc:0.8853,logloss:0.3976,mean_mrr:0.8252,ndcg@2:0.8261,ndcg@4:0.869,ndcg@6:0.87,group_auc:0.8924\n","step 20 , total_loss: 0.7120, data_loss: 0.7120\n","step 40 , total_loss: 0.7664, data_loss: 0.7664\n","step 60 , total_loss: 0.7270, data_loss: 0.7270\n","step 80 , total_loss: 0.7443, data_loss: 0.7443\n","step 100 , total_loss: 0.7465, data_loss: 0.7465\n","step 120 , total_loss: 0.6896, data_loss: 0.6896\n","step 140 , total_loss: 0.7618, data_loss: 0.7618\n","step 160 , total_loss: 0.7945, data_loss: 0.7945\n","step 180 , total_loss: 0.7381, data_loss: 0.7381\n","step 200 , total_loss: 0.7558, data_loss: 0.7558\n","step 220 , total_loss: 0.7408, data_loss: 0.7408\n","step 240 , total_loss: 0.7466, data_loss: 0.7466\n","step 260 , total_loss: 0.7562, data_loss: 0.7562\n","step 280 , total_loss: 0.7523, data_loss: 0.7523\n","step 300 , total_loss: 0.7063, data_loss: 0.7063\n","step 320 , total_loss: 0.7008, data_loss: 0.7008\n","step 340 , total_loss: 0.7925, data_loss: 0.7925\n","step 360 , total_loss: 0.8118, data_loss: 0.8118\n","step 380 , total_loss: 0.7265, data_loss: 0.7265\n","step 400 , total_loss: 0.7707, data_loss: 0.7707\n","step 420 , total_loss: 0.8512, data_loss: 0.8512\n","step 440 , total_loss: 0.7271, data_loss: 0.7271\n","step 460 , total_loss: 0.7572, data_loss: 0.7572\n","step 480 , total_loss: 0.7884, data_loss: 0.7884\n","step 500 , total_loss: 0.7699, data_loss: 0.7699\n","step 520 , total_loss: 0.7597, data_loss: 0.7597\n","step 540 , total_loss: 0.7231, data_loss: 0.7231\n","step 560 , total_loss: 0.7282, data_loss: 0.7282\n","step 580 , total_loss: 0.7554, data_loss: 0.7554\n","step 600 , total_loss: 0.7604, data_loss: 0.7604\n","step 620 , total_loss: 0.7418, data_loss: 0.7418\n","step 640 , total_loss: 0.8082, data_loss: 0.8082\n","step 660 , total_loss: 0.8336, data_loss: 0.8336\n","step 680 , total_loss: 0.7763, data_loss: 0.7763\n","step 700 , total_loss: 0.7539, data_loss: 0.7539\n","step 720 , total_loss: 0.7079, data_loss: 0.7079\n","step 740 , total_loss: 0.7378, data_loss: 0.7378\n","step 760 , total_loss: 0.7638, data_loss: 0.7638\n","eval valid at epoch 9: auc:0.8877,logloss:0.4392,mean_mrr:0.827,ndcg@2:0.827,ndcg@4:0.8703,ndcg@6:0.8714,group_auc:0.8932\n","step 20 , total_loss: 0.7824, data_loss: 0.7824\n","step 40 , total_loss: 0.6897, data_loss: 0.6897\n","step 60 , total_loss: 0.7483, data_loss: 0.7483\n","step 80 , total_loss: 0.7100, data_loss: 0.7100\n","step 100 , total_loss: 0.7435, data_loss: 0.7435\n","step 120 , total_loss: 0.8057, data_loss: 0.8057\n","step 140 , total_loss: 0.7703, data_loss: 0.7703\n","step 160 , total_loss: 0.7924, data_loss: 0.7924\n","step 180 , total_loss: 0.7032, data_loss: 0.7032\n","step 200 , total_loss: 0.7469, data_loss: 0.7469\n","step 220 , total_loss: 0.7711, data_loss: 0.7711\n","step 240 , total_loss: 0.7240, data_loss: 0.7240\n","step 260 , total_loss: 0.7371, data_loss: 0.7371\n","step 280 , total_loss: 0.7635, data_loss: 0.7635\n","step 300 , total_loss: 0.7022, data_loss: 0.7022\n","step 320 , total_loss: 0.8017, data_loss: 0.8017\n","step 340 , total_loss: 0.8176, data_loss: 0.8176\n","step 360 , total_loss: 0.8163, data_loss: 0.8163\n","step 380 , total_loss: 0.6886, data_loss: 0.6886\n","step 400 , total_loss: 0.7401, data_loss: 0.7401\n","step 420 , total_loss: 0.7601, data_loss: 0.7601\n","step 440 , total_loss: 0.7429, data_loss: 0.7429\n","step 460 , total_loss: 0.7768, data_loss: 0.7768\n","step 480 , total_loss: 0.7614, data_loss: 0.7614\n","step 500 , total_loss: 0.8116, data_loss: 0.8116\n","step 520 , total_loss: 0.7357, data_loss: 0.7357\n","step 540 , total_loss: 0.7224, data_loss: 0.7224\n","step 560 , total_loss: 0.8388, data_loss: 0.8388\n","step 580 , total_loss: 0.7000, data_loss: 0.7000\n","step 600 , total_loss: 0.7367, data_loss: 0.7367\n","step 620 , total_loss: 0.7512, data_loss: 0.7512\n","step 640 , total_loss: 0.7030, data_loss: 0.7030\n","step 660 , total_loss: 0.7500, data_loss: 0.7500\n","step 680 , total_loss: 0.7117, data_loss: 0.7117\n","step 700 , total_loss: 0.7517, data_loss: 0.7517\n","step 720 , total_loss: 0.6847, data_loss: 0.6847\n","step 740 , total_loss: 0.6682, data_loss: 0.6682\n","step 760 , total_loss: 0.8623, data_loss: 0.8623\n","eval valid at epoch 10: auc:0.8887,logloss:0.4454,mean_mrr:0.8275,ndcg@2:0.8283,ndcg@4:0.8707,ndcg@6:0.8718,group_auc:0.8938\n","[(1, {'auc': 0.7675, 'logloss': 0.5047, 'mean_mrr': 0.6859, 'ndcg@2': 0.6459, 'ndcg@4': 0.7573, 'ndcg@6': 0.7653, 'group_auc': 0.7776}), (2, {'auc': 0.8364, 'logloss': 0.4611, 'mean_mrr': 0.7617, 'ndcg@2': 0.7498, 'ndcg@4': 0.8202, 'ndcg@6': 0.8225, 'group_auc': 0.8455}), (3, {'auc': 0.8516, 'logloss': 0.4317, 'mean_mrr': 0.7758, 'ndcg@2': 0.7674, 'ndcg@4': 0.8312, 'ndcg@6': 0.8332, 'group_auc': 0.8569}), (4, {'auc': 0.8641, 'logloss': 0.4217, 'mean_mrr': 0.8019, 'ndcg@2': 0.8016, 'ndcg@4': 0.8513, 'ndcg@6': 0.8527, 'group_auc': 0.877}), (5, {'auc': 0.8794, 'logloss': 0.4032, 'mean_mrr': 0.814, 'ndcg@2': 0.8148, 'ndcg@4': 0.8605, 'ndcg@6': 0.8617, 'group_auc': 0.885}), (6, {'auc': 0.88, 'logloss': 0.386, 'mean_mrr': 0.8188, 'ndcg@2': 0.8185, 'ndcg@4': 0.8641, 'ndcg@6': 0.8653, 'group_auc': 0.8879}), (7, {'auc': 0.8843, 'logloss': 0.3969, 'mean_mrr': 0.8213, 'ndcg@2': 0.822, 'ndcg@4': 0.866, 'ndcg@6': 0.8671, 'group_auc': 0.8898}), (8, {'auc': 0.8853, 'logloss': 0.3976, 'mean_mrr': 0.8252, 'ndcg@2': 0.8261, 'ndcg@4': 0.869, 'ndcg@6': 0.87, 'group_auc': 0.8924}), (9, {'auc': 0.8877, 'logloss': 0.4392, 'mean_mrr': 0.827, 'ndcg@2': 0.827, 'ndcg@4': 0.8703, 'ndcg@6': 0.8714, 'group_auc': 0.8932}), (10, {'auc': 0.8887, 'logloss': 0.4454, 'mean_mrr': 0.8275, 'ndcg@2': 0.8283, 'ndcg@4': 0.8707, 'ndcg@6': 0.8718, 'group_auc': 0.8938})]\n","best epoch: 10\n","Time cost for training is 197.31 mins\n"]}],"source":["with Timer() as train_time:\n","    model = model.fit(train_file, valid_file, valid_num_ngs=valid_num_ngs) \n","\n","# valid_num_ngs is the number of negative lines after each positive line in your valid_file \n","# we will evaluate the performance of model on valid_file every epoch\n","print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53342,"status":"ok","timestamp":1650000644460,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"gmm3DPjbiY9N","outputId":"8d589301-91a9-446f-99dc-ebcff115c0a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'auc': 0.8906, 'logloss': 0.4465, 'mean_mrr': 0.7055, 'ndcg@2': 0.6683, 'ndcg@4': 0.7577, 'ndcg@6': 0.776, 'group_auc': 0.8951}\n"]}],"source":["res_syn = model.run_eval(test_file, num_ngs=test_num_ngs)\n","print(res_syn)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":428,"status":"ok","timestamp":1650000657669,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"VB7MBFNkjl5e","outputId":"976697e7-e35e-416d-9e5a-436c9032db89"},"outputs":[{"data":{"application/scrapbook.scrap.json+json":{"data":{"auc":0.8906,"group_auc":0.8951,"logloss":0.4465,"mean_mrr":0.7055,"ndcg@2":0.6683,"ndcg@4":0.7577,"ndcg@6":0.776},"encoder":"json","name":"res_syn","version":1}},"metadata":{"scrapbook":{"data":true,"display":false,"name":"res_syn"}},"output_type":"display_data"}],"source":["sb.glue(\"res_syn\", res_syn)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":35776,"status":"ok","timestamp":1650000695071,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"h2uxYGfFjpL9"},"outputs":[],"source":["model = model.predict(test_file, output_file)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7124,"status":"ok","timestamp":1650000712820,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"wGZ26pt-ujeo","outputId":"5e57cd48-8e85-463f-e278-ec02afe67ef6"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\base_model.py:701: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n","  curr_hidden_nn_layer = tf.compat.v1.layers.batch_normalization(\n","C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs, training=training)\n"]},{"name":"stdout","output_type":"stream","text":["loading saved model in resources/model\\sli_rec/best_model\n"]}],"source":["model_best_trained = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n","path_best_trained = os.path.join(hparams.MODEL_DIR, \"best_model\")\n","print('loading saved model in {0}'.format(path_best_trained))\n","model_best_trained.load_model(path_best_trained)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75245,"status":"ok","timestamp":1650000790316,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"fKtBHxlGu5-K","outputId":"d3fdcadf-665d-4120-c4fa-78af49376d1b"},"outputs":[{"data":{"text/plain":["{'auc': 0.8906,\n"," 'logloss': 0.4465,\n"," 'mean_mrr': 0.7055,\n"," 'ndcg@2': 0.6683,\n"," 'ndcg@4': 0.7577,\n"," 'ndcg@6': 0.776,\n"," 'group_auc': 0.8951}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["model_best_trained.run_eval(test_file, num_ngs=test_num_ngs)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48189,"status":"ok","timestamp":1650000881133,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"XH7L5VOQvARx","outputId":"048eb05a-af69-47d3-9111-62281609532d"},"outputs":[{"data":{"text/plain":["<recommenders.models.deeprec.models.sequential.sli_rec.SLI_RECModel at 0x151186b48e0>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model_best_trained.predict(test_file, output_file)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["<recommenders.models.deeprec.models.sequential.sli_rec.SLI_RECModel at 0x151186b48e0>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["model_best_trained.predict('test_data','output.txt')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPMZYkqYRJvrImpPUSQoA76","collapsed_sections":[],"mount_file_id":"1aN-Xq8xQ0gMEOoDsqX8RKLj3SKskndqj","name":"SLI_REC.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"}},"nbformat":4,"nbformat_minor":0}
