{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8296,"status":"ok","timestamp":1649980980504,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"Sknnn2xs-AHi","outputId":"80551ecd-5a8e-4fc5-fab5-74699c879c18"},"outputs":[{"name":"stdout","output_type":"stream","text":["System version: 3.8.9 (tags/v3.8.9:a743f81, Apr  6 2021, 14:02:34) [MSC v.1928 64 bit (AMD64)]\n","Tensorflow version: 2.8.0\n"]}],"source":["import sys\n","import os\n","import logging\n","import papermill as pm\n","import scrapbook as sb\n","from tempfile import TemporaryDirectory\n","import numpy as np\n","import tensorflow.compat.v1 as tf\n","tf.get_logger().setLevel('ERROR') # only show error messages\n","\n","from recommenders.utils.timer import Timer\n","from recommenders.utils.constants import SEED\n","from recommenders.models.deeprec.deeprec_utils import (\n","    prepare_hparams\n",")\n","\n","from resources.data_preprocessing2 import data_preprocessing\n","# from recommenders.datasets.amazon_reviews import download_and_extract, data_preprocessing\n","from recommenders.datasets.download_utils import maybe_download\n","\n","\n","from recommenders.models.deeprec.models.sequential.sli_rec import SLI_RECModel as SeqModel\n","####  to use the other model, use one of the following lines:\n","#from recommenders.models.deeprec.models.sequential.asvd import A2SVDModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.caser import CaserModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.gru4rec import GRU4RecModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.sum import SUMModel as SeqModel\n","\n","#from recommenders.models.deeprec.models.sequential.nextitnet import NextItNetModel\n","\n","from recommenders.models.deeprec.io.sequential_iterator import SequentialIterator\n","#from recommenders.models.deeprec.io.nextitnet_iterator import NextItNetIterator\n","\n","print(\"System version: {}\".format(sys.version))\n","print(\"Tensorflow version: {}\".format(tf.__version__))"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":424,"status":"ok","timestamp":1649980983686,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"sxtfUZfP-ZWR"},"outputs":[],"source":["##  ATTENTION: change to the corresponding config file, e.g., caser.yaml for CaserModel, sum.yaml for SUMModel\n","# yaml_file = '../../recommenders/models/deeprec/config/sli_rec.yaml'  \n","yaml_file = './sli_rec.yaml'  "]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":415,"status":"ok","timestamp":1649981001550,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"_NnzhN4h_rI5"},"outputs":[],"source":["EPOCHS = 10\n","BATCH_SIZE = 400\n","RANDOM_SEED = SEED  # Set None for non-deterministic result\n","\n","data_path = os.path.join(\"resources/results/20220504\")"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":419,"status":"ok","timestamp":1649981009184,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"0RAMNcI3AClc"},"outputs":[],"source":["# for test\n","train_file = os.path.join(data_path, r'train_data')\n","valid_file = os.path.join(data_path, r'valid_data')\n","test_file = os.path.join(data_path, r'test_data')\n","user_vocab = os.path.join(data_path, r'user_vocab.pkl')\n","item_vocab = os.path.join(data_path, r'item_vocab.pkl')\n","cate_vocab = os.path.join(data_path, r'cate_vocab.pkl')\n","output_file = os.path.join(data_path, r'output_sli_rec.txt')\n","\n","# reviews_name = 'json'\n","# meta_name = 'json'\n","# reviews_file = os.path.join(data_path, reviews_name)\n","# meta_file = os.path.join(data_path, meta_name)\n","train_num_ngs = 4 # number of negative instances with a positive instance for training\n","valid_num_ngs = 4 # number of negative instances with a positive instance for validation\n","test_num_ngs = 9 # number of negative instances with a positive instance for testing\n","sample_rate = 0.1 # sample a small item set for training and testing here for fast example\n","\n","input_files = [data_path, train_file, valid_file, test_file, user_vocab, item_vocab, cate_vocab]\n","\n","if not os.path.exists(train_file):\n","    # download_and_extract(reviews_name, reviews_file)\n","    # download_and_extract(meta_name, meta_file)\n","    data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs)\n","    #### uncomment this for the NextItNet model, because it does not need to unfold the user history\n","    # data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs, is_history_expanding=False)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1013,"status":"ok","timestamp":1649981039553,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"rwTMO3WEWaCu"},"outputs":[],"source":["### NOTE:  \n","### remember to use `_create_vocab(train_file, user_vocab, item_vocab, cate_vocab)` to generate the user_vocab, item_vocab and cate_vocab files, if you are using your own dataset rather than using our demo Amazon dataset.\n","hparams = prepare_hparams(yaml_file, \n","                          embed_l2=0., \n","                          layer_l2=0., \n","                          learning_rate=0.001,  # set to 0.01 if batch normalization is disable\n","                          epochs=EPOCHS,\n","                          batch_size=BATCH_SIZE,\n","                          show_step=20,\n","                          MODEL_DIR=os.path.join(data_path, \"model\", \"sli_rec/\"),\n","                          SUMMARIES_DIR=os.path.join(data_path, \"summary\", \"sli_rec/\"),\n","                          user_vocab=user_vocab,\n","                          item_vocab=item_vocab,\n","                          cate_vocab=cate_vocab,\n","                          need_sample=True,\n","                          train_num_ngs=train_num_ngs, # provides the number of negative instances for each positive instance for loss computation.\n","            )"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":420,"status":"ok","timestamp":1649981043565,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"4Rvq7gFluVPq"},"outputs":[],"source":["input_creator = SequentialIterator\n","#### uncomment this for the NextItNet model, because it needs a special data iterator for training\n","#input_creator = NextItNetIterator"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11139,"status":"ok","timestamp":1649981057379,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"VFNfgcKNuaVv","outputId":"2f195cde-2963-41ff-aa84-0a17d9a9cd3d"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\base_model.py:701: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n","  curr_hidden_nn_layer = tf.compat.v1.layers.batch_normalization(\n","C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs, training=training)\n"]}],"source":["model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n","\n","## sometimes we don't want to train a model from scratch\n","## then we can load a pre-trained model like this: \n","#model.load_model(r'your_model_path')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63766,"status":"ok","timestamp":1649981126167,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"8AQxPlk-uheU","outputId":"23ee2335-3935-437b-c4f2-0c01fee93d8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'auc': 0.5504, 'logloss': 0.6931, 'mean_mrr': 0.322, 'ndcg@2': 0.1975, 'ndcg@4': 0.2897, 'ndcg@6': 0.3625, 'group_auc': 0.5484}\n"]}],"source":["# test_num_ngs is the number of negative lines after each positive line in your test_file\n","print(model.run_eval(test_file, num_ngs=test_num_ngs)) "]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19408573,"status":"ok","timestamp":1650000544829,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"QFKQu9rGu0jq","outputId":"68371df4-d8f1-4844-8f13-d634505f1b33"},"outputs":[{"name":"stdout","output_type":"stream","text":["step 20 , total_loss: 1.5138, data_loss: 1.5138\n","step 40 , total_loss: 1.3492, data_loss: 1.3492\n","step 60 , total_loss: 1.3590, data_loss: 1.3590\n","step 80 , total_loss: 1.2899, data_loss: 1.2899\n","step 100 , total_loss: 1.3073, data_loss: 1.3073\n","step 120 , total_loss: 1.2321, data_loss: 1.2321\n","step 140 , total_loss: 1.2895, data_loss: 1.2895\n","step 160 , total_loss: 1.3049, data_loss: 1.3049\n","step 180 , total_loss: 1.2702, data_loss: 1.2702\n","step 200 , total_loss: 1.2973, data_loss: 1.2973\n","step 220 , total_loss: 1.2337, data_loss: 1.2337\n","step 240 , total_loss: 1.2505, data_loss: 1.2505\n","step 260 , total_loss: 1.2658, data_loss: 1.2658\n","step 280 , total_loss: 1.2386, data_loss: 1.2386\n","step 300 , total_loss: 1.2466, data_loss: 1.2466\n","step 320 , total_loss: 1.1930, data_loss: 1.1930\n","step 340 , total_loss: 1.2470, data_loss: 1.2470\n","step 360 , total_loss: 1.2177, data_loss: 1.2177\n","step 380 , total_loss: 1.1590, data_loss: 1.1590\n","step 400 , total_loss: 1.2311, data_loss: 1.2311\n","step 420 , total_loss: 1.1837, data_loss: 1.1837\n","step 440 , total_loss: 1.2493, data_loss: 1.2493\n","step 460 , total_loss: 1.2543, data_loss: 1.2543\n","step 480 , total_loss: 1.1838, data_loss: 1.1838\n","step 500 , total_loss: 1.2033, data_loss: 1.2033\n","step 520 , total_loss: 1.2061, data_loss: 1.2061\n","step 540 , total_loss: 1.1579, data_loss: 1.1579\n","step 560 , total_loss: 1.1865, data_loss: 1.1865\n","step 580 , total_loss: 1.2003, data_loss: 1.2003\n","step 600 , total_loss: 1.2336, data_loss: 1.2336\n","step 620 , total_loss: 1.1554, data_loss: 1.1554\n","step 640 , total_loss: 1.1165, data_loss: 1.1165\n","step 660 , total_loss: 1.1757, data_loss: 1.1757\n","step 680 , total_loss: 1.1582, data_loss: 1.1582\n","step 700 , total_loss: 1.1028, data_loss: 1.1028\n","step 720 , total_loss: 1.0971, data_loss: 1.0971\n","eval valid at epoch 1: auc:0.7751,logloss:0.5502,mean_mrr:0.6908,ndcg@2:0.6555,ndcg@4:0.7591,ndcg@6:0.7689,group_auc:0.7796\n","step 20 , total_loss: 1.2082, data_loss: 1.2082\n","step 40 , total_loss: 1.1665, data_loss: 1.1665\n","step 60 , total_loss: 1.1817, data_loss: 1.1817\n","step 80 , total_loss: 1.2002, data_loss: 1.2002\n","step 100 , total_loss: 1.1016, data_loss: 1.1016\n","step 120 , total_loss: 1.1490, data_loss: 1.1490\n","step 140 , total_loss: 1.0432, data_loss: 1.0432\n","step 160 , total_loss: 1.0371, data_loss: 1.0371\n","step 180 , total_loss: 1.1108, data_loss: 1.1108\n","step 200 , total_loss: 1.1428, data_loss: 1.1428\n","step 220 , total_loss: 1.1188, data_loss: 1.1188\n","step 240 , total_loss: 1.0762, data_loss: 1.0762\n","step 260 , total_loss: 1.0536, data_loss: 1.0536\n","step 280 , total_loss: 1.1028, data_loss: 1.1028\n","step 300 , total_loss: 1.0714, data_loss: 1.0714\n","step 320 , total_loss: 1.0874, data_loss: 1.0874\n","step 340 , total_loss: 1.0261, data_loss: 1.0261\n","step 360 , total_loss: 0.9786, data_loss: 0.9786\n","step 380 , total_loss: 0.9566, data_loss: 0.9566\n","step 400 , total_loss: 1.0557, data_loss: 1.0557\n","step 420 , total_loss: 0.9586, data_loss: 0.9586\n","step 440 , total_loss: 1.0447, data_loss: 1.0447\n","step 460 , total_loss: 0.9701, data_loss: 0.9701\n","step 480 , total_loss: 0.8971, data_loss: 0.8971\n","step 500 , total_loss: 1.0013, data_loss: 1.0013\n","step 520 , total_loss: 0.9883, data_loss: 0.9883\n","step 540 , total_loss: 0.9190, data_loss: 0.9190\n","step 560 , total_loss: 0.9124, data_loss: 0.9124\n","step 580 , total_loss: 0.9485, data_loss: 0.9485\n","step 600 , total_loss: 0.9866, data_loss: 0.9866\n","step 620 , total_loss: 0.9185, data_loss: 0.9185\n","step 640 , total_loss: 0.9397, data_loss: 0.9397\n","step 660 , total_loss: 0.9682, data_loss: 0.9682\n","step 680 , total_loss: 0.8756, data_loss: 0.8756\n","step 700 , total_loss: 0.9158, data_loss: 0.9158\n","step 720 , total_loss: 0.9632, data_loss: 0.9632\n","eval valid at epoch 2: auc:0.8522,logloss:0.4468,mean_mrr:0.7763,ndcg@2:0.767,ndcg@4:0.8317,ndcg@6:0.8335,group_auc:0.8567\n","step 20 , total_loss: 0.9248, data_loss: 0.9248\n","step 40 , total_loss: 0.8584, data_loss: 0.8584\n","step 60 , total_loss: 0.8689, data_loss: 0.8689\n","step 80 , total_loss: 0.9400, data_loss: 0.9400\n","step 100 , total_loss: 0.8621, data_loss: 0.8621\n","step 120 , total_loss: 0.8294, data_loss: 0.8294\n","step 140 , total_loss: 0.8948, data_loss: 0.8948\n","step 160 , total_loss: 0.8156, data_loss: 0.8156\n","step 180 , total_loss: 0.8972, data_loss: 0.8972\n","step 200 , total_loss: 0.9299, data_loss: 0.9299\n","step 220 , total_loss: 0.9061, data_loss: 0.9061\n","step 240 , total_loss: 0.8111, data_loss: 0.8111\n","step 260 , total_loss: 0.8204, data_loss: 0.8204\n","step 280 , total_loss: 0.8556, data_loss: 0.8556\n","step 300 , total_loss: 0.9115, data_loss: 0.9115\n","step 320 , total_loss: 0.8339, data_loss: 0.8339\n","step 340 , total_loss: 0.9013, data_loss: 0.9013\n","step 360 , total_loss: 0.8724, data_loss: 0.8724\n","step 380 , total_loss: 0.8659, data_loss: 0.8659\n","step 400 , total_loss: 0.8455, data_loss: 0.8455\n","step 420 , total_loss: 0.8398, data_loss: 0.8398\n","step 440 , total_loss: 0.7701, data_loss: 0.7701\n","step 460 , total_loss: 0.8049, data_loss: 0.8049\n","step 480 , total_loss: 0.8501, data_loss: 0.8501\n","step 500 , total_loss: 0.8523, data_loss: 0.8523\n","step 520 , total_loss: 0.8260, data_loss: 0.8260\n","step 540 , total_loss: 0.7559, data_loss: 0.7559\n","step 560 , total_loss: 0.8892, data_loss: 0.8892\n","step 580 , total_loss: 0.8800, data_loss: 0.8800\n","step 600 , total_loss: 0.8408, data_loss: 0.8408\n","step 620 , total_loss: 0.8779, data_loss: 0.8779\n","step 640 , total_loss: 0.8523, data_loss: 0.8523\n","step 660 , total_loss: 0.7753, data_loss: 0.7753\n","step 680 , total_loss: 0.8415, data_loss: 0.8415\n","step 700 , total_loss: 0.7971, data_loss: 0.7971\n","step 720 , total_loss: 0.8526, data_loss: 0.8526\n","eval valid at epoch 3: auc:0.8808,logloss:0.3881,mean_mrr:0.8092,ndcg@2:0.8074,ndcg@4:0.857,ndcg@6:0.8581,group_auc:0.8813\n","step 20 , total_loss: 0.8089, data_loss: 0.8089\n","step 40 , total_loss: 0.8004, data_loss: 0.8004\n","step 60 , total_loss: 0.7763, data_loss: 0.7763\n","step 80 , total_loss: 0.8604, data_loss: 0.8604\n","step 100 , total_loss: 0.8703, data_loss: 0.8703\n","step 120 , total_loss: 0.8124, data_loss: 0.8124\n","step 140 , total_loss: 0.8081, data_loss: 0.8081\n","step 160 , total_loss: 0.7872, data_loss: 0.7872\n","step 180 , total_loss: 0.8381, data_loss: 0.8381\n","step 200 , total_loss: 0.7525, data_loss: 0.7525\n","step 220 , total_loss: 0.8327, data_loss: 0.8327\n","step 240 , total_loss: 0.8745, data_loss: 0.8745\n","step 260 , total_loss: 0.8098, data_loss: 0.8098\n","step 280 , total_loss: 0.7866, data_loss: 0.7866\n","step 300 , total_loss: 0.7893, data_loss: 0.7893\n","step 320 , total_loss: 0.7380, data_loss: 0.7380\n","step 340 , total_loss: 0.8444, data_loss: 0.8444\n","step 360 , total_loss: 0.7951, data_loss: 0.7951\n","step 380 , total_loss: 0.8124, data_loss: 0.8124\n","step 400 , total_loss: 0.7331, data_loss: 0.7331\n","step 420 , total_loss: 0.7776, data_loss: 0.7776\n","step 440 , total_loss: 0.7754, data_loss: 0.7754\n","step 460 , total_loss: 0.7734, data_loss: 0.7734\n","step 480 , total_loss: 0.8207, data_loss: 0.8207\n","step 500 , total_loss: 0.8050, data_loss: 0.8050\n","step 520 , total_loss: 0.8221, data_loss: 0.8221\n","step 540 , total_loss: 0.8007, data_loss: 0.8007\n","step 560 , total_loss: 0.8953, data_loss: 0.8953\n","step 580 , total_loss: 0.7707, data_loss: 0.7707\n","step 600 , total_loss: 0.8309, data_loss: 0.8309\n","step 620 , total_loss: 0.7907, data_loss: 0.7907\n","step 640 , total_loss: 0.8120, data_loss: 0.8120\n","step 660 , total_loss: 0.9366, data_loss: 0.9366\n","step 680 , total_loss: 0.8803, data_loss: 0.8803\n","step 700 , total_loss: 0.7891, data_loss: 0.7891\n","step 720 , total_loss: 0.8113, data_loss: 0.8113\n","eval valid at epoch 4: auc:0.8856,logloss:0.3911,mean_mrr:0.8166,ndcg@2:0.8157,ndcg@4:0.8627,ndcg@6:0.8637,group_auc:0.8865\n","step 20 , total_loss: 0.8098, data_loss: 0.8098\n","step 40 , total_loss: 0.7575, data_loss: 0.7575\n","step 60 , total_loss: 0.8161, data_loss: 0.8161\n","step 80 , total_loss: 0.8318, data_loss: 0.8318\n","step 100 , total_loss: 0.7944, data_loss: 0.7944\n","step 120 , total_loss: 0.7411, data_loss: 0.7411\n","step 140 , total_loss: 0.8167, data_loss: 0.8167\n","step 160 , total_loss: 0.7736, data_loss: 0.7736\n","step 180 , total_loss: 0.7898, data_loss: 0.7898\n","step 200 , total_loss: 0.7308, data_loss: 0.7308\n","step 220 , total_loss: 0.7966, data_loss: 0.7966\n","step 240 , total_loss: 0.7907, data_loss: 0.7907\n","step 260 , total_loss: 0.8575, data_loss: 0.8575\n","step 280 , total_loss: 0.8848, data_loss: 0.8848\n","step 300 , total_loss: 0.7640, data_loss: 0.7640\n","step 320 , total_loss: 0.7654, data_loss: 0.7654\n","step 340 , total_loss: 0.8320, data_loss: 0.8320\n","step 360 , total_loss: 0.7430, data_loss: 0.7430\n","step 380 , total_loss: 0.7914, data_loss: 0.7914\n","step 400 , total_loss: 0.7973, data_loss: 0.7973\n","step 420 , total_loss: 0.8048, data_loss: 0.8048\n","step 440 , total_loss: 0.7963, data_loss: 0.7963\n","step 460 , total_loss: 0.7911, data_loss: 0.7911\n","step 480 , total_loss: 0.7490, data_loss: 0.7490\n","step 500 , total_loss: 0.7999, data_loss: 0.7999\n","step 520 , total_loss: 0.8565, data_loss: 0.8565\n","step 540 , total_loss: 0.6913, data_loss: 0.6913\n","step 560 , total_loss: 0.7374, data_loss: 0.7374\n","step 580 , total_loss: 0.8506, data_loss: 0.8506\n","step 600 , total_loss: 0.8365, data_loss: 0.8365\n","step 620 , total_loss: 0.8190, data_loss: 0.8190\n","step 640 , total_loss: 0.7995, data_loss: 0.7995\n","step 660 , total_loss: 0.7445, data_loss: 0.7445\n","step 680 , total_loss: 0.7439, data_loss: 0.7439\n","step 700 , total_loss: 0.7851, data_loss: 0.7851\n","step 720 , total_loss: 0.7468, data_loss: 0.7468\n","eval valid at epoch 5: auc:0.8872,logloss:0.3712,mean_mrr:0.8195,ndcg@2:0.8197,ndcg@4:0.8649,ndcg@6:0.8658,group_auc:0.8886\n","step 20 , total_loss: 0.7543, data_loss: 0.7543\n","step 40 , total_loss: 0.8505, data_loss: 0.8505\n","step 60 , total_loss: 0.7131, data_loss: 0.7131\n","step 80 , total_loss: 0.7553, data_loss: 0.7553\n","step 100 , total_loss: 0.7799, data_loss: 0.7799\n","step 120 , total_loss: 0.8587, data_loss: 0.8587\n","step 140 , total_loss: 0.8379, data_loss: 0.8379\n","step 160 , total_loss: 0.7932, data_loss: 0.7932\n","step 180 , total_loss: 0.7620, data_loss: 0.7620\n","step 200 , total_loss: 0.7503, data_loss: 0.7503\n","step 220 , total_loss: 0.7747, data_loss: 0.7747\n","step 240 , total_loss: 0.7894, data_loss: 0.7894\n","step 260 , total_loss: 0.7367, data_loss: 0.7367\n","step 280 , total_loss: 0.8065, data_loss: 0.8065\n","step 300 , total_loss: 0.8057, data_loss: 0.8057\n","step 320 , total_loss: 0.7390, data_loss: 0.7390\n","step 340 , total_loss: 0.7841, data_loss: 0.7841\n","step 360 , total_loss: 0.8015, data_loss: 0.8015\n","step 380 , total_loss: 0.7720, data_loss: 0.7720\n","step 400 , total_loss: 0.7604, data_loss: 0.7604\n","step 420 , total_loss: 0.8122, data_loss: 0.8122\n","step 440 , total_loss: 0.7574, data_loss: 0.7574\n","step 460 , total_loss: 0.7787, data_loss: 0.7787\n","step 480 , total_loss: 0.7970, data_loss: 0.7970\n","step 500 , total_loss: 0.7065, data_loss: 0.7065\n","step 520 , total_loss: 0.7606, data_loss: 0.7606\n","step 540 , total_loss: 0.7781, data_loss: 0.7781\n","step 560 , total_loss: 0.7692, data_loss: 0.7692\n","step 580 , total_loss: 0.7303, data_loss: 0.7303\n","step 600 , total_loss: 0.8513, data_loss: 0.8513\n","step 620 , total_loss: 0.7363, data_loss: 0.7363\n","step 640 , total_loss: 0.7710, data_loss: 0.7710\n","step 660 , total_loss: 0.7546, data_loss: 0.7546\n","step 680 , total_loss: 0.7991, data_loss: 0.7991\n","step 700 , total_loss: 0.7493, data_loss: 0.7493\n","step 720 , total_loss: 0.7031, data_loss: 0.7031\n","eval valid at epoch 6: auc:0.8863,logloss:0.3672,mean_mrr:0.82,ndcg@2:0.819,ndcg@4:0.8653,ndcg@6:0.8662,group_auc:0.8887\n","step 20 , total_loss: 0.8733, data_loss: 0.8733\n","step 40 , total_loss: 0.7149, data_loss: 0.7149\n","step 60 , total_loss: 0.8238, data_loss: 0.8238\n","step 80 , total_loss: 0.7129, data_loss: 0.7129\n","step 100 , total_loss: 0.7275, data_loss: 0.7275\n","step 120 , total_loss: 0.7644, data_loss: 0.7644\n","step 140 , total_loss: 0.7269, data_loss: 0.7269\n","step 160 , total_loss: 0.8244, data_loss: 0.8244\n","step 180 , total_loss: 0.7945, data_loss: 0.7945\n","step 200 , total_loss: 0.8088, data_loss: 0.8088\n","step 220 , total_loss: 0.7124, data_loss: 0.7124\n","step 240 , total_loss: 0.7479, data_loss: 0.7479\n","step 260 , total_loss: 0.7677, data_loss: 0.7677\n","step 280 , total_loss: 0.7741, data_loss: 0.7741\n","step 300 , total_loss: 0.7324, data_loss: 0.7324\n","step 320 , total_loss: 0.7403, data_loss: 0.7403\n","step 340 , total_loss: 0.7981, data_loss: 0.7981\n","step 360 , total_loss: 0.7504, data_loss: 0.7504\n","step 380 , total_loss: 0.8524, data_loss: 0.8524\n","step 400 , total_loss: 0.7346, data_loss: 0.7346\n","step 420 , total_loss: 0.7488, data_loss: 0.7488\n","step 440 , total_loss: 0.7558, data_loss: 0.7558\n","step 460 , total_loss: 0.7635, data_loss: 0.7635\n","step 480 , total_loss: 0.8180, data_loss: 0.8180\n","step 500 , total_loss: 0.7157, data_loss: 0.7157\n","step 520 , total_loss: 0.7605, data_loss: 0.7605\n","step 540 , total_loss: 0.8268, data_loss: 0.8268\n","step 560 , total_loss: 0.7896, data_loss: 0.7896\n","step 580 , total_loss: 0.7735, data_loss: 0.7735\n","step 600 , total_loss: 0.7555, data_loss: 0.7555\n","step 620 , total_loss: 0.7504, data_loss: 0.7504\n","step 640 , total_loss: 0.7518, data_loss: 0.7518\n","step 660 , total_loss: 0.7666, data_loss: 0.7666\n","step 680 , total_loss: 0.7449, data_loss: 0.7449\n","step 700 , total_loss: 0.7889, data_loss: 0.7889\n","step 720 , total_loss: 0.7969, data_loss: 0.7969\n","eval valid at epoch 7: auc:0.889,logloss:0.3876,mean_mrr:0.825,ndcg@2:0.825,ndcg@4:0.8689,ndcg@6:0.8699,group_auc:0.8919\n","step 20 , total_loss: 0.7092, data_loss: 0.7092\n","step 40 , total_loss: 0.8179, data_loss: 0.8179\n","step 60 , total_loss: 0.7988, data_loss: 0.7988\n","step 80 , total_loss: 0.7596, data_loss: 0.7596\n","step 100 , total_loss: 0.8237, data_loss: 0.8237\n","step 120 , total_loss: 0.6885, data_loss: 0.6885\n","step 140 , total_loss: 0.7253, data_loss: 0.7253\n","step 160 , total_loss: 0.7424, data_loss: 0.7424\n","step 180 , total_loss: 0.8953, data_loss: 0.8953\n","step 200 , total_loss: 0.7597, data_loss: 0.7597\n","step 220 , total_loss: 0.7315, data_loss: 0.7315\n","step 240 , total_loss: 0.7451, data_loss: 0.7451\n","step 260 , total_loss: 0.8088, data_loss: 0.8088\n","step 280 , total_loss: 0.7510, data_loss: 0.7510\n","step 300 , total_loss: 0.7323, data_loss: 0.7323\n","step 320 , total_loss: 0.7939, data_loss: 0.7939\n","step 340 , total_loss: 0.7896, data_loss: 0.7896\n","step 360 , total_loss: 0.7760, data_loss: 0.7760\n","step 380 , total_loss: 0.7783, data_loss: 0.7783\n","step 400 , total_loss: 0.7293, data_loss: 0.7293\n","step 420 , total_loss: 0.8389, data_loss: 0.8389\n","step 440 , total_loss: 0.7251, data_loss: 0.7251\n","step 460 , total_loss: 0.7581, data_loss: 0.7581\n","step 480 , total_loss: 0.8026, data_loss: 0.8026\n","step 500 , total_loss: 0.7532, data_loss: 0.7532\n","step 520 , total_loss: 0.7518, data_loss: 0.7518\n","step 540 , total_loss: 0.7622, data_loss: 0.7622\n","step 560 , total_loss: 0.8733, data_loss: 0.8733\n","step 580 , total_loss: 0.7988, data_loss: 0.7988\n","step 600 , total_loss: 0.7663, data_loss: 0.7663\n","step 620 , total_loss: 0.7180, data_loss: 0.7180\n","step 640 , total_loss: 0.7320, data_loss: 0.7320\n","step 660 , total_loss: 0.8048, data_loss: 0.8048\n","step 680 , total_loss: 0.7608, data_loss: 0.7608\n","step 700 , total_loss: 0.7735, data_loss: 0.7735\n","step 720 , total_loss: 0.7832, data_loss: 0.7832\n","eval valid at epoch 8: auc:0.8902,logloss:0.3769,mean_mrr:0.8259,ndcg@2:0.8247,ndcg@4:0.8696,ndcg@6:0.8705,group_auc:0.8921\n","step 20 , total_loss: 0.8309, data_loss: 0.8309\n","step 40 , total_loss: 0.7740, data_loss: 0.7740\n","step 60 , total_loss: 0.7524, data_loss: 0.7524\n","step 80 , total_loss: 0.7632, data_loss: 0.7632\n","step 100 , total_loss: 0.7282, data_loss: 0.7282\n","step 120 , total_loss: 0.7959, data_loss: 0.7959\n","step 140 , total_loss: 0.7187, data_loss: 0.7187\n","step 160 , total_loss: 0.7450, data_loss: 0.7450\n","step 180 , total_loss: 0.7677, data_loss: 0.7677\n","step 200 , total_loss: 0.7391, data_loss: 0.7391\n","step 220 , total_loss: 0.7544, data_loss: 0.7544\n","step 240 , total_loss: 0.7924, data_loss: 0.7924\n","step 260 , total_loss: 0.7951, data_loss: 0.7951\n","step 280 , total_loss: 0.7792, data_loss: 0.7792\n","step 300 , total_loss: 0.7513, data_loss: 0.7513\n","step 320 , total_loss: 0.7084, data_loss: 0.7084\n","step 340 , total_loss: 0.7405, data_loss: 0.7405\n","step 360 , total_loss: 0.8080, data_loss: 0.8080\n","step 380 , total_loss: 0.7539, data_loss: 0.7539\n","step 400 , total_loss: 0.8048, data_loss: 0.8048\n","step 420 , total_loss: 0.7345, data_loss: 0.7345\n","step 440 , total_loss: 0.7750, data_loss: 0.7750\n","step 460 , total_loss: 0.7909, data_loss: 0.7909\n","step 480 , total_loss: 0.8055, data_loss: 0.8055\n","step 500 , total_loss: 0.8231, data_loss: 0.8231\n","step 520 , total_loss: 0.6450, data_loss: 0.6450\n","step 540 , total_loss: 0.7036, data_loss: 0.7036\n","step 560 , total_loss: 0.7546, data_loss: 0.7546\n","step 580 , total_loss: 0.7167, data_loss: 0.7167\n","step 600 , total_loss: 0.8048, data_loss: 0.8048\n","step 620 , total_loss: 0.7812, data_loss: 0.7812\n","step 640 , total_loss: 0.7549, data_loss: 0.7549\n","step 660 , total_loss: 0.7785, data_loss: 0.7785\n","step 680 , total_loss: 0.7850, data_loss: 0.7850\n","step 700 , total_loss: 0.7519, data_loss: 0.7519\n","step 720 , total_loss: 0.7998, data_loss: 0.7998\n","eval valid at epoch 9: auc:0.8903,logloss:0.3989,mean_mrr:0.8256,ndcg@2:0.8256,ndcg@4:0.8694,ndcg@6:0.8703,group_auc:0.8924\n","step 20 , total_loss: 0.8042, data_loss: 0.8042\n","step 40 , total_loss: 0.8127, data_loss: 0.8127\n","step 60 , total_loss: 0.7667, data_loss: 0.7667\n","step 80 , total_loss: 0.6966, data_loss: 0.6966\n","step 100 , total_loss: 0.7826, data_loss: 0.7826\n","step 120 , total_loss: 0.7993, data_loss: 0.7993\n","step 140 , total_loss: 0.7654, data_loss: 0.7654\n","step 160 , total_loss: 0.7971, data_loss: 0.7971\n","step 180 , total_loss: 0.7602, data_loss: 0.7602\n","step 200 , total_loss: 0.6893, data_loss: 0.6893\n","step 220 , total_loss: 0.7385, data_loss: 0.7385\n","step 240 , total_loss: 0.7689, data_loss: 0.7689\n","step 260 , total_loss: 0.7381, data_loss: 0.7381\n","step 280 , total_loss: 0.8650, data_loss: 0.8650\n","step 300 , total_loss: 0.7753, data_loss: 0.7753\n","step 320 , total_loss: 0.7117, data_loss: 0.7117\n","step 340 , total_loss: 0.7027, data_loss: 0.7027\n","step 360 , total_loss: 0.7249, data_loss: 0.7249\n","step 380 , total_loss: 0.6938, data_loss: 0.6938\n","step 400 , total_loss: 0.8307, data_loss: 0.8307\n","step 420 , total_loss: 0.7378, data_loss: 0.7378\n","step 440 , total_loss: 0.7326, data_loss: 0.7326\n","step 460 , total_loss: 0.7711, data_loss: 0.7711\n","step 480 , total_loss: 0.7717, data_loss: 0.7717\n","step 500 , total_loss: 0.7125, data_loss: 0.7125\n","step 520 , total_loss: 0.9022, data_loss: 0.9022\n","step 540 , total_loss: 0.8410, data_loss: 0.8410\n","step 560 , total_loss: 0.8173, data_loss: 0.8173\n","step 580 , total_loss: 0.7814, data_loss: 0.7814\n","step 600 , total_loss: 0.7887, data_loss: 0.7887\n","step 620 , total_loss: 0.7486, data_loss: 0.7486\n","step 640 , total_loss: 0.7627, data_loss: 0.7627\n","step 660 , total_loss: 0.7582, data_loss: 0.7582\n","step 680 , total_loss: 0.8401, data_loss: 0.8401\n","step 700 , total_loss: 0.8346, data_loss: 0.8346\n","step 720 , total_loss: 0.6743, data_loss: 0.6743\n","eval valid at epoch 10: auc:0.8896,logloss:0.4158,mean_mrr:0.8267,ndcg@2:0.8265,ndcg@4:0.8701,ndcg@6:0.8711,group_auc:0.8929\n","[(1, {'auc': 0.7751, 'logloss': 0.5502, 'mean_mrr': 0.6908, 'ndcg@2': 0.6555, 'ndcg@4': 0.7591, 'ndcg@6': 0.7689, 'group_auc': 0.7796}), (2, {'auc': 0.8522, 'logloss': 0.4468, 'mean_mrr': 0.7763, 'ndcg@2': 0.767, 'ndcg@4': 0.8317, 'ndcg@6': 0.8335, 'group_auc': 0.8567}), (3, {'auc': 0.8808, 'logloss': 0.3881, 'mean_mrr': 0.8092, 'ndcg@2': 0.8074, 'ndcg@4': 0.857, 'ndcg@6': 0.8581, 'group_auc': 0.8813}), (4, {'auc': 0.8856, 'logloss': 0.3911, 'mean_mrr': 0.8166, 'ndcg@2': 0.8157, 'ndcg@4': 0.8627, 'ndcg@6': 0.8637, 'group_auc': 0.8865}), (5, {'auc': 0.8872, 'logloss': 0.3712, 'mean_mrr': 0.8195, 'ndcg@2': 0.8197, 'ndcg@4': 0.8649, 'ndcg@6': 0.8658, 'group_auc': 0.8886}), (6, {'auc': 0.8863, 'logloss': 0.3672, 'mean_mrr': 0.82, 'ndcg@2': 0.819, 'ndcg@4': 0.8653, 'ndcg@6': 0.8662, 'group_auc': 0.8887}), (7, {'auc': 0.889, 'logloss': 0.3876, 'mean_mrr': 0.825, 'ndcg@2': 0.825, 'ndcg@4': 0.8689, 'ndcg@6': 0.8699, 'group_auc': 0.8919}), (8, {'auc': 0.8902, 'logloss': 0.3769, 'mean_mrr': 0.8259, 'ndcg@2': 0.8247, 'ndcg@4': 0.8696, 'ndcg@6': 0.8705, 'group_auc': 0.8921}), (9, {'auc': 0.8903, 'logloss': 0.3989, 'mean_mrr': 0.8256, 'ndcg@2': 0.8256, 'ndcg@4': 0.8694, 'ndcg@6': 0.8703, 'group_auc': 0.8924}), (10, {'auc': 0.8896, 'logloss': 0.4158, 'mean_mrr': 0.8267, 'ndcg@2': 0.8265, 'ndcg@4': 0.8701, 'ndcg@6': 0.8711, 'group_auc': 0.8929})]\n","best epoch: 10\n","Time cost for training is 172.52 mins\n"]}],"source":["with Timer() as train_time:\n","    model = model.fit(train_file, valid_file, valid_num_ngs=valid_num_ngs) \n","\n","# valid_num_ngs is the number of negative lines after each positive line in your valid_file \n","# we will evaluate the performance of model on valid_file every epoch\n","print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53342,"status":"ok","timestamp":1650000644460,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"gmm3DPjbiY9N","outputId":"8d589301-91a9-446f-99dc-ebcff115c0a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'auc': 0.8907, 'logloss': 0.4206, 'mean_mrr': 0.6947, 'ndcg@2': 0.654, 'ndcg@4': 0.7474, 'ndcg@6': 0.7679, 'group_auc': 0.8907}\n"]}],"source":["res_syn = model.run_eval(test_file, num_ngs=test_num_ngs)\n","print(res_syn)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":428,"status":"ok","timestamp":1650000657669,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"VB7MBFNkjl5e","outputId":"976697e7-e35e-416d-9e5a-436c9032db89"},"outputs":[{"data":{"application/scrapbook.scrap.json+json":{"data":{"auc":0.8907,"group_auc":0.8907,"logloss":0.4206,"mean_mrr":0.6947,"ndcg@2":0.654,"ndcg@4":0.7474,"ndcg@6":0.7679},"encoder":"json","name":"res_syn","version":1}},"metadata":{"scrapbook":{"data":true,"display":false,"name":"res_syn"}},"output_type":"display_data"}],"source":["sb.glue(\"res_syn\", res_syn)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":35776,"status":"ok","timestamp":1650000695071,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"h2uxYGfFjpL9"},"outputs":[],"source":["model = model.predict(test_file, output_file)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7124,"status":"ok","timestamp":1650000712820,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"wGZ26pt-ujeo","outputId":"5e57cd48-8e85-463f-e278-ec02afe67ef6"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\base_model.py:701: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n","  curr_hidden_nn_layer = tf.compat.v1.layers.batch_normalization(\n","C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs, training=training)\n"]},{"name":"stdout","output_type":"stream","text":["loading saved model in resources/results/20220504\\model\\sli_rec/best_model\n"]}],"source":["model_best_trained = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n","path_best_trained = os.path.join(hparams.MODEL_DIR, \"best_model\")\n","print('loading saved model in {0}'.format(path_best_trained))\n","model_best_trained.load_model(path_best_trained)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75245,"status":"ok","timestamp":1650000790316,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"fKtBHxlGu5-K","outputId":"d3fdcadf-665d-4120-c4fa-78af49376d1b"},"outputs":[{"data":{"text/plain":["{'auc': 0.8907,\n"," 'logloss': 0.4206,\n"," 'mean_mrr': 0.6947,\n"," 'ndcg@2': 0.654,\n"," 'ndcg@4': 0.7474,\n"," 'ndcg@6': 0.7679,\n"," 'group_auc': 0.8907}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["model_best_trained.run_eval(test_file, num_ngs=test_num_ngs)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48189,"status":"ok","timestamp":1650000881133,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"XH7L5VOQvARx","outputId":"048eb05a-af69-47d3-9111-62281609532d"},"outputs":[{"data":{"text/plain":["<recommenders.models.deeprec.models.sequential.sli_rec.SLI_RECModel at 0x2130339aa00>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["model_best_trained.predict(test_file, output_file)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPMZYkqYRJvrImpPUSQoA76","collapsed_sections":[],"mount_file_id":"1aN-Xq8xQ0gMEOoDsqX8RKLj3SKskndqj","name":"SLI_REC.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"}},"nbformat":4,"nbformat_minor":0}
