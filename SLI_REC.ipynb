{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8296,"status":"ok","timestamp":1649980980504,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"Sknnn2xs-AHi","outputId":"80551ecd-5a8e-4fc5-fab5-74699c879c18"},"outputs":[{"name":"stdout","output_type":"stream","text":["System version: 3.8.9 (tags/v3.8.9:a743f81, Apr  6 2021, 14:02:34) [MSC v.1928 64 bit (AMD64)]\n","Tensorflow version: 2.8.0\n"]}],"source":["import sys\n","import os\n","import logging\n","import papermill as pm\n","import scrapbook as sb\n","from tempfile import TemporaryDirectory\n","import numpy as np\n","import tensorflow.compat.v1 as tf\n","tf.get_logger().setLevel('ERROR') # only show error messages\n","\n","from recommenders.utils.timer import Timer\n","from recommenders.utils.constants import SEED\n","from recommenders.models.deeprec.deeprec_utils import (\n","    prepare_hparams\n",")\n","\n","from resources.data_preprocessing import data_preprocessing\n","# from recommenders.datasets.amazon_reviews import download_and_extract, data_preprocessing\n","from recommenders.datasets.download_utils import maybe_download\n","\n","\n","from recommenders.models.deeprec.models.sequential.sli_rec import SLI_RECModel as SeqModel\n","####  to use the other model, use one of the following lines:\n","#from recommenders.models.deeprec.models.sequential.asvd import A2SVDModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.caser import CaserModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.gru4rec import GRU4RecModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.sum import SUMModel as SeqModel\n","\n","#from recommenders.models.deeprec.models.sequential.nextitnet import NextItNetModel\n","\n","from recommenders.models.deeprec.io.sequential_iterator import SequentialIterator\n","#from recommenders.models.deeprec.io.nextitnet_iterator import NextItNetIterator\n","\n","print(\"System version: {}\".format(sys.version))\n","print(\"Tensorflow version: {}\".format(tf.__version__))"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":424,"status":"ok","timestamp":1649980983686,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"sxtfUZfP-ZWR"},"outputs":[],"source":["##  ATTENTION: change to the corresponding config file, e.g., caser.yaml for CaserModel, sum.yaml for SUMModel\n","# yaml_file = '../../recommenders/models/deeprec/config/sli_rec.yaml'  \n","yaml_file = './sli_rec.yaml'  "]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":415,"status":"ok","timestamp":1649981001550,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"_NnzhN4h_rI5"},"outputs":[],"source":["EPOCHS = 10\n","BATCH_SIZE = 400\n","RANDOM_SEED = SEED  # Set None for non-deterministic result\n","\n","data_path = os.path.join(\"resources/\")"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":419,"status":"ok","timestamp":1649981009184,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"0RAMNcI3AClc"},"outputs":[],"source":["# for test\n","train_file = os.path.join(data_path, r'train_data')\n","valid_file = os.path.join(data_path, r'valid_data')\n","test_file = os.path.join(data_path, r'test_data')\n","user_vocab = os.path.join(data_path, r'user_vocab.pkl')\n","item_vocab = os.path.join(data_path, r'item_vocab.pkl')\n","cate_vocab = os.path.join(data_path, r'cate_vocab.pkl')\n","output_file = os.path.join(data_path, r'output_sli_rec.txt')\n","\n","# reviews_name = 'json'\n","# meta_name = 'json'\n","# reviews_file = os.path.join(data_path, reviews_name)\n","# meta_file = os.path.join(data_path, meta_name)\n","train_num_ngs = 4 # number of negative instances with a positive instance for training\n","valid_num_ngs = 4 # number of negative instances with a positive instance for validation\n","test_num_ngs = 9 # number of negative instances with a positive instance for testing\n","sample_rate = 0.01 # sample a small item set for training and testing here for fast example\n","\n","input_files = [data_path, train_file, valid_file, test_file, user_vocab, item_vocab, cate_vocab]\n","\n","if not os.path.exists(train_file):\n","    # download_and_extract(reviews_name, reviews_file)\n","    # download_and_extract(meta_name, meta_file)\n","    data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs)\n","    #### uncomment this for the NextItNet model, because it does not need to unfold the user history\n","    # data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs, is_history_expanding=False)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1013,"status":"ok","timestamp":1649981039553,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"rwTMO3WEWaCu"},"outputs":[],"source":["### NOTE:  \n","### remember to use `_create_vocab(train_file, user_vocab, item_vocab, cate_vocab)` to generate the user_vocab, item_vocab and cate_vocab files, if you are using your own dataset rather than using our demo Amazon dataset.\n","hparams = prepare_hparams(yaml_file, \n","                          embed_l2=0., \n","                          layer_l2=0., \n","                          learning_rate=0.001,  # set to 0.01 if batch normalization is disable\n","                          epochs=EPOCHS,\n","                          batch_size=BATCH_SIZE,\n","                          show_step=20,\n","                          MODEL_DIR=os.path.join(data_path, \"model\", \"sli_rec/\"),\n","                          SUMMARIES_DIR=os.path.join(data_path, \"summary\", \"sli_rec/\"),\n","                          user_vocab=user_vocab,\n","                          item_vocab=item_vocab,\n","                          cate_vocab=cate_vocab,\n","                          need_sample=True,\n","                          train_num_ngs=train_num_ngs, # provides the number of negative instances for each positive instance for loss computation.\n","            )"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":420,"status":"ok","timestamp":1649981043565,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"4Rvq7gFluVPq"},"outputs":[],"source":["input_creator = SequentialIterator\n","#### uncomment this for the NextItNet model, because it needs a special data iterator for training\n","#input_creator = NextItNetIterator"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11139,"status":"ok","timestamp":1649981057379,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"VFNfgcKNuaVv","outputId":"2f195cde-2963-41ff-aa84-0a17d9a9cd3d"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\base_model.py:701: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n","  curr_hidden_nn_layer = tf.compat.v1.layers.batch_normalization(\n","C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs, training=training)\n"]}],"source":["model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n","\n","## sometimes we don't want to train a model from scratch\n","## then we can load a pre-trained model like this: \n","#model.load_model(r'your_model_path')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63766,"status":"ok","timestamp":1649981126167,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"8AQxPlk-uheU","outputId":"23ee2335-3935-437b-c4f2-0c01fee93d8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'auc': 0.5334, 'logloss': 0.6931, 'mean_mrr': 0.2906, 'ndcg@2': 0.1578, 'ndcg@4': 0.2541, 'ndcg@6': 0.3323, 'group_auc': 0.5335}\n"]}],"source":["# test_num_ngs is the number of negative lines after each positive line in your test_file\n","print(model.run_eval(test_file, num_ngs=test_num_ngs)) "]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19408573,"status":"ok","timestamp":1650000544829,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"QFKQu9rGu0jq","outputId":"68371df4-d8f1-4844-8f13-d634505f1b33"},"outputs":[{"name":"stdout","output_type":"stream","text":["step 20 , total_loss: 1.5521, data_loss: 1.5521\n","step 40 , total_loss: 1.4554, data_loss: 1.4554\n","step 60 , total_loss: 1.4642, data_loss: 1.4642\n","step 80 , total_loss: 1.3631, data_loss: 1.3631\n","step 100 , total_loss: 1.3537, data_loss: 1.3537\n","step 120 , total_loss: 1.3309, data_loss: 1.3309\n","step 140 , total_loss: 1.3341, data_loss: 1.3341\n","step 160 , total_loss: 1.3540, data_loss: 1.3540\n","step 180 , total_loss: 1.2683, data_loss: 1.2683\n","step 200 , total_loss: 1.3028, data_loss: 1.3028\n","step 220 , total_loss: 1.2759, data_loss: 1.2759\n","step 240 , total_loss: 1.3438, data_loss: 1.3438\n","step 260 , total_loss: 1.2713, data_loss: 1.2713\n","step 280 , total_loss: 1.2713, data_loss: 1.2713\n","step 300 , total_loss: 1.3057, data_loss: 1.3057\n","step 320 , total_loss: 1.2740, data_loss: 1.2740\n","step 340 , total_loss: 1.3078, data_loss: 1.3078\n","step 360 , total_loss: 1.3250, data_loss: 1.3250\n","step 380 , total_loss: 1.2559, data_loss: 1.2559\n","step 400 , total_loss: 1.1904, data_loss: 1.1904\n","step 420 , total_loss: 1.3166, data_loss: 1.3166\n","step 440 , total_loss: 1.2006, data_loss: 1.2006\n","step 460 , total_loss: 1.1927, data_loss: 1.1927\n","step 480 , total_loss: 1.2211, data_loss: 1.2211\n","step 500 , total_loss: 1.2247, data_loss: 1.2247\n","step 520 , total_loss: 1.1725, data_loss: 1.1725\n","step 540 , total_loss: 1.1623, data_loss: 1.1623\n","step 560 , total_loss: 1.2318, data_loss: 1.2318\n","step 580 , total_loss: 1.1981, data_loss: 1.1981\n","step 600 , total_loss: 1.1558, data_loss: 1.1558\n","step 620 , total_loss: 1.2675, data_loss: 1.2675\n","step 640 , total_loss: 1.2483, data_loss: 1.2483\n","step 660 , total_loss: 1.2197, data_loss: 1.2197\n","step 680 , total_loss: 1.1346, data_loss: 1.1346\n","step 700 , total_loss: 1.2047, data_loss: 1.2047\n","step 720 , total_loss: 1.2339, data_loss: 1.2339\n","step 740 , total_loss: 1.2115, data_loss: 1.2115\n","step 760 , total_loss: 1.2079, data_loss: 1.2079\n","step 780 , total_loss: 1.1807, data_loss: 1.1807\n","step 800 , total_loss: 1.2172, data_loss: 1.2172\n","step 820 , total_loss: 1.1380, data_loss: 1.1380\n","step 840 , total_loss: 1.1243, data_loss: 1.1243\n","step 860 , total_loss: 1.1323, data_loss: 1.1323\n","step 880 , total_loss: 1.1213, data_loss: 1.1213\n","step 900 , total_loss: 1.1777, data_loss: 1.1777\n","step 920 , total_loss: 1.1410, data_loss: 1.1410\n","eval valid at epoch 1: auc:0.774,logloss:0.6034,mean_mrr:0.7054,ndcg@2:0.6678,ndcg@4:0.7674,ndcg@6:0.7796,group_auc:0.7834\n","step 20 , total_loss: 1.1703, data_loss: 1.1703\n","step 40 , total_loss: 1.1111, data_loss: 1.1111\n","step 60 , total_loss: 1.0956, data_loss: 1.0956\n","step 80 , total_loss: 1.1227, data_loss: 1.1227\n","step 100 , total_loss: 1.0710, data_loss: 1.0710\n","step 120 , total_loss: 1.0970, data_loss: 1.0970\n","step 140 , total_loss: 1.0376, data_loss: 1.0376\n","step 160 , total_loss: 1.0508, data_loss: 1.0508\n","step 180 , total_loss: 0.9803, data_loss: 0.9803\n","step 200 , total_loss: 1.0220, data_loss: 1.0220\n","step 220 , total_loss: 0.9607, data_loss: 0.9607\n","step 240 , total_loss: 0.9975, data_loss: 0.9975\n","step 260 , total_loss: 0.9488, data_loss: 0.9488\n","step 280 , total_loss: 0.9961, data_loss: 0.9961\n","step 300 , total_loss: 1.0224, data_loss: 1.0224\n","step 320 , total_loss: 0.9247, data_loss: 0.9247\n","step 340 , total_loss: 0.9083, data_loss: 0.9083\n","step 360 , total_loss: 0.8941, data_loss: 0.8941\n","step 380 , total_loss: 0.9149, data_loss: 0.9149\n","step 400 , total_loss: 0.8345, data_loss: 0.8345\n","step 420 , total_loss: 0.9025, data_loss: 0.9025\n","step 440 , total_loss: 0.9219, data_loss: 0.9219\n","step 460 , total_loss: 0.8553, data_loss: 0.8553\n","step 480 , total_loss: 0.7951, data_loss: 0.7951\n","step 500 , total_loss: 0.9080, data_loss: 0.9080\n","step 520 , total_loss: 0.8353, data_loss: 0.8353\n","step 540 , total_loss: 0.9094, data_loss: 0.9094\n","step 560 , total_loss: 0.8462, data_loss: 0.8462\n","step 580 , total_loss: 0.8860, data_loss: 0.8860\n","step 600 , total_loss: 0.8305, data_loss: 0.8305\n","step 620 , total_loss: 0.8900, data_loss: 0.8900\n","step 640 , total_loss: 0.8381, data_loss: 0.8381\n","step 660 , total_loss: 0.7990, data_loss: 0.7990\n","step 680 , total_loss: 0.8918, data_loss: 0.8918\n","step 700 , total_loss: 0.7846, data_loss: 0.7846\n","step 720 , total_loss: 0.8926, data_loss: 0.8926\n","step 740 , total_loss: 0.8430, data_loss: 0.8430\n","step 760 , total_loss: 0.9088, data_loss: 0.9088\n","step 780 , total_loss: 0.8327, data_loss: 0.8327\n","step 800 , total_loss: 0.8948, data_loss: 0.8948\n","step 820 , total_loss: 0.8506, data_loss: 0.8506\n","step 840 , total_loss: 0.8009, data_loss: 0.8009\n","step 860 , total_loss: 0.8297, data_loss: 0.8297\n","step 880 , total_loss: 0.7960, data_loss: 0.7960\n","step 900 , total_loss: 0.8141, data_loss: 0.8141\n","step 920 , total_loss: 0.9263, data_loss: 0.9263\n","eval valid at epoch 2: auc:0.8869,logloss:0.4085,mean_mrr:0.8157,ndcg@2:0.8136,ndcg@4:0.861,ndcg@6:0.8629,group_auc:0.8842\n","step 20 , total_loss: 0.8716, data_loss: 0.8716\n","step 40 , total_loss: 0.8335, data_loss: 0.8335\n","step 60 , total_loss: 0.8545, data_loss: 0.8545\n","step 80 , total_loss: 0.8459, data_loss: 0.8459\n","step 100 , total_loss: 0.8192, data_loss: 0.8192\n","step 120 , total_loss: 0.8168, data_loss: 0.8168\n","step 140 , total_loss: 0.8965, data_loss: 0.8965\n","step 160 , total_loss: 0.7997, data_loss: 0.7997\n","step 180 , total_loss: 0.8366, data_loss: 0.8366\n","step 200 , total_loss: 0.7770, data_loss: 0.7770\n","step 220 , total_loss: 0.8738, data_loss: 0.8738\n","step 240 , total_loss: 0.9565, data_loss: 0.9565\n","step 260 , total_loss: 0.7959, data_loss: 0.7959\n","step 280 , total_loss: 0.8659, data_loss: 0.8659\n","step 300 , total_loss: 0.7867, data_loss: 0.7867\n","step 320 , total_loss: 0.7931, data_loss: 0.7931\n","step 340 , total_loss: 0.8492, data_loss: 0.8492\n","step 360 , total_loss: 0.8786, data_loss: 0.8786\n","step 380 , total_loss: 0.8201, data_loss: 0.8201\n","step 400 , total_loss: 0.8699, data_loss: 0.8699\n","step 420 , total_loss: 0.8193, data_loss: 0.8193\n","step 440 , total_loss: 0.8806, data_loss: 0.8806\n","step 460 , total_loss: 0.8374, data_loss: 0.8374\n","step 480 , total_loss: 0.7705, data_loss: 0.7705\n","step 500 , total_loss: 0.7775, data_loss: 0.7775\n","step 520 , total_loss: 0.8223, data_loss: 0.8223\n","step 540 , total_loss: 0.7261, data_loss: 0.7261\n","step 560 , total_loss: 0.8214, data_loss: 0.8214\n","step 580 , total_loss: 0.8170, data_loss: 0.8170\n","step 600 , total_loss: 0.8786, data_loss: 0.8786\n","step 620 , total_loss: 0.8004, data_loss: 0.8004\n","step 640 , total_loss: 0.8834, data_loss: 0.8834\n","step 660 , total_loss: 0.7504, data_loss: 0.7504\n","step 680 , total_loss: 0.8133, data_loss: 0.8133\n","step 700 , total_loss: 0.8366, data_loss: 0.8366\n","step 720 , total_loss: 0.8675, data_loss: 0.8675\n","step 740 , total_loss: 0.8163, data_loss: 0.8163\n","step 760 , total_loss: 0.7614, data_loss: 0.7614\n","step 780 , total_loss: 0.8290, data_loss: 0.8290\n","step 800 , total_loss: 0.7872, data_loss: 0.7872\n","step 820 , total_loss: 0.8109, data_loss: 0.8109\n","step 840 , total_loss: 0.8129, data_loss: 0.8129\n","step 860 , total_loss: 0.8363, data_loss: 0.8363\n","step 880 , total_loss: 0.8300, data_loss: 0.8300\n","step 900 , total_loss: 0.7964, data_loss: 0.7964\n","step 920 , total_loss: 0.7305, data_loss: 0.7305\n","eval valid at epoch 3: auc:0.8931,logloss:0.399,mean_mrr:0.8265,ndcg@2:0.8249,ndcg@4:0.8693,ndcg@6:0.8709,group_auc:0.891\n","step 20 , total_loss: 0.8576, data_loss: 0.8576\n","step 40 , total_loss: 0.7798, data_loss: 0.7798\n","step 60 , total_loss: 0.8160, data_loss: 0.8160\n","step 80 , total_loss: 0.8319, data_loss: 0.8319\n","step 100 , total_loss: 0.7880, data_loss: 0.7880\n","step 120 , total_loss: 0.8884, data_loss: 0.8884\n","step 140 , total_loss: 0.7754, data_loss: 0.7754\n","step 160 , total_loss: 0.8159, data_loss: 0.8159\n","step 180 , total_loss: 0.8783, data_loss: 0.8783\n","step 200 , total_loss: 0.8063, data_loss: 0.8063\n","step 220 , total_loss: 0.7662, data_loss: 0.7662\n","step 240 , total_loss: 0.8584, data_loss: 0.8584\n","step 260 , total_loss: 0.8497, data_loss: 0.8497\n","step 280 , total_loss: 0.7761, data_loss: 0.7761\n","step 300 , total_loss: 0.8504, data_loss: 0.8504\n","step 320 , total_loss: 0.7875, data_loss: 0.7875\n","step 340 , total_loss: 0.8097, data_loss: 0.8097\n","step 360 , total_loss: 0.7589, data_loss: 0.7589\n","step 380 , total_loss: 0.8101, data_loss: 0.8101\n","step 400 , total_loss: 0.7939, data_loss: 0.7939\n","step 420 , total_loss: 0.8010, data_loss: 0.8010\n","step 440 , total_loss: 0.8008, data_loss: 0.8008\n","step 460 , total_loss: 0.8302, data_loss: 0.8302\n","step 480 , total_loss: 0.8171, data_loss: 0.8171\n","step 500 , total_loss: 0.7497, data_loss: 0.7497\n","step 520 , total_loss: 0.8360, data_loss: 0.8360\n","step 540 , total_loss: 0.7905, data_loss: 0.7905\n","step 560 , total_loss: 0.8352, data_loss: 0.8352\n","step 580 , total_loss: 0.8277, data_loss: 0.8277\n","step 600 , total_loss: 0.7145, data_loss: 0.7145\n","step 620 , total_loss: 0.7766, data_loss: 0.7766\n","step 640 , total_loss: 0.8102, data_loss: 0.8102\n","step 660 , total_loss: 0.8240, data_loss: 0.8240\n","step 680 , total_loss: 0.8168, data_loss: 0.8168\n","step 700 , total_loss: 0.7583, data_loss: 0.7583\n","step 720 , total_loss: 0.8135, data_loss: 0.8135\n","step 740 , total_loss: 0.8648, data_loss: 0.8648\n","step 760 , total_loss: 0.7859, data_loss: 0.7859\n","step 780 , total_loss: 0.7087, data_loss: 0.7087\n","step 800 , total_loss: 0.8161, data_loss: 0.8161\n","step 820 , total_loss: 0.7934, data_loss: 0.7934\n","step 840 , total_loss: 0.8500, data_loss: 0.8500\n","step 860 , total_loss: 0.7310, data_loss: 0.7310\n","step 880 , total_loss: 0.7388, data_loss: 0.7388\n","step 900 , total_loss: 0.8699, data_loss: 0.8699\n","step 920 , total_loss: 0.8000, data_loss: 0.8000\n","eval valid at epoch 4: auc:0.8943,logloss:0.3944,mean_mrr:0.829,ndcg@2:0.8276,ndcg@4:0.8714,ndcg@6:0.8728,group_auc:0.893\n","step 20 , total_loss: 0.7750, data_loss: 0.7750\n","step 40 , total_loss: 0.7314, data_loss: 0.7314\n","step 60 , total_loss: 0.7628, data_loss: 0.7628\n","step 80 , total_loss: 0.8138, data_loss: 0.8138\n","step 100 , total_loss: 0.7588, data_loss: 0.7588\n","step 120 , total_loss: 0.8839, data_loss: 0.8839\n","step 140 , total_loss: 0.7258, data_loss: 0.7258\n","step 160 , total_loss: 0.7498, data_loss: 0.7498\n","step 180 , total_loss: 0.7732, data_loss: 0.7732\n","step 200 , total_loss: 0.8095, data_loss: 0.8095\n","step 220 , total_loss: 0.7607, data_loss: 0.7607\n","step 240 , total_loss: 0.8488, data_loss: 0.8488\n","step 260 , total_loss: 0.7948, data_loss: 0.7948\n","step 280 , total_loss: 0.7613, data_loss: 0.7613\n","step 300 , total_loss: 0.7723, data_loss: 0.7723\n","step 320 , total_loss: 0.8154, data_loss: 0.8154\n","step 340 , total_loss: 0.8009, data_loss: 0.8009\n","step 360 , total_loss: 0.8045, data_loss: 0.8045\n","step 380 , total_loss: 0.8185, data_loss: 0.8185\n","step 400 , total_loss: 0.7488, data_loss: 0.7488\n","step 420 , total_loss: 0.7354, data_loss: 0.7354\n","step 440 , total_loss: 0.7972, data_loss: 0.7972\n","step 460 , total_loss: 0.8049, data_loss: 0.8049\n","step 480 , total_loss: 0.7918, data_loss: 0.7918\n","step 500 , total_loss: 0.7775, data_loss: 0.7775\n","step 520 , total_loss: 0.7126, data_loss: 0.7126\n","step 540 , total_loss: 0.8025, data_loss: 0.8025\n","step 560 , total_loss: 0.7191, data_loss: 0.7191\n","step 580 , total_loss: 0.7770, data_loss: 0.7770\n","step 600 , total_loss: 0.7929, data_loss: 0.7929\n","step 620 , total_loss: 0.7550, data_loss: 0.7550\n","step 640 , total_loss: 0.7563, data_loss: 0.7563\n","step 660 , total_loss: 0.8680, data_loss: 0.8680\n","step 680 , total_loss: 0.7715, data_loss: 0.7715\n","step 700 , total_loss: 0.7832, data_loss: 0.7832\n","step 720 , total_loss: 0.7429, data_loss: 0.7429\n","step 740 , total_loss: 0.7530, data_loss: 0.7530\n","step 760 , total_loss: 0.8159, data_loss: 0.8159\n","step 780 , total_loss: 0.7584, data_loss: 0.7584\n","step 800 , total_loss: 0.7984, data_loss: 0.7984\n","step 820 , total_loss: 0.8084, data_loss: 0.8084\n","step 840 , total_loss: 0.8451, data_loss: 0.8451\n","step 860 , total_loss: 0.7826, data_loss: 0.7826\n","step 880 , total_loss: 0.8279, data_loss: 0.8279\n","step 900 , total_loss: 0.7775, data_loss: 0.7775\n","step 920 , total_loss: 0.7328, data_loss: 0.7328\n","eval valid at epoch 5: auc:0.8973,logloss:0.4166,mean_mrr:0.833,ndcg@2:0.8326,ndcg@4:0.8744,ndcg@6:0.8758,group_auc:0.8961\n","step 20 , total_loss: 0.7876, data_loss: 0.7876\n","step 40 , total_loss: 0.8073, data_loss: 0.8073\n","step 60 , total_loss: 0.8387, data_loss: 0.8387\n","step 80 , total_loss: 0.8119, data_loss: 0.8119\n","step 100 , total_loss: 0.8292, data_loss: 0.8292\n","step 120 , total_loss: 0.7623, data_loss: 0.7623\n","step 140 , total_loss: 0.7932, data_loss: 0.7932\n","step 160 , total_loss: 0.7534, data_loss: 0.7534\n","step 180 , total_loss: 0.7330, data_loss: 0.7330\n","step 200 , total_loss: 0.7655, data_loss: 0.7655\n","step 220 , total_loss: 0.7573, data_loss: 0.7573\n","step 240 , total_loss: 0.7293, data_loss: 0.7293\n","step 260 , total_loss: 0.7972, data_loss: 0.7972\n","step 280 , total_loss: 0.7439, data_loss: 0.7439\n","step 300 , total_loss: 0.7464, data_loss: 0.7464\n","step 320 , total_loss: 0.7264, data_loss: 0.7264\n","step 340 , total_loss: 0.7788, data_loss: 0.7788\n","step 360 , total_loss: 0.8074, data_loss: 0.8074\n","step 380 , total_loss: 0.8104, data_loss: 0.8104\n","step 400 , total_loss: 0.7756, data_loss: 0.7756\n","step 420 , total_loss: 0.7527, data_loss: 0.7527\n","step 440 , total_loss: 0.7677, data_loss: 0.7677\n","step 460 , total_loss: 0.7509, data_loss: 0.7509\n","step 480 , total_loss: 0.8159, data_loss: 0.8159\n","step 500 , total_loss: 0.7659, data_loss: 0.7659\n","step 520 , total_loss: 0.7290, data_loss: 0.7290\n","step 540 , total_loss: 0.7756, data_loss: 0.7756\n","step 560 , total_loss: 0.7368, data_loss: 0.7368\n","step 580 , total_loss: 0.8436, data_loss: 0.8436\n","step 600 , total_loss: 0.7575, data_loss: 0.7575\n","step 620 , total_loss: 0.7399, data_loss: 0.7399\n","step 640 , total_loss: 0.7531, data_loss: 0.7531\n","step 660 , total_loss: 0.8055, data_loss: 0.8055\n","step 680 , total_loss: 0.7534, data_loss: 0.7534\n","step 700 , total_loss: 0.7134, data_loss: 0.7134\n","step 720 , total_loss: 0.7881, data_loss: 0.7881\n","step 740 , total_loss: 0.7588, data_loss: 0.7588\n","step 760 , total_loss: 0.7805, data_loss: 0.7805\n","step 780 , total_loss: 0.7516, data_loss: 0.7516\n","step 800 , total_loss: 0.7869, data_loss: 0.7869\n","step 820 , total_loss: 0.7419, data_loss: 0.7419\n","step 840 , total_loss: 0.7079, data_loss: 0.7079\n","step 860 , total_loss: 0.7608, data_loss: 0.7608\n","step 880 , total_loss: 0.7838, data_loss: 0.7838\n","step 900 , total_loss: 0.7580, data_loss: 0.7580\n","step 920 , total_loss: 0.7831, data_loss: 0.7831\n","eval valid at epoch 6: auc:0.8977,logloss:0.4201,mean_mrr:0.8349,ndcg@2:0.8349,ndcg@4:0.876,ndcg@6:0.8773,group_auc:0.8974\n","step 20 , total_loss: 0.7858, data_loss: 0.7858\n","step 40 , total_loss: 0.7783, data_loss: 0.7783\n","step 60 , total_loss: 0.7783, data_loss: 0.7783\n","step 80 , total_loss: 0.7536, data_loss: 0.7536\n","step 100 , total_loss: 0.7820, data_loss: 0.7820\n","step 120 , total_loss: 0.7674, data_loss: 0.7674\n","step 140 , total_loss: 0.7748, data_loss: 0.7748\n","step 160 , total_loss: 0.7203, data_loss: 0.7203\n","step 180 , total_loss: 0.7584, data_loss: 0.7584\n","step 200 , total_loss: 0.7963, data_loss: 0.7963\n","step 220 , total_loss: 0.7713, data_loss: 0.7713\n","step 240 , total_loss: 0.7431, data_loss: 0.7431\n","step 260 , total_loss: 0.7286, data_loss: 0.7286\n","step 280 , total_loss: 0.7181, data_loss: 0.7181\n","step 300 , total_loss: 0.7386, data_loss: 0.7386\n","step 320 , total_loss: 0.7742, data_loss: 0.7742\n","step 340 , total_loss: 0.7401, data_loss: 0.7401\n","step 360 , total_loss: 0.7530, data_loss: 0.7530\n","step 380 , total_loss: 0.7170, data_loss: 0.7170\n","step 400 , total_loss: 0.7925, data_loss: 0.7925\n","step 420 , total_loss: 0.7168, data_loss: 0.7168\n","step 440 , total_loss: 0.7827, data_loss: 0.7827\n","step 460 , total_loss: 0.7766, data_loss: 0.7766\n","step 480 , total_loss: 0.8026, data_loss: 0.8026\n","step 500 , total_loss: 0.8168, data_loss: 0.8168\n","step 520 , total_loss: 0.7497, data_loss: 0.7497\n","step 540 , total_loss: 0.7654, data_loss: 0.7654\n","step 560 , total_loss: 0.7109, data_loss: 0.7109\n","step 580 , total_loss: 0.7305, data_loss: 0.7305\n","step 600 , total_loss: 0.7693, data_loss: 0.7693\n","step 620 , total_loss: 0.8141, data_loss: 0.8141\n","step 640 , total_loss: 0.7932, data_loss: 0.7932\n","step 660 , total_loss: 0.7756, data_loss: 0.7756\n","step 680 , total_loss: 0.7554, data_loss: 0.7554\n","step 700 , total_loss: 0.7427, data_loss: 0.7427\n","step 720 , total_loss: 0.7519, data_loss: 0.7519\n","step 740 , total_loss: 0.7545, data_loss: 0.7545\n","step 760 , total_loss: 0.7429, data_loss: 0.7429\n","step 780 , total_loss: 0.7782, data_loss: 0.7782\n","step 800 , total_loss: 0.7304, data_loss: 0.7304\n","step 820 , total_loss: 0.7055, data_loss: 0.7055\n","step 840 , total_loss: 0.8035, data_loss: 0.8035\n","step 860 , total_loss: 0.8368, data_loss: 0.8368\n","step 880 , total_loss: 0.7734, data_loss: 0.7734\n","step 900 , total_loss: 0.7864, data_loss: 0.7864\n","step 920 , total_loss: 0.7683, data_loss: 0.7683\n","eval valid at epoch 7: auc:0.898,logloss:0.4324,mean_mrr:0.8362,ndcg@2:0.8363,ndcg@4:0.8767,ndcg@6:0.8782,group_auc:0.898\n","step 20 , total_loss: 0.8395, data_loss: 0.8395\n","step 40 , total_loss: 0.8028, data_loss: 0.8028\n","step 60 , total_loss: 0.7750, data_loss: 0.7750\n","step 80 , total_loss: 0.7855, data_loss: 0.7855\n","step 100 , total_loss: 0.7760, data_loss: 0.7760\n","step 120 , total_loss: 0.7619, data_loss: 0.7619\n","step 140 , total_loss: 0.7314, data_loss: 0.7314\n","step 160 , total_loss: 0.7588, data_loss: 0.7588\n","step 180 , total_loss: 0.7804, data_loss: 0.7804\n","step 200 , total_loss: 0.7960, data_loss: 0.7960\n","step 220 , total_loss: 0.7615, data_loss: 0.7615\n","step 240 , total_loss: 0.7351, data_loss: 0.7351\n","step 260 , total_loss: 0.7711, data_loss: 0.7711\n","step 280 , total_loss: 0.7303, data_loss: 0.7303\n","step 300 , total_loss: 0.7668, data_loss: 0.7668\n","step 320 , total_loss: 0.7750, data_loss: 0.7750\n","step 340 , total_loss: 0.8098, data_loss: 0.8098\n","step 360 , total_loss: 0.8604, data_loss: 0.8604\n","step 380 , total_loss: 0.7769, data_loss: 0.7769\n","step 400 , total_loss: 0.7900, data_loss: 0.7900\n","step 420 , total_loss: 0.6389, data_loss: 0.6389\n","step 440 , total_loss: 0.7529, data_loss: 0.7529\n","step 460 , total_loss: 0.7499, data_loss: 0.7499\n","step 480 , total_loss: 0.7567, data_loss: 0.7567\n","step 500 , total_loss: 0.7443, data_loss: 0.7443\n","step 520 , total_loss: 0.7417, data_loss: 0.7417\n","step 540 , total_loss: 0.7546, data_loss: 0.7546\n","step 560 , total_loss: 0.7052, data_loss: 0.7052\n","step 580 , total_loss: 0.7312, data_loss: 0.7312\n","step 600 , total_loss: 0.8005, data_loss: 0.8005\n","step 620 , total_loss: 0.7578, data_loss: 0.7578\n","step 640 , total_loss: 0.8095, data_loss: 0.8095\n","step 660 , total_loss: 0.8191, data_loss: 0.8191\n","step 680 , total_loss: 0.6708, data_loss: 0.6708\n","step 700 , total_loss: 0.7368, data_loss: 0.7368\n","step 720 , total_loss: 0.7316, data_loss: 0.7316\n","step 740 , total_loss: 0.7845, data_loss: 0.7845\n","step 760 , total_loss: 0.7620, data_loss: 0.7620\n","step 780 , total_loss: 0.7440, data_loss: 0.7440\n","step 800 , total_loss: 0.7496, data_loss: 0.7496\n","step 820 , total_loss: 0.7868, data_loss: 0.7868\n","step 840 , total_loss: 0.7328, data_loss: 0.7328\n","step 860 , total_loss: 0.7345, data_loss: 0.7345\n","step 880 , total_loss: 0.7600, data_loss: 0.7600\n","step 900 , total_loss: 0.7375, data_loss: 0.7375\n","step 920 , total_loss: 0.7938, data_loss: 0.7938\n","eval valid at epoch 8: auc:0.8988,logloss:0.4492,mean_mrr:0.8352,ndcg@2:0.8346,ndcg@4:0.876,ndcg@6:0.8774,group_auc:0.8975\n","step 20 , total_loss: 0.6897, data_loss: 0.6897\n","step 40 , total_loss: 0.7740, data_loss: 0.7740\n","step 60 , total_loss: 0.8552, data_loss: 0.8552\n","step 80 , total_loss: 0.7602, data_loss: 0.7602\n","step 100 , total_loss: 0.7097, data_loss: 0.7097\n","step 120 , total_loss: 0.7256, data_loss: 0.7256\n","step 140 , total_loss: 0.7427, data_loss: 0.7427\n","step 160 , total_loss: 0.6836, data_loss: 0.6836\n","step 180 , total_loss: 0.7711, data_loss: 0.7711\n","step 200 , total_loss: 0.7669, data_loss: 0.7669\n","step 220 , total_loss: 0.7717, data_loss: 0.7717\n","step 240 , total_loss: 0.7409, data_loss: 0.7409\n","step 260 , total_loss: 0.7550, data_loss: 0.7550\n","step 280 , total_loss: 0.7633, data_loss: 0.7633\n","step 300 , total_loss: 0.7016, data_loss: 0.7016\n","step 320 , total_loss: 0.6883, data_loss: 0.6883\n","step 340 , total_loss: 0.8424, data_loss: 0.8424\n","step 360 , total_loss: 0.7969, data_loss: 0.7969\n","step 380 , total_loss: 0.7449, data_loss: 0.7449\n","step 400 , total_loss: 0.7700, data_loss: 0.7700\n","step 420 , total_loss: 0.8025, data_loss: 0.8025\n","step 440 , total_loss: 0.7776, data_loss: 0.7776\n","step 460 , total_loss: 0.7687, data_loss: 0.7687\n","step 480 , total_loss: 0.7540, data_loss: 0.7540\n","step 500 , total_loss: 0.7668, data_loss: 0.7668\n","step 520 , total_loss: 0.7733, data_loss: 0.7733\n","step 540 , total_loss: 0.7655, data_loss: 0.7655\n","step 560 , total_loss: 0.7045, data_loss: 0.7045\n","step 580 , total_loss: 0.7843, data_loss: 0.7843\n","step 600 , total_loss: 0.7167, data_loss: 0.7167\n","step 620 , total_loss: 0.7439, data_loss: 0.7439\n","step 640 , total_loss: 0.8001, data_loss: 0.8001\n","step 660 , total_loss: 0.7599, data_loss: 0.7599\n","step 680 , total_loss: 0.7384, data_loss: 0.7384\n","step 700 , total_loss: 0.7018, data_loss: 0.7018\n","step 720 , total_loss: 0.7442, data_loss: 0.7442\n","step 740 , total_loss: 0.7208, data_loss: 0.7208\n","step 760 , total_loss: 0.8024, data_loss: 0.8024\n","step 780 , total_loss: 0.8050, data_loss: 0.8050\n","step 800 , total_loss: 0.6838, data_loss: 0.6838\n","step 820 , total_loss: 0.8365, data_loss: 0.8365\n","step 840 , total_loss: 0.7565, data_loss: 0.7565\n","step 860 , total_loss: 0.7035, data_loss: 0.7035\n","step 880 , total_loss: 0.7170, data_loss: 0.7170\n","step 900 , total_loss: 0.6578, data_loss: 0.6578\n","step 920 , total_loss: 0.9010, data_loss: 0.9010\n","eval valid at epoch 9: auc:0.8998,logloss:0.4538,mean_mrr:0.8369,ndcg@2:0.8364,ndcg@4:0.8773,ndcg@6:0.8787,group_auc:0.8984\n","step 20 , total_loss: 0.7346, data_loss: 0.7346\n","step 40 , total_loss: 0.7479, data_loss: 0.7479\n","step 60 , total_loss: 0.6905, data_loss: 0.6905\n","step 80 , total_loss: 0.7556, data_loss: 0.7556\n","step 100 , total_loss: 0.7272, data_loss: 0.7272\n","step 120 , total_loss: 0.7749, data_loss: 0.7749\n","step 140 , total_loss: 0.8200, data_loss: 0.8200\n","step 160 , total_loss: 0.7617, data_loss: 0.7617\n","step 180 , total_loss: 0.7535, data_loss: 0.7535\n","step 200 , total_loss: 0.6778, data_loss: 0.6778\n","step 220 , total_loss: 0.7944, data_loss: 0.7944\n","step 240 , total_loss: 0.7454, data_loss: 0.7454\n","step 260 , total_loss: 0.7310, data_loss: 0.7310\n","step 280 , total_loss: 0.7350, data_loss: 0.7350\n","step 300 , total_loss: 0.7740, data_loss: 0.7740\n","step 320 , total_loss: 0.7756, data_loss: 0.7756\n","step 340 , total_loss: 0.7369, data_loss: 0.7369\n","step 360 , total_loss: 0.7587, data_loss: 0.7587\n","step 380 , total_loss: 0.6865, data_loss: 0.6865\n","step 400 , total_loss: 0.7763, data_loss: 0.7763\n","step 420 , total_loss: 0.7657, data_loss: 0.7657\n","step 440 , total_loss: 0.6708, data_loss: 0.6708\n","step 460 , total_loss: 0.6694, data_loss: 0.6694\n","step 480 , total_loss: 0.8439, data_loss: 0.8439\n","step 500 , total_loss: 0.7914, data_loss: 0.7914\n","step 520 , total_loss: 0.7562, data_loss: 0.7562\n","step 540 , total_loss: 0.7571, data_loss: 0.7571\n","step 560 , total_loss: 0.7398, data_loss: 0.7398\n","step 580 , total_loss: 0.7160, data_loss: 0.7160\n","step 600 , total_loss: 0.7326, data_loss: 0.7326\n","step 620 , total_loss: 0.6696, data_loss: 0.6696\n","step 640 , total_loss: 0.6992, data_loss: 0.6992\n","step 660 , total_loss: 0.7064, data_loss: 0.7064\n","step 680 , total_loss: 0.7584, data_loss: 0.7584\n","step 700 , total_loss: 0.7438, data_loss: 0.7438\n","step 720 , total_loss: 0.8195, data_loss: 0.8195\n","step 740 , total_loss: 0.7133, data_loss: 0.7133\n","step 760 , total_loss: 0.8237, data_loss: 0.8237\n","step 780 , total_loss: 0.7694, data_loss: 0.7694\n","step 800 , total_loss: 0.7649, data_loss: 0.7649\n","step 820 , total_loss: 0.7095, data_loss: 0.7095\n","step 840 , total_loss: 0.6892, data_loss: 0.6892\n","step 860 , total_loss: 0.8103, data_loss: 0.8103\n","step 880 , total_loss: 0.8110, data_loss: 0.8110\n","step 900 , total_loss: 0.7394, data_loss: 0.7394\n","step 920 , total_loss: 0.7326, data_loss: 0.7326\n","eval valid at epoch 10: auc:0.9004,logloss:0.4914,mean_mrr:0.8376,ndcg@2:0.8372,ndcg@4:0.8781,ndcg@6:0.8793,group_auc:0.8994\n","[(1, {'auc': 0.774, 'logloss': 0.6034, 'mean_mrr': 0.7054, 'ndcg@2': 0.6678, 'ndcg@4': 0.7674, 'ndcg@6': 0.7796, 'group_auc': 0.7834}), (2, {'auc': 0.8869, 'logloss': 0.4085, 'mean_mrr': 0.8157, 'ndcg@2': 0.8136, 'ndcg@4': 0.861, 'ndcg@6': 0.8629, 'group_auc': 0.8842}), (3, {'auc': 0.8931, 'logloss': 0.399, 'mean_mrr': 0.8265, 'ndcg@2': 0.8249, 'ndcg@4': 0.8693, 'ndcg@6': 0.8709, 'group_auc': 0.891}), (4, {'auc': 0.8943, 'logloss': 0.3944, 'mean_mrr': 0.829, 'ndcg@2': 0.8276, 'ndcg@4': 0.8714, 'ndcg@6': 0.8728, 'group_auc': 0.893}), (5, {'auc': 0.8973, 'logloss': 0.4166, 'mean_mrr': 0.833, 'ndcg@2': 0.8326, 'ndcg@4': 0.8744, 'ndcg@6': 0.8758, 'group_auc': 0.8961}), (6, {'auc': 0.8977, 'logloss': 0.4201, 'mean_mrr': 0.8349, 'ndcg@2': 0.8349, 'ndcg@4': 0.876, 'ndcg@6': 0.8773, 'group_auc': 0.8974}), (7, {'auc': 0.898, 'logloss': 0.4324, 'mean_mrr': 0.8362, 'ndcg@2': 0.8363, 'ndcg@4': 0.8767, 'ndcg@6': 0.8782, 'group_auc': 0.898}), (8, {'auc': 0.8988, 'logloss': 0.4492, 'mean_mrr': 0.8352, 'ndcg@2': 0.8346, 'ndcg@4': 0.876, 'ndcg@6': 0.8774, 'group_auc': 0.8975}), (9, {'auc': 0.8998, 'logloss': 0.4538, 'mean_mrr': 0.8369, 'ndcg@2': 0.8364, 'ndcg@4': 0.8773, 'ndcg@6': 0.8787, 'group_auc': 0.8984}), (10, {'auc': 0.9004, 'logloss': 0.4914, 'mean_mrr': 0.8376, 'ndcg@2': 0.8372, 'ndcg@4': 0.8781, 'ndcg@6': 0.8793, 'group_auc': 0.8994})]\n","best epoch: 10\n","Time cost for training is 265.83 mins\n"]}],"source":["with Timer() as train_time:\n","    model = model.fit(train_file, valid_file, valid_num_ngs=valid_num_ngs) \n","\n","# valid_num_ngs is the number of negative lines after each positive line in your valid_file \n","# we will evaluate the performance of model on valid_file every epoch\n","print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53342,"status":"ok","timestamp":1650000644460,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"gmm3DPjbiY9N","outputId":"8d589301-91a9-446f-99dc-ebcff115c0a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'auc': 0.9003, 'logloss': 0.5098, 'mean_mrr': 0.7183, 'ndcg@2': 0.683, 'ndcg@4': 0.7684, 'ndcg@6': 0.7852, 'group_auc': 0.8993}\n"]}],"source":["res_syn = model.run_eval(test_file, num_ngs=test_num_ngs)\n","print(res_syn)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":428,"status":"ok","timestamp":1650000657669,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"VB7MBFNkjl5e","outputId":"976697e7-e35e-416d-9e5a-436c9032db89"},"outputs":[{"data":{"application/scrapbook.scrap.json+json":{"data":{"auc":0.9003,"group_auc":0.8993,"logloss":0.5098,"mean_mrr":0.7183,"ndcg@2":0.683,"ndcg@4":0.7684,"ndcg@6":0.7852},"encoder":"json","name":"res_syn","version":1}},"metadata":{"scrapbook":{"data":true,"display":false,"name":"res_syn"}},"output_type":"display_data"}],"source":["sb.glue(\"res_syn\", res_syn)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":35776,"status":"ok","timestamp":1650000695071,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"h2uxYGfFjpL9"},"outputs":[],"source":["model = model.predict(test_file, output_file)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7124,"status":"ok","timestamp":1650000712820,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"wGZ26pt-ujeo","outputId":"5e57cd48-8e85-463f-e278-ec02afe67ef6"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\base_model.py:701: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n","  curr_hidden_nn_layer = tf.compat.v1.layers.batch_normalization(\n","C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs, training=training)\n"]},{"name":"stdout","output_type":"stream","text":["loading saved model in resources/model\\sli_rec/best_model\n"]}],"source":["model_best_trained = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n","path_best_trained = os.path.join(hparams.MODEL_DIR, \"best_model\")\n","print('loading saved model in {0}'.format(path_best_trained))\n","model_best_trained.load_model(path_best_trained)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75245,"status":"ok","timestamp":1650000790316,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"fKtBHxlGu5-K","outputId":"d3fdcadf-665d-4120-c4fa-78af49376d1b"},"outputs":[{"data":{"text/plain":["{'auc': 0.9003,\n"," 'logloss': 0.5098,\n"," 'mean_mrr': 0.7183,\n"," 'ndcg@2': 0.683,\n"," 'ndcg@4': 0.7684,\n"," 'ndcg@6': 0.7852,\n"," 'group_auc': 0.8993}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["model_best_trained.run_eval(test_file, num_ngs=test_num_ngs)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48189,"status":"ok","timestamp":1650000881133,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"XH7L5VOQvARx","outputId":"048eb05a-af69-47d3-9111-62281609532d"},"outputs":[{"data":{"text/plain":["<recommenders.models.deeprec.models.sequential.sli_rec.SLI_RECModel at 0x1b57fca2f70>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model_best_trained.predict(test_file, output_file)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPMZYkqYRJvrImpPUSQoA76","collapsed_sections":[],"mount_file_id":"1aN-Xq8xQ0gMEOoDsqX8RKLj3SKskndqj","name":"SLI_REC.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"}},"nbformat":4,"nbformat_minor":0}
