{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8296,"status":"ok","timestamp":1649980980504,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"Sknnn2xs-AHi","outputId":"80551ecd-5a8e-4fc5-fab5-74699c879c18"},"outputs":[{"name":"stdout","output_type":"stream","text":["System version: 3.8.9 (tags/v3.8.9:a743f81, Apr  6 2021, 14:02:34) [MSC v.1928 64 bit (AMD64)]\n","Tensorflow version: 2.8.0\n"]}],"source":["import sys\n","import os\n","import logging\n","import papermill as pm\n","import scrapbook as sb\n","from tempfile import TemporaryDirectory\n","import numpy as np\n","import tensorflow.compat.v1 as tf\n","tf.get_logger().setLevel('ERROR') # only show error messages\n","\n","from recommenders.utils.timer import Timer\n","from recommenders.utils.constants import SEED\n","from recommenders.models.deeprec.deeprec_utils import (\n","    prepare_hparams\n",")\n","\n","from resources.data_preprocessing2 import data_preprocessing\n","# from recommenders.datasets.amazon_reviews import download_and_extract, data_preprocessing\n","from recommenders.datasets.download_utils import maybe_download\n","\n","\n","from recommenders.models.deeprec.models.sequential.sli_rec import SLI_RECModel as SeqModel\n","####  to use the other model, use one of the following lines:\n","#from recommenders.models.deeprec.models.sequential.asvd import A2SVDModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.caser import CaserModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.gru4rec import GRU4RecModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.sum import SUMModel as SeqModel\n","\n","#from recommenders.models.deeprec.models.sequential.nextitnet import NextItNetModel\n","\n","from recommenders.models.deeprec.io.sequential_iterator import SequentialIterator\n","#from recommenders.models.deeprec.io.nextitnet_iterator import NextItNetIterator\n","\n","print(\"System version: {}\".format(sys.version))\n","print(\"Tensorflow version: {}\".format(tf.__version__))"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":424,"status":"ok","timestamp":1649980983686,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"sxtfUZfP-ZWR"},"outputs":[],"source":["##  ATTENTION: change to the corresponding config file, e.g., caser.yaml for CaserModel, sum.yaml for SUMModel\n","# yaml_file = '../../recommenders/models/deeprec/config/sli_rec.yaml'  \n","yaml_file = './sli_rec.yaml'  "]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":415,"status":"ok","timestamp":1649981001550,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"_NnzhN4h_rI5"},"outputs":[],"source":["EPOCHS = 10\n","BATCH_SIZE = 400\n","RANDOM_SEED = SEED  # Set None for non-deterministic result\n","\n","data_path = os.path.join(\"resources/\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":419,"status":"ok","timestamp":1649981009184,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"0RAMNcI3AClc"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\dtypes\\common.py:1776: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  npdtype = np.dtype(dtype)\n"]},{"name":"stdout","output_type":"stream","text":["9303\n"]}],"source":["# for test\n","train_file = os.path.join(data_path, r'train_data')\n","valid_file = os.path.join(data_path, r'valid_data')\n","test_file = os.path.join(data_path, r'test_data')\n","user_vocab = os.path.join(data_path, r'user_vocab.pkl')\n","item_vocab = os.path.join(data_path, r'item_vocab.pkl')\n","cate_vocab = os.path.join(data_path, r'cate_vocab.pkl')\n","output_file = os.path.join(data_path, r'output_sli_rec.txt')\n","\n","# reviews_name = 'json'\n","# meta_name = 'json'\n","# reviews_file = os.path.join(data_path, reviews_name)\n","# meta_file = os.path.join(data_path, meta_name)\n","train_num_ngs = 4 # number of negative instances with a positive instance for training\n","valid_num_ngs = 4 # number of negative instances with a positive instance for validation\n","test_num_ngs = 9 # number of negative instances with a positive instance for testing\n","sample_rate = 0.01 # sample a small item set for training and testing here for fast example\n","\n","input_files = [data_path, train_file, valid_file, test_file, user_vocab, item_vocab, cate_vocab]\n","\n","if not os.path.exists(train_file):\n","    # download_and_extract(reviews_name, reviews_file)\n","    # download_and_extract(meta_name, meta_file)\n","    data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs)\n","    #### uncomment this for the NextItNet model, because it does not need to unfold the user history\n","    # data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs, is_history_expanding=False)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1013,"status":"ok","timestamp":1649981039553,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"rwTMO3WEWaCu"},"outputs":[],"source":["### NOTE:  \n","### remember to use `_create_vocab(train_file, user_vocab, item_vocab, cate_vocab)` to generate the user_vocab, item_vocab and cate_vocab files, if you are using your own dataset rather than using our demo Amazon dataset.\n","hparams = prepare_hparams(yaml_file, \n","                          embed_l2=0., \n","                          layer_l2=0., \n","                          learning_rate=0.001,  # set to 0.01 if batch normalization is disable\n","                          epochs=EPOCHS,\n","                          batch_size=BATCH_SIZE,\n","                          show_step=20,\n","                          MODEL_DIR=os.path.join(data_path, \"model\", \"sli_rec/\"),\n","                          SUMMARIES_DIR=os.path.join(data_path, \"summary\", \"sli_rec/\"),\n","                          user_vocab=user_vocab,\n","                          item_vocab=item_vocab,\n","                          cate_vocab=cate_vocab,\n","                          need_sample=True,\n","                          train_num_ngs=train_num_ngs, # provides the number of negative instances for each positive instance for loss computation.\n","            )"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":420,"status":"ok","timestamp":1649981043565,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"4Rvq7gFluVPq"},"outputs":[],"source":["input_creator = SequentialIterator\n","#### uncomment this for the NextItNet model, because it needs a special data iterator for training\n","#input_creator = NextItNetIterator"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11139,"status":"ok","timestamp":1649981057379,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"VFNfgcKNuaVv","outputId":"2f195cde-2963-41ff-aa84-0a17d9a9cd3d"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\base_model.py:701: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n","  curr_hidden_nn_layer = tf.compat.v1.layers.batch_normalization(\n","C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs, training=training)\n"]}],"source":["model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n","\n","## sometimes we don't want to train a model from scratch\n","## then we can load a pre-trained model like this: \n","#model.load_model(r'your_model_path')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63766,"status":"ok","timestamp":1649981126167,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"8AQxPlk-uheU","outputId":"23ee2335-3935-437b-c4f2-0c01fee93d8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'auc': 0.5103, 'logloss': 0.6931, 'mean_mrr': 0.2795, 'ndcg@2': 0.1533, 'ndcg@4': 0.2121, 'ndcg@6': 0.3234, 'group_auc': 0.5104}\n"]}],"source":["# test_num_ngs is the number of negative lines after each positive line in your test_file\n","print(model.run_eval(test_file, num_ngs=test_num_ngs)) "]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19408573,"status":"ok","timestamp":1650000544829,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"QFKQu9rGu0jq","outputId":"68371df4-d8f1-4844-8f13-d634505f1b33"},"outputs":[{"name":"stdout","output_type":"stream","text":["step 20 , total_loss: 1.4722, data_loss: 1.4722\n","step 40 , total_loss: 1.4511, data_loss: 1.4511\n","step 60 , total_loss: 1.3487, data_loss: 1.3487\n","step 80 , total_loss: 1.3341, data_loss: 1.3341\n","step 100 , total_loss: 1.3651, data_loss: 1.3651\n","step 120 , total_loss: 1.2440, data_loss: 1.2440\n","step 140 , total_loss: 1.3374, data_loss: 1.3374\n","step 160 , total_loss: 1.2832, data_loss: 1.2832\n","step 180 , total_loss: 1.3531, data_loss: 1.3531\n","step 200 , total_loss: 1.2372, data_loss: 1.2372\n","step 220 , total_loss: 1.2385, data_loss: 1.2385\n","step 240 , total_loss: 1.2814, data_loss: 1.2814\n","step 260 , total_loss: 1.2386, data_loss: 1.2386\n","step 280 , total_loss: 1.2502, data_loss: 1.2502\n","step 300 , total_loss: 1.2643, data_loss: 1.2643\n","step 320 , total_loss: 1.2367, data_loss: 1.2367\n","step 340 , total_loss: 1.1630, data_loss: 1.1630\n","step 360 , total_loss: 1.1675, data_loss: 1.1675\n","step 380 , total_loss: 1.1339, data_loss: 1.1339\n","step 400 , total_loss: 1.1547, data_loss: 1.1547\n","step 420 , total_loss: 1.1581, data_loss: 1.1581\n","step 440 , total_loss: 1.2362, data_loss: 1.2362\n","step 460 , total_loss: 1.2192, data_loss: 1.2192\n","step 480 , total_loss: 1.2499, data_loss: 1.2499\n","step 500 , total_loss: 1.1784, data_loss: 1.1784\n","step 520 , total_loss: 1.2483, data_loss: 1.2483\n","step 540 , total_loss: 1.1975, data_loss: 1.1975\n","step 560 , total_loss: 1.1695, data_loss: 1.1695\n","step 580 , total_loss: 1.2535, data_loss: 1.2535\n","step 600 , total_loss: 1.1207, data_loss: 1.1207\n","step 620 , total_loss: 1.0969, data_loss: 1.0969\n","step 640 , total_loss: 1.1455, data_loss: 1.1455\n","step 660 , total_loss: 1.1782, data_loss: 1.1782\n","step 680 , total_loss: 1.1419, data_loss: 1.1419\n","step 700 , total_loss: 1.1430, data_loss: 1.1430\n","step 720 , total_loss: 1.0893, data_loss: 1.0893\n","step 740 , total_loss: 1.1707, data_loss: 1.1707\n","step 760 , total_loss: 1.1509, data_loss: 1.1509\n","step 780 , total_loss: 1.1049, data_loss: 1.1049\n","eval valid at epoch 1: auc:0.7755,logloss:0.5693,mean_mrr:0.6943,ndcg@2:0.6573,ndcg@4:0.7629,ndcg@6:0.7715,group_auc:0.7816\n","step 20 , total_loss: 1.2019, data_loss: 1.2019\n","step 40 , total_loss: 1.0901, data_loss: 1.0901\n","step 60 , total_loss: 1.1082, data_loss: 1.1082\n","step 80 , total_loss: 1.0589, data_loss: 1.0589\n","step 100 , total_loss: 1.1667, data_loss: 1.1667\n","step 120 , total_loss: 1.0628, data_loss: 1.0628\n","step 140 , total_loss: 1.0659, data_loss: 1.0659\n","step 160 , total_loss: 1.1017, data_loss: 1.1017\n","step 180 , total_loss: 1.1208, data_loss: 1.1208\n","step 200 , total_loss: 1.0625, data_loss: 1.0625\n","step 220 , total_loss: 1.0215, data_loss: 1.0215\n","step 240 , total_loss: 1.0175, data_loss: 1.0175\n","step 260 , total_loss: 0.9747, data_loss: 0.9747\n","step 280 , total_loss: 1.0949, data_loss: 1.0949\n","step 300 , total_loss: 1.0459, data_loss: 1.0459\n","step 320 , total_loss: 1.0186, data_loss: 1.0186\n","step 340 , total_loss: 1.0621, data_loss: 1.0621\n","step 360 , total_loss: 1.0509, data_loss: 1.0509\n","step 380 , total_loss: 0.9928, data_loss: 0.9928\n","step 400 , total_loss: 1.0079, data_loss: 1.0079\n","step 420 , total_loss: 1.0456, data_loss: 1.0456\n","step 440 , total_loss: 0.9677, data_loss: 0.9677\n","step 460 , total_loss: 1.0859, data_loss: 1.0859\n","step 480 , total_loss: 0.9435, data_loss: 0.9435\n","step 500 , total_loss: 1.0341, data_loss: 1.0341\n","step 520 , total_loss: 0.9483, data_loss: 0.9483\n","step 540 , total_loss: 0.9538, data_loss: 0.9538\n","step 560 , total_loss: 1.0039, data_loss: 1.0039\n","step 580 , total_loss: 1.0445, data_loss: 1.0445\n","step 600 , total_loss: 0.9586, data_loss: 0.9586\n","step 620 , total_loss: 0.9494, data_loss: 0.9494\n","step 640 , total_loss: 0.9910, data_loss: 0.9910\n","step 660 , total_loss: 0.9325, data_loss: 0.9325\n","step 680 , total_loss: 0.9585, data_loss: 0.9585\n","step 700 , total_loss: 0.9071, data_loss: 0.9071\n","step 720 , total_loss: 0.9091, data_loss: 0.9091\n","step 740 , total_loss: 0.9429, data_loss: 0.9429\n","step 760 , total_loss: 0.9956, data_loss: 0.9956\n","step 780 , total_loss: 0.9444, data_loss: 0.9444\n","eval valid at epoch 2: auc:0.8495,logloss:0.4541,mean_mrr:0.7682,ndcg@2:0.756,ndcg@4:0.8254,ndcg@6:0.8273,group_auc:0.8497\n","step 20 , total_loss: 0.8502, data_loss: 0.8502\n","step 40 , total_loss: 0.9732, data_loss: 0.9732\n","step 60 , total_loss: 0.8764, data_loss: 0.8764\n","step 80 , total_loss: 0.9613, data_loss: 0.9613\n","step 100 , total_loss: 0.9470, data_loss: 0.9470\n","step 120 , total_loss: 0.8847, data_loss: 0.8847\n","step 140 , total_loss: 0.8797, data_loss: 0.8797\n","step 160 , total_loss: 0.8954, data_loss: 0.8954\n","step 180 , total_loss: 0.8545, data_loss: 0.8545\n","step 200 , total_loss: 0.8696, data_loss: 0.8696\n","step 220 , total_loss: 0.9721, data_loss: 0.9721\n","step 240 , total_loss: 0.8747, data_loss: 0.8747\n","step 260 , total_loss: 0.9515, data_loss: 0.9515\n","step 280 , total_loss: 0.9075, data_loss: 0.9075\n","step 300 , total_loss: 0.8362, data_loss: 0.8362\n","step 320 , total_loss: 0.9029, data_loss: 0.9029\n","step 340 , total_loss: 0.8429, data_loss: 0.8429\n","step 360 , total_loss: 0.8787, data_loss: 0.8787\n","step 380 , total_loss: 0.8157, data_loss: 0.8157\n","step 400 , total_loss: 0.8579, data_loss: 0.8579\n","step 420 , total_loss: 0.8632, data_loss: 0.8632\n","step 440 , total_loss: 0.7827, data_loss: 0.7827\n","step 460 , total_loss: 0.8085, data_loss: 0.8085\n","step 480 , total_loss: 0.8506, data_loss: 0.8506\n","step 500 , total_loss: 0.8421, data_loss: 0.8421\n","step 520 , total_loss: 0.8828, data_loss: 0.8828\n","step 540 , total_loss: 0.9334, data_loss: 0.9334\n","step 560 , total_loss: 0.8452, data_loss: 0.8452\n","step 580 , total_loss: 0.8244, data_loss: 0.8244\n","step 600 , total_loss: 0.8033, data_loss: 0.8033\n","step 620 , total_loss: 0.8216, data_loss: 0.8216\n","step 640 , total_loss: 0.8146, data_loss: 0.8146\n","step 660 , total_loss: 0.8524, data_loss: 0.8524\n","step 680 , total_loss: 0.8082, data_loss: 0.8082\n","step 700 , total_loss: 0.9034, data_loss: 0.9034\n","step 720 , total_loss: 0.8540, data_loss: 0.8540\n","step 740 , total_loss: 0.7948, data_loss: 0.7948\n","step 760 , total_loss: 0.9039, data_loss: 0.9039\n","step 780 , total_loss: 0.7992, data_loss: 0.7992\n","eval valid at epoch 3: auc:0.8719,logloss:0.391,mean_mrr:0.8059,ndcg@2:0.8006,ndcg@4:0.8544,ndcg@6:0.8556,group_auc:0.8774\n","step 20 , total_loss: 0.8264, data_loss: 0.8264\n","step 40 , total_loss: 0.8450, data_loss: 0.8450\n","step 60 , total_loss: 0.8232, data_loss: 0.8232\n","step 80 , total_loss: 0.8392, data_loss: 0.8392\n","step 100 , total_loss: 0.8917, data_loss: 0.8917\n","step 120 , total_loss: 0.7904, data_loss: 0.7904\n","step 140 , total_loss: 0.7796, data_loss: 0.7796\n","step 160 , total_loss: 0.8647, data_loss: 0.8647\n","step 180 , total_loss: 0.8740, data_loss: 0.8740\n","step 200 , total_loss: 0.8660, data_loss: 0.8660\n","step 220 , total_loss: 0.8413, data_loss: 0.8413\n","step 240 , total_loss: 0.8006, data_loss: 0.8006\n","step 260 , total_loss: 0.7774, data_loss: 0.7774\n","step 280 , total_loss: 0.7751, data_loss: 0.7751\n","step 300 , total_loss: 0.8377, data_loss: 0.8377\n","step 320 , total_loss: 0.7543, data_loss: 0.7543\n","step 340 , total_loss: 0.8388, data_loss: 0.8388\n","step 360 , total_loss: 0.7972, data_loss: 0.7972\n","step 380 , total_loss: 0.8067, data_loss: 0.8067\n","step 400 , total_loss: 0.7442, data_loss: 0.7442\n","step 420 , total_loss: 0.7686, data_loss: 0.7686\n","step 440 , total_loss: 0.8994, data_loss: 0.8994\n","step 460 , total_loss: 0.7732, data_loss: 0.7732\n","step 480 , total_loss: 0.8057, data_loss: 0.8057\n","step 500 , total_loss: 0.7996, data_loss: 0.7996\n","step 520 , total_loss: 0.8108, data_loss: 0.8108\n","step 540 , total_loss: 0.7748, data_loss: 0.7748\n","step 560 , total_loss: 0.7841, data_loss: 0.7841\n","step 580 , total_loss: 0.9037, data_loss: 0.9037\n","step 600 , total_loss: 0.7731, data_loss: 0.7731\n","step 620 , total_loss: 0.7942, data_loss: 0.7942\n","step 640 , total_loss: 0.8197, data_loss: 0.8197\n","step 660 , total_loss: 0.7670, data_loss: 0.7670\n","step 680 , total_loss: 0.8285, data_loss: 0.8285\n","step 700 , total_loss: 0.8114, data_loss: 0.8114\n","step 720 , total_loss: 0.7847, data_loss: 0.7847\n","step 740 , total_loss: 0.9579, data_loss: 0.9579\n","step 760 , total_loss: 0.8087, data_loss: 0.8087\n","step 780 , total_loss: 0.7234, data_loss: 0.7234\n","eval valid at epoch 4: auc:0.8788,logloss:0.3686,mean_mrr:0.8141,ndcg@2:0.8116,ndcg@4:0.8607,ndcg@6:0.8617,group_auc:0.8837\n","step 20 , total_loss: 0.8889, data_loss: 0.8889\n","step 40 , total_loss: 0.8042, data_loss: 0.8042\n","step 60 , total_loss: 0.8045, data_loss: 0.8045\n","step 80 , total_loss: 0.7527, data_loss: 0.7527\n","step 100 , total_loss: 0.7756, data_loss: 0.7756\n","step 120 , total_loss: 0.7949, data_loss: 0.7949\n","step 140 , total_loss: 0.8537, data_loss: 0.8537\n","step 160 , total_loss: 0.7674, data_loss: 0.7674\n","step 180 , total_loss: 0.8394, data_loss: 0.8394\n","step 200 , total_loss: 0.8254, data_loss: 0.8254\n","step 220 , total_loss: 0.8108, data_loss: 0.8108\n","step 240 , total_loss: 0.7468, data_loss: 0.7468\n","step 260 , total_loss: 0.8485, data_loss: 0.8485\n","step 280 , total_loss: 0.8569, data_loss: 0.8569\n","step 300 , total_loss: 0.7542, data_loss: 0.7542\n","step 320 , total_loss: 0.8538, data_loss: 0.8538\n","step 340 , total_loss: 0.7813, data_loss: 0.7813\n","step 360 , total_loss: 0.8845, data_loss: 0.8845\n","step 380 , total_loss: 0.7480, data_loss: 0.7480\n","step 400 , total_loss: 0.7717, data_loss: 0.7717\n","step 420 , total_loss: 0.7908, data_loss: 0.7908\n","step 440 , total_loss: 0.7630, data_loss: 0.7630\n","step 460 , total_loss: 0.8395, data_loss: 0.8395\n","step 480 , total_loss: 0.8210, data_loss: 0.8210\n","step 500 , total_loss: 0.8129, data_loss: 0.8129\n","step 520 , total_loss: 0.7888, data_loss: 0.7888\n","step 540 , total_loss: 0.8764, data_loss: 0.8764\n","step 560 , total_loss: 0.7781, data_loss: 0.7781\n","step 580 , total_loss: 0.7747, data_loss: 0.7747\n","step 600 , total_loss: 0.8543, data_loss: 0.8543\n","step 620 , total_loss: 0.7018, data_loss: 0.7018\n","step 640 , total_loss: 0.7603, data_loss: 0.7603\n","step 660 , total_loss: 0.7940, data_loss: 0.7940\n","step 680 , total_loss: 0.7510, data_loss: 0.7510\n","step 700 , total_loss: 0.7993, data_loss: 0.7993\n","step 720 , total_loss: 0.7982, data_loss: 0.7982\n","step 740 , total_loss: 0.7436, data_loss: 0.7436\n","step 760 , total_loss: 0.8751, data_loss: 0.8751\n","step 780 , total_loss: 0.8540, data_loss: 0.8540\n","eval valid at epoch 5: auc:0.8836,logloss:0.3757,mean_mrr:0.8217,ndcg@2:0.8184,ndcg@4:0.8662,ndcg@6:0.8674,group_auc:0.8882\n","step 20 , total_loss: 0.7727, data_loss: 0.7727\n","step 40 , total_loss: 0.7973, data_loss: 0.7973\n","step 60 , total_loss: 0.7655, data_loss: 0.7655\n","step 80 , total_loss: 0.8256, data_loss: 0.8256\n","step 100 , total_loss: 0.7577, data_loss: 0.7577\n","step 120 , total_loss: 0.7861, data_loss: 0.7861\n","step 140 , total_loss: 0.7200, data_loss: 0.7200\n","step 160 , total_loss: 0.7670, data_loss: 0.7670\n","step 180 , total_loss: 0.7985, data_loss: 0.7985\n","step 200 , total_loss: 0.8009, data_loss: 0.8009\n","step 220 , total_loss: 0.8067, data_loss: 0.8067\n","step 240 , total_loss: 0.7441, data_loss: 0.7441\n","step 260 , total_loss: 0.8057, data_loss: 0.8057\n","step 280 , total_loss: 0.7388, data_loss: 0.7388\n","step 300 , total_loss: 0.7318, data_loss: 0.7318\n","step 320 , total_loss: 0.7671, data_loss: 0.7671\n","step 340 , total_loss: 0.7973, data_loss: 0.7973\n","step 360 , total_loss: 0.7762, data_loss: 0.7762\n","step 380 , total_loss: 0.7368, data_loss: 0.7368\n","step 400 , total_loss: 0.8489, data_loss: 0.8489\n","step 420 , total_loss: 0.7838, data_loss: 0.7838\n","step 440 , total_loss: 0.7993, data_loss: 0.7993\n","step 460 , total_loss: 0.7458, data_loss: 0.7458\n","step 480 , total_loss: 0.7886, data_loss: 0.7886\n","step 500 , total_loss: 0.7488, data_loss: 0.7488\n","step 520 , total_loss: 0.7613, data_loss: 0.7613\n","step 540 , total_loss: 0.7517, data_loss: 0.7517\n","step 560 , total_loss: 0.7970, data_loss: 0.7970\n","step 580 , total_loss: 0.8030, data_loss: 0.8030\n","step 600 , total_loss: 0.8685, data_loss: 0.8685\n","step 620 , total_loss: 0.8154, data_loss: 0.8154\n","step 640 , total_loss: 0.7944, data_loss: 0.7944\n","step 660 , total_loss: 0.7590, data_loss: 0.7590\n","step 680 , total_loss: 0.7507, data_loss: 0.7507\n","step 700 , total_loss: 0.8010, data_loss: 0.8010\n","step 720 , total_loss: 0.7506, data_loss: 0.7506\n","step 740 , total_loss: 0.7810, data_loss: 0.7810\n","step 760 , total_loss: 0.8527, data_loss: 0.8527\n","step 780 , total_loss: 0.8162, data_loss: 0.8162\n","eval valid at epoch 6: auc:0.884,logloss:0.376,mean_mrr:0.8227,ndcg@2:0.8196,ndcg@4:0.8669,ndcg@6:0.8681,group_auc:0.889\n","step 20 , total_loss: 0.9623, data_loss: 0.9623\n","step 40 , total_loss: 0.6933, data_loss: 0.6933\n","step 60 , total_loss: 0.7971, data_loss: 0.7971\n","step 80 , total_loss: 0.9189, data_loss: 0.9189\n","step 100 , total_loss: 0.7706, data_loss: 0.7706\n","step 120 , total_loss: 0.7833, data_loss: 0.7833\n","step 140 , total_loss: 0.7980, data_loss: 0.7980\n","step 160 , total_loss: 0.7850, data_loss: 0.7850\n","step 180 , total_loss: 0.7832, data_loss: 0.7832\n","step 200 , total_loss: 0.8103, data_loss: 0.8103\n","step 220 , total_loss: 0.8874, data_loss: 0.8874\n","step 240 , total_loss: 0.8081, data_loss: 0.8081\n","step 260 , total_loss: 0.7251, data_loss: 0.7251\n","step 280 , total_loss: 0.7963, data_loss: 0.7963\n","step 300 , total_loss: 0.8023, data_loss: 0.8023\n","step 320 , total_loss: 0.6715, data_loss: 0.6715\n","step 340 , total_loss: 0.7760, data_loss: 0.7760\n","step 360 , total_loss: 0.6941, data_loss: 0.6941\n","step 380 , total_loss: 0.8100, data_loss: 0.8100\n","step 400 , total_loss: 0.7618, data_loss: 0.7618\n","step 420 , total_loss: 0.7591, data_loss: 0.7591\n","step 440 , total_loss: 0.7543, data_loss: 0.7543\n","step 460 , total_loss: 0.7545, data_loss: 0.7545\n","step 480 , total_loss: 0.7983, data_loss: 0.7983\n","step 500 , total_loss: 0.7814, data_loss: 0.7814\n","step 520 , total_loss: 0.8090, data_loss: 0.8090\n","step 540 , total_loss: 0.7435, data_loss: 0.7435\n","step 560 , total_loss: 0.7294, data_loss: 0.7294\n","step 580 , total_loss: 0.7322, data_loss: 0.7322\n","step 600 , total_loss: 0.7039, data_loss: 0.7039\n","step 620 , total_loss: 0.7953, data_loss: 0.7953\n","step 640 , total_loss: 0.7688, data_loss: 0.7688\n","step 660 , total_loss: 0.7849, data_loss: 0.7849\n","step 680 , total_loss: 0.7593, data_loss: 0.7593\n","step 700 , total_loss: 0.7573, data_loss: 0.7573\n","step 720 , total_loss: 0.7655, data_loss: 0.7655\n","step 740 , total_loss: 0.7637, data_loss: 0.7637\n","step 760 , total_loss: 0.7866, data_loss: 0.7866\n","step 780 , total_loss: 0.7557, data_loss: 0.7557\n","eval valid at epoch 7: auc:0.8891,logloss:0.3885,mean_mrr:0.827,ndcg@2:0.8242,ndcg@4:0.8702,ndcg@6:0.8714,group_auc:0.8921\n","step 20 , total_loss: 0.6999, data_loss: 0.6999\n","step 40 , total_loss: 0.7753, data_loss: 0.7753\n","step 60 , total_loss: 0.6956, data_loss: 0.6956\n","step 80 , total_loss: 0.8033, data_loss: 0.8033\n","step 100 , total_loss: 0.7470, data_loss: 0.7470\n","step 120 , total_loss: 0.7795, data_loss: 0.7795\n","step 140 , total_loss: 0.7334, data_loss: 0.7334\n","step 160 , total_loss: 0.7730, data_loss: 0.7730\n","step 180 , total_loss: 0.7965, data_loss: 0.7965\n","step 200 , total_loss: 0.7215, data_loss: 0.7215\n","step 220 , total_loss: 0.7750, data_loss: 0.7750\n","step 240 , total_loss: 0.7204, data_loss: 0.7204\n","step 260 , total_loss: 0.7983, data_loss: 0.7983\n","step 280 , total_loss: 0.7229, data_loss: 0.7229\n","step 300 , total_loss: 0.7904, data_loss: 0.7904\n","step 320 , total_loss: 0.7442, data_loss: 0.7442\n","step 340 , total_loss: 0.8247, data_loss: 0.8247\n","step 360 , total_loss: 0.7696, data_loss: 0.7696\n","step 380 , total_loss: 0.7774, data_loss: 0.7774\n","step 400 , total_loss: 0.8371, data_loss: 0.8371\n","step 420 , total_loss: 0.7547, data_loss: 0.7547\n","step 440 , total_loss: 0.8100, data_loss: 0.8100\n","step 460 , total_loss: 0.7388, data_loss: 0.7388\n","step 480 , total_loss: 0.8094, data_loss: 0.8094\n","step 500 , total_loss: 0.6880, data_loss: 0.6880\n","step 520 , total_loss: 0.7742, data_loss: 0.7742\n","step 540 , total_loss: 0.7528, data_loss: 0.7528\n","step 560 , total_loss: 0.6914, data_loss: 0.6914\n","step 580 , total_loss: 0.7793, data_loss: 0.7793\n","step 600 , total_loss: 0.7138, data_loss: 0.7138\n","step 620 , total_loss: 0.8067, data_loss: 0.8067\n","step 640 , total_loss: 0.7433, data_loss: 0.7433\n","step 660 , total_loss: 0.7857, data_loss: 0.7857\n","step 680 , total_loss: 0.8051, data_loss: 0.8051\n","step 700 , total_loss: 0.7355, data_loss: 0.7355\n","step 720 , total_loss: 0.8054, data_loss: 0.8054\n","step 740 , total_loss: 0.7433, data_loss: 0.7433\n","step 760 , total_loss: 0.7815, data_loss: 0.7815\n","step 780 , total_loss: 0.7715, data_loss: 0.7715\n","eval valid at epoch 8: auc:0.8877,logloss:0.4037,mean_mrr:0.8219,ndcg@2:0.8201,ndcg@4:0.8665,ndcg@6:0.8676,group_auc:0.8891\n","step 20 , total_loss: 0.7570, data_loss: 0.7570\n","step 40 , total_loss: 0.7632, data_loss: 0.7632\n","step 60 , total_loss: 0.7555, data_loss: 0.7555\n","step 80 , total_loss: 0.8190, data_loss: 0.8190\n","step 100 , total_loss: 0.7305, data_loss: 0.7305\n","step 120 , total_loss: 0.8101, data_loss: 0.8101\n","step 140 , total_loss: 0.7410, data_loss: 0.7410\n","step 160 , total_loss: 0.7752, data_loss: 0.7752\n","step 180 , total_loss: 0.7457, data_loss: 0.7457\n","step 200 , total_loss: 0.7677, data_loss: 0.7677\n","step 220 , total_loss: 0.7764, data_loss: 0.7764\n","step 240 , total_loss: 0.7800, data_loss: 0.7800\n","step 260 , total_loss: 0.7756, data_loss: 0.7756\n","step 280 , total_loss: 0.7674, data_loss: 0.7674\n","step 300 , total_loss: 0.7595, data_loss: 0.7595\n","step 320 , total_loss: 0.7965, data_loss: 0.7965\n","step 340 , total_loss: 0.8104, data_loss: 0.8104\n","step 360 , total_loss: 0.7165, data_loss: 0.7165\n","step 380 , total_loss: 0.8400, data_loss: 0.8400\n","step 400 , total_loss: 0.7855, data_loss: 0.7855\n","step 420 , total_loss: 0.7676, data_loss: 0.7676\n","step 440 , total_loss: 0.8329, data_loss: 0.8329\n","step 460 , total_loss: 0.7741, data_loss: 0.7741\n","step 480 , total_loss: 0.7901, data_loss: 0.7901\n","step 500 , total_loss: 0.6900, data_loss: 0.6900\n","step 520 , total_loss: 0.7618, data_loss: 0.7618\n","step 540 , total_loss: 0.6849, data_loss: 0.6849\n","step 560 , total_loss: 0.7674, data_loss: 0.7674\n","step 580 , total_loss: 0.7793, data_loss: 0.7793\n","step 600 , total_loss: 0.7419, data_loss: 0.7419\n","step 620 , total_loss: 0.7376, data_loss: 0.7376\n","step 640 , total_loss: 0.7316, data_loss: 0.7316\n","step 660 , total_loss: 0.7353, data_loss: 0.7353\n","step 680 , total_loss: 0.7198, data_loss: 0.7198\n","step 700 , total_loss: 0.8066, data_loss: 0.8066\n","step 720 , total_loss: 0.7189, data_loss: 0.7189\n","step 740 , total_loss: 0.6954, data_loss: 0.6954\n","step 760 , total_loss: 0.7257, data_loss: 0.7257\n","step 780 , total_loss: 0.7401, data_loss: 0.7401\n","eval valid at epoch 9: auc:0.8898,logloss:0.4245,mean_mrr:0.8275,ndcg@2:0.8254,ndcg@4:0.8707,ndcg@6:0.8717,group_auc:0.8924\n","step 20 , total_loss: 0.7404, data_loss: 0.7404\n","step 40 , total_loss: 0.7867, data_loss: 0.7867\n","step 60 , total_loss: 0.6718, data_loss: 0.6718\n","step 80 , total_loss: 0.7502, data_loss: 0.7502\n","step 100 , total_loss: 0.8175, data_loss: 0.8175\n","step 120 , total_loss: 0.7640, data_loss: 0.7640\n","step 140 , total_loss: 0.7130, data_loss: 0.7130\n","step 160 , total_loss: 0.7966, data_loss: 0.7966\n","step 180 , total_loss: 0.7761, data_loss: 0.7761\n","step 200 , total_loss: 0.6568, data_loss: 0.6568\n","step 220 , total_loss: 0.7586, data_loss: 0.7586\n","step 240 , total_loss: 0.7603, data_loss: 0.7603\n","step 260 , total_loss: 0.7713, data_loss: 0.7713\n","step 280 , total_loss: 0.7943, data_loss: 0.7943\n","step 300 , total_loss: 0.7352, data_loss: 0.7352\n","step 320 , total_loss: 0.7822, data_loss: 0.7822\n","step 340 , total_loss: 0.7648, data_loss: 0.7648\n","step 360 , total_loss: 0.7376, data_loss: 0.7376\n","step 380 , total_loss: 0.7737, data_loss: 0.7737\n","step 400 , total_loss: 0.7411, data_loss: 0.7411\n","step 420 , total_loss: 0.7384, data_loss: 0.7384\n","step 440 , total_loss: 0.7854, data_loss: 0.7854\n","step 460 , total_loss: 0.7984, data_loss: 0.7984\n","step 480 , total_loss: 0.7636, data_loss: 0.7636\n","step 500 , total_loss: 0.7318, data_loss: 0.7318\n","step 520 , total_loss: 0.7957, data_loss: 0.7957\n","step 540 , total_loss: 0.7705, data_loss: 0.7705\n","step 560 , total_loss: 0.8128, data_loss: 0.8128\n","step 580 , total_loss: 0.8167, data_loss: 0.8167\n","step 600 , total_loss: 0.7687, data_loss: 0.7687\n","step 620 , total_loss: 0.7252, data_loss: 0.7252\n","step 640 , total_loss: 0.7187, data_loss: 0.7187\n","step 660 , total_loss: 0.7203, data_loss: 0.7203\n","step 680 , total_loss: 0.8181, data_loss: 0.8181\n","step 700 , total_loss: 0.6957, data_loss: 0.6957\n","step 720 , total_loss: 0.7777, data_loss: 0.7777\n","step 740 , total_loss: 0.7190, data_loss: 0.7190\n","step 760 , total_loss: 0.6921, data_loss: 0.6921\n","step 780 , total_loss: 0.8064, data_loss: 0.8064\n","eval valid at epoch 10: auc:0.8912,logloss:0.4155,mean_mrr:0.8289,ndcg@2:0.8269,ndcg@4:0.8715,ndcg@6:0.8728,group_auc:0.8933\n","[(1, {'auc': 0.7755, 'logloss': 0.5693, 'mean_mrr': 0.6943, 'ndcg@2': 0.6573, 'ndcg@4': 0.7629, 'ndcg@6': 0.7715, 'group_auc': 0.7816}), (2, {'auc': 0.8495, 'logloss': 0.4541, 'mean_mrr': 0.7682, 'ndcg@2': 0.756, 'ndcg@4': 0.8254, 'ndcg@6': 0.8273, 'group_auc': 0.8497}), (3, {'auc': 0.8719, 'logloss': 0.391, 'mean_mrr': 0.8059, 'ndcg@2': 0.8006, 'ndcg@4': 0.8544, 'ndcg@6': 0.8556, 'group_auc': 0.8774}), (4, {'auc': 0.8788, 'logloss': 0.3686, 'mean_mrr': 0.8141, 'ndcg@2': 0.8116, 'ndcg@4': 0.8607, 'ndcg@6': 0.8617, 'group_auc': 0.8837}), (5, {'auc': 0.8836, 'logloss': 0.3757, 'mean_mrr': 0.8217, 'ndcg@2': 0.8184, 'ndcg@4': 0.8662, 'ndcg@6': 0.8674, 'group_auc': 0.8882}), (6, {'auc': 0.884, 'logloss': 0.376, 'mean_mrr': 0.8227, 'ndcg@2': 0.8196, 'ndcg@4': 0.8669, 'ndcg@6': 0.8681, 'group_auc': 0.889}), (7, {'auc': 0.8891, 'logloss': 0.3885, 'mean_mrr': 0.827, 'ndcg@2': 0.8242, 'ndcg@4': 0.8702, 'ndcg@6': 0.8714, 'group_auc': 0.8921}), (8, {'auc': 0.8877, 'logloss': 0.4037, 'mean_mrr': 0.8219, 'ndcg@2': 0.8201, 'ndcg@4': 0.8665, 'ndcg@6': 0.8676, 'group_auc': 0.8891}), (9, {'auc': 0.8898, 'logloss': 0.4245, 'mean_mrr': 0.8275, 'ndcg@2': 0.8254, 'ndcg@4': 0.8707, 'ndcg@6': 0.8717, 'group_auc': 0.8924}), (10, {'auc': 0.8912, 'logloss': 0.4155, 'mean_mrr': 0.8289, 'ndcg@2': 0.8269, 'ndcg@4': 0.8715, 'ndcg@6': 0.8728, 'group_auc': 0.8933})]\n","best epoch: 10\n","Time cost for training is 197.04 mins\n"]}],"source":["with Timer() as train_time:\n","    model = model.fit(train_file, valid_file, valid_num_ngs=valid_num_ngs) \n","\n","# valid_num_ngs is the number of negative lines after each positive line in your valid_file \n","# we will evaluate the performance of model on valid_file every epoch\n","print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53342,"status":"ok","timestamp":1650000644460,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"gmm3DPjbiY9N","outputId":"8d589301-91a9-446f-99dc-ebcff115c0a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'auc': 0.9087, 'logloss': 0.3999, 'mean_mrr': 0.7242, 'ndcg@2': 0.6872, 'ndcg@4': 0.7814, 'ndcg@6': 0.7877, 'group_auc': 0.905}\n"]}],"source":["res_syn = model.run_eval(test_file, num_ngs=test_num_ngs)\n","print(res_syn)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":428,"status":"ok","timestamp":1650000657669,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"VB7MBFNkjl5e","outputId":"976697e7-e35e-416d-9e5a-436c9032db89"},"outputs":[{"data":{"application/scrapbook.scrap.json+json":{"data":{"auc":0.9087,"group_auc":0.905,"logloss":0.3999,"mean_mrr":0.7242,"ndcg@2":0.6872,"ndcg@4":0.7814,"ndcg@6":0.7877},"encoder":"json","name":"res_syn","version":1}},"metadata":{"scrapbook":{"data":true,"display":false,"name":"res_syn"}},"output_type":"display_data"}],"source":["sb.glue(\"res_syn\", res_syn)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":35776,"status":"ok","timestamp":1650000695071,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"h2uxYGfFjpL9"},"outputs":[],"source":["model = model.predict(test_file, output_file)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7124,"status":"ok","timestamp":1650000712820,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"wGZ26pt-ujeo","outputId":"5e57cd48-8e85-463f-e278-ec02afe67ef6"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\base_model.py:701: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n","  curr_hidden_nn_layer = tf.compat.v1.layers.batch_normalization(\n","C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs, training=training)\n"]},{"name":"stdout","output_type":"stream","text":["loading saved model in resources/model\\sli_rec/best_model\n"]}],"source":["model_best_trained = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n","path_best_trained = os.path.join(hparams.MODEL_DIR, \"best_model\")\n","print('loading saved model in {0}'.format(path_best_trained))\n","model_best_trained.load_model(path_best_trained)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75245,"status":"ok","timestamp":1650000790316,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"fKtBHxlGu5-K","outputId":"d3fdcadf-665d-4120-c4fa-78af49376d1b"},"outputs":[{"data":{"text/plain":["{'auc': 0.9087,\n"," 'logloss': 0.3999,\n"," 'mean_mrr': 0.7242,\n"," 'ndcg@2': 0.6872,\n"," 'ndcg@4': 0.7814,\n"," 'ndcg@6': 0.7877,\n"," 'group_auc': 0.905}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model_best_trained.run_eval(test_file, num_ngs=test_num_ngs)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48189,"status":"ok","timestamp":1650000881133,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"XH7L5VOQvARx","outputId":"048eb05a-af69-47d3-9111-62281609532d"},"outputs":[{"data":{"text/plain":["<recommenders.models.deeprec.models.sequential.sli_rec.SLI_RECModel at 0x279360196a0>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["model_best_trained.predict(test_file, output_file)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPMZYkqYRJvrImpPUSQoA76","collapsed_sections":[],"mount_file_id":"1aN-Xq8xQ0gMEOoDsqX8RKLj3SKskndqj","name":"SLI_REC.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"}},"nbformat":4,"nbformat_minor":0}
