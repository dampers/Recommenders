{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4785,"status":"ok","timestamp":1649946944115,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"Sknnn2xs-AHi","outputId":"ce8fcf33-cadf-4747-95ea-84eb61493cee"},"outputs":[{"name":"stdout","output_type":"stream","text":["System version: 3.8.9 (tags/v3.8.9:a743f81, Apr  6 2021, 14:02:34) [MSC v.1928 64 bit (AMD64)]\n","Tensorflow version: 2.8.0\n"]}],"source":["import sys\n","import os\n","import logging\n","import papermill as pm\n","import scrapbook as sb\n","from tempfile import TemporaryDirectory\n","import numpy as np\n","import tensorflow.compat.v1 as tf\n","tf.get_logger().setLevel('ERROR') # only show error messages\n","\n","from recommenders.utils.timer import Timer\n","from recommenders.utils.constants import SEED\n","from recommenders.models.deeprec.deeprec_utils import (\n","    prepare_hparams\n",")\n","\n","from resources.data_preprocessing import data_preprocessing\n","# from recommenders.datasets.amazon_reviews import download_and_extract, data_preprocessing\n","from recommenders.datasets.download_utils import maybe_download\n","\n","\n","#from recommenders.models.deeprec.models.sequential.sli_rec import SLI_RECModel as SeqModel\n","####  to use the other model, use one of the following lines:\n","from recommenders.models.deeprec.models.sequential.asvd import A2SVDModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.caser import CaserModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.gru4rec import GRU4RecModel as SeqModel\n","# from recommenders.models.deeprec.models.sequential.sum import SUMModel as SeqModel\n","\n","#from recommenders.models.deeprec.models.sequential.nextitnet import NextItNetModel\n","\n","from recommenders.models.deeprec.io.sequential_iterator import SequentialIterator\n","#from recommenders.models.deeprec.io.nextitnet_iterator import NextItNetIterator\n","\n","print(\"System version: {}\".format(sys.version))\n","print(\"Tensorflow version: {}\".format(tf.__version__))"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":401,"status":"ok","timestamp":1649946958359,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"sxtfUZfP-ZWR"},"outputs":[],"source":["##  ATTENTION: change to the corresponding config file, e.g., caser.yaml for CaserModel, sum.yaml for SUMModel\n","# yaml_file = '../../recommenders/models/deeprec/config/sli_rec.yaml'  \n","yaml_file = './asvd.yaml'  "]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":322,"status":"ok","timestamp":1649947140491,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"_NnzhN4h_rI5"},"outputs":[],"source":["EPOCHS = 10\n","BATCH_SIZE = 400\n","RANDOM_SEED = SEED  # Set None for non-deterministic result\n","\n","data_path = os.path.join(\"resources/\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45584,"status":"ok","timestamp":1649947187284,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"0RAMNcI3AClc","outputId":"8b52057f-b32f-4f24-8ed6-52571d5e203c"},"outputs":[],"source":["# for test\n","train_file = os.path.join(data_path, r'train_data')\n","valid_file = os.path.join(data_path, r'valid_data')\n","test_file = os.path.join(data_path, r'test_data')\n","user_vocab = os.path.join(data_path, r'user_vocab.pkl')\n","item_vocab = os.path.join(data_path, r'item_vocab.pkl')\n","cate_vocab = os.path.join(data_path, r'cate_vocab.pkl')\n","output_file = os.path.join(data_path, r'output_a2svd.txt')\n","\n","# reviews_name = 'json'\n","# meta_name = 'json'\n","# reviews_file = os.path.join(data_path, reviews_name)\n","# meta_file = os.path.join(data_path, meta_name)\n","train_num_ngs = 4 # number of negative instances with a positive instance for training\n","valid_num_ngs = 4 # number of negative instances with a positive instance for validation\n","test_num_ngs = 9 # number of negative instances with a positive instance for testing\n","sample_rate = 0.01 # sample a small item set for training and testing here for fast example\n","\n","input_files = [data_path, train_file, valid_file, test_file, user_vocab, item_vocab, cate_vocab]\n","\n","if not os.path.exists(train_file):\n","    # download_and_extract(reviews_name, reviews_file)\n","    # download_and_extract(meta_name, meta_file)\n","    data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs)\n","    #### uncomment this for the NextItNet model, because it does not need to unfold the user history\n","    # data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs, is_history_expanding=False)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":261,"status":"ok","timestamp":1649947208847,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"rwTMO3WEWaCu"},"outputs":[],"source":["### NOTE:  \n","### remember to use `_create_vocab(train_file, user_vocab, item_vocab, cate_vocab)` to generate the user_vocab, item_vocab and cate_vocab files, if you are using your own dataset rather than using our demo Amazon dataset.\n","hparams = prepare_hparams(yaml_file, \n","                          embed_l2=0., \n","                          layer_l2=0., \n","                          learning_rate=0.001,  # set to 0.01 if batch normalization is disable\n","                          epochs=EPOCHS,\n","                          batch_size=BATCH_SIZE,\n","                          show_step=20,\n","                          MODEL_DIR=os.path.join(data_path, \"model\", \"a2svd/\"),\n","                          SUMMARIES_DIR=os.path.join(data_path, \"summary\", \"a2svd/\"),\n","                          user_vocab=user_vocab,\n","                          item_vocab=item_vocab,\n","                          cate_vocab=cate_vocab,\n","                          need_sample=True,\n","                          train_num_ngs=train_num_ngs, # provides the number of negative instances for each positive instance for loss computation.\n","                          attention_size = 40\n","            )"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":281,"status":"ok","timestamp":1649947211274,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"4Rvq7gFluVPq"},"outputs":[],"source":["input_creator = SequentialIterator\n","#### uncomment this for the NextItNet model, because it needs a special data iterator for training\n","#input_creator = NextItNetIterator"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2511,"status":"ok","timestamp":1649947217731,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"VFNfgcKNuaVv","outputId":"c93a77b7-4d79-4c6f-ab1e-9ba4014a97e3"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\base_model.py:701: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n","  curr_hidden_nn_layer = tf.compat.v1.layers.batch_normalization(\n","C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs, training=training)\n"]}],"source":["model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n","\n","## sometimes we don't want to train a model from scratch\n","## then we can load a pre-trained model like this: \n","#model.load_model(r'your_model_path')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29393,"status":"ok","timestamp":1649947248801,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"8AQxPlk-uheU","outputId":"045944e8-4cf5-463a-fd55-a6cd565ab6ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'auc': 0.5171, 'logloss': 0.6931, 'mean_mrr': 0.3034, 'ndcg@2': 0.181, 'ndcg@4': 0.2639, 'ndcg@6': 0.3312, 'group_auc': 0.5181}\n"]}],"source":["# test_num_ngs is the number of negative lines after each positive line in your test_file\n","print(model.run_eval(test_file, num_ngs=test_num_ngs)) "]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2946200,"status":"ok","timestamp":1649950492313,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"QFKQu9rGu0jq","outputId":"818611ad-d718-4214-a3bd-163be4668815"},"outputs":[{"name":"stdout","output_type":"stream","text":["step 20 , total_loss: 1.4978, data_loss: 1.4978\n","step 40 , total_loss: 1.4164, data_loss: 1.4164\n","step 60 , total_loss: 1.3903, data_loss: 1.3903\n","step 80 , total_loss: 1.3706, data_loss: 1.3706\n","step 100 , total_loss: 1.3423, data_loss: 1.3423\n","step 120 , total_loss: 1.3224, data_loss: 1.3224\n","step 140 , total_loss: 1.3432, data_loss: 1.3432\n","step 160 , total_loss: 1.3938, data_loss: 1.3938\n","step 180 , total_loss: 1.3199, data_loss: 1.3199\n","step 200 , total_loss: 1.2876, data_loss: 1.2876\n","step 220 , total_loss: 1.3051, data_loss: 1.3051\n","step 240 , total_loss: 1.2723, data_loss: 1.2723\n","step 260 , total_loss: 1.3215, data_loss: 1.3215\n","step 280 , total_loss: 1.2803, data_loss: 1.2803\n","step 300 , total_loss: 1.2662, data_loss: 1.2662\n","step 320 , total_loss: 1.2921, data_loss: 1.2921\n","step 340 , total_loss: 1.2295, data_loss: 1.2295\n","step 360 , total_loss: 1.3019, data_loss: 1.3019\n","step 380 , total_loss: 1.3002, data_loss: 1.3002\n","step 400 , total_loss: 1.3291, data_loss: 1.3291\n","step 420 , total_loss: 1.2845, data_loss: 1.2845\n","step 440 , total_loss: 1.2852, data_loss: 1.2852\n","step 460 , total_loss: 1.2749, data_loss: 1.2749\n","step 480 , total_loss: 1.2280, data_loss: 1.2280\n","step 500 , total_loss: 1.2375, data_loss: 1.2375\n","step 520 , total_loss: 1.2110, data_loss: 1.2110\n","step 540 , total_loss: 1.2787, data_loss: 1.2787\n","step 560 , total_loss: 1.2031, data_loss: 1.2031\n","step 580 , total_loss: 1.2761, data_loss: 1.2761\n","step 600 , total_loss: 1.2471, data_loss: 1.2471\n","step 620 , total_loss: 1.3014, data_loss: 1.3014\n","step 640 , total_loss: 1.2502, data_loss: 1.2502\n","step 660 , total_loss: 1.2668, data_loss: 1.2668\n","step 680 , total_loss: 1.2718, data_loss: 1.2718\n","step 700 , total_loss: 1.1926, data_loss: 1.1926\n","step 720 , total_loss: 1.2179, data_loss: 1.2179\n","step 740 , total_loss: 1.1893, data_loss: 1.1893\n","step 760 , total_loss: 1.2073, data_loss: 1.2073\n","eval valid at epoch 1: auc:0.7495,logloss:0.5481,mean_mrr:0.6618,ndcg@2:0.6174,ndcg@4:0.735,ndcg@6:0.747,group_auc:0.7536\n","step 20 , total_loss: 1.1691, data_loss: 1.1691\n","step 40 , total_loss: 1.2408, data_loss: 1.2408\n","step 60 , total_loss: 1.2624, data_loss: 1.2624\n","step 80 , total_loss: 1.1967, data_loss: 1.1967\n","step 100 , total_loss: 1.1895, data_loss: 1.1895\n","step 120 , total_loss: 1.2362, data_loss: 1.2362\n","step 140 , total_loss: 1.1806, data_loss: 1.1806\n","step 160 , total_loss: 1.2736, data_loss: 1.2736\n","step 180 , total_loss: 1.1236, data_loss: 1.1236\n","step 200 , total_loss: 1.2068, data_loss: 1.2068\n","step 220 , total_loss: 1.2391, data_loss: 1.2391\n","step 240 , total_loss: 1.1410, data_loss: 1.1410\n","step 260 , total_loss: 1.1593, data_loss: 1.1593\n","step 280 , total_loss: 1.2208, data_loss: 1.2208\n","step 300 , total_loss: 1.1948, data_loss: 1.1948\n","step 320 , total_loss: 1.1374, data_loss: 1.1374\n","step 340 , total_loss: 1.2175, data_loss: 1.2175\n","step 360 , total_loss: 1.1464, data_loss: 1.1464\n","step 380 , total_loss: 1.2621, data_loss: 1.2621\n","step 400 , total_loss: 1.2046, data_loss: 1.2046\n","step 420 , total_loss: 1.2423, data_loss: 1.2423\n","step 440 , total_loss: 1.1878, data_loss: 1.1878\n","step 460 , total_loss: 1.1706, data_loss: 1.1706\n","step 480 , total_loss: 1.1959, data_loss: 1.1959\n","step 500 , total_loss: 1.1997, data_loss: 1.1997\n","step 520 , total_loss: 1.1983, data_loss: 1.1983\n","step 540 , total_loss: 1.1593, data_loss: 1.1593\n","step 560 , total_loss: 1.1703, data_loss: 1.1703\n","step 580 , total_loss: 1.1283, data_loss: 1.1283\n","step 600 , total_loss: 1.1973, data_loss: 1.1973\n","step 620 , total_loss: 1.2034, data_loss: 1.2034\n","step 640 , total_loss: 1.1486, data_loss: 1.1486\n","step 660 , total_loss: 1.1568, data_loss: 1.1568\n","step 680 , total_loss: 1.1721, data_loss: 1.1721\n","step 700 , total_loss: 1.1566, data_loss: 1.1566\n","step 720 , total_loss: 1.2368, data_loss: 1.2368\n","step 740 , total_loss: 1.1627, data_loss: 1.1627\n","step 760 , total_loss: 1.1386, data_loss: 1.1386\n","eval valid at epoch 2: auc:0.7679,logloss:0.5203,mean_mrr:0.6731,ndcg@2:0.631,ndcg@4:0.7465,ndcg@6:0.7556,group_auc:0.7654\n","step 20 , total_loss: 1.1054, data_loss: 1.1054\n","step 40 , total_loss: 1.0986, data_loss: 1.0986\n","step 60 , total_loss: 1.1740, data_loss: 1.1740\n","step 80 , total_loss: 1.1593, data_loss: 1.1593\n","step 100 , total_loss: 1.1429, data_loss: 1.1429\n","step 120 , total_loss: 1.0710, data_loss: 1.0710\n","step 140 , total_loss: 1.1572, data_loss: 1.1572\n","step 160 , total_loss: 1.1522, data_loss: 1.1522\n","step 180 , total_loss: 1.1290, data_loss: 1.1290\n","step 200 , total_loss: 1.1692, data_loss: 1.1692\n","step 220 , total_loss: 1.1743, data_loss: 1.1743\n","step 240 , total_loss: 1.0992, data_loss: 1.0992\n","step 260 , total_loss: 1.0935, data_loss: 1.0935\n","step 280 , total_loss: 1.1777, data_loss: 1.1777\n","step 300 , total_loss: 1.1245, data_loss: 1.1245\n","step 320 , total_loss: 1.1049, data_loss: 1.1049\n","step 340 , total_loss: 1.1398, data_loss: 1.1398\n","step 360 , total_loss: 1.0534, data_loss: 1.0534\n","step 380 , total_loss: 1.1294, data_loss: 1.1294\n","step 400 , total_loss: 1.1610, data_loss: 1.1610\n","step 420 , total_loss: 1.1441, data_loss: 1.1441\n","step 440 , total_loss: 1.1374, data_loss: 1.1374\n","step 460 , total_loss: 1.0817, data_loss: 1.0817\n","step 480 , total_loss: 1.1673, data_loss: 1.1673\n","step 500 , total_loss: 1.1504, data_loss: 1.1504\n","step 520 , total_loss: 1.1376, data_loss: 1.1376\n","step 540 , total_loss: 1.1248, data_loss: 1.1248\n","step 560 , total_loss: 1.1584, data_loss: 1.1584\n","step 580 , total_loss: 1.1215, data_loss: 1.1215\n","step 600 , total_loss: 1.1796, data_loss: 1.1796\n","step 620 , total_loss: 1.1141, data_loss: 1.1141\n","step 640 , total_loss: 1.1252, data_loss: 1.1252\n","step 660 , total_loss: 1.1347, data_loss: 1.1347\n","step 680 , total_loss: 1.1728, data_loss: 1.1728\n","step 700 , total_loss: 1.1542, data_loss: 1.1542\n","step 720 , total_loss: 1.1010, data_loss: 1.1010\n","step 740 , total_loss: 1.0954, data_loss: 1.0954\n","step 760 , total_loss: 1.1321, data_loss: 1.1321\n","eval valid at epoch 3: auc:0.7815,logloss:0.5453,mean_mrr:0.6895,ndcg@2:0.6517,ndcg@4:0.7604,ndcg@6:0.768,group_auc:0.7804\n","step 20 , total_loss: 1.0954, data_loss: 1.0954\n","step 40 , total_loss: 1.0973, data_loss: 1.0973\n","step 60 , total_loss: 1.1345, data_loss: 1.1345\n","step 80 , total_loss: 1.1697, data_loss: 1.1697\n","step 100 , total_loss: 1.1172, data_loss: 1.1172\n","step 120 , total_loss: 1.1368, data_loss: 1.1368\n","step 140 , total_loss: 1.2212, data_loss: 1.2212\n","step 160 , total_loss: 1.2112, data_loss: 1.2112\n","step 180 , total_loss: 1.1268, data_loss: 1.1268\n","step 200 , total_loss: 1.0391, data_loss: 1.0391\n","step 220 , total_loss: 1.1445, data_loss: 1.1445\n","step 240 , total_loss: 1.0707, data_loss: 1.0707\n","step 260 , total_loss: 1.1013, data_loss: 1.1013\n","step 280 , total_loss: 1.0827, data_loss: 1.0827\n","step 300 , total_loss: 1.0459, data_loss: 1.0459\n","step 320 , total_loss: 1.0560, data_loss: 1.0560\n","step 340 , total_loss: 1.1950, data_loss: 1.1950\n","step 360 , total_loss: 1.1076, data_loss: 1.1076\n","step 380 , total_loss: 1.0812, data_loss: 1.0812\n","step 400 , total_loss: 1.1053, data_loss: 1.1053\n","step 420 , total_loss: 1.0570, data_loss: 1.0570\n","step 440 , total_loss: 1.1172, data_loss: 1.1172\n","step 460 , total_loss: 1.1375, data_loss: 1.1375\n","step 480 , total_loss: 0.9974, data_loss: 0.9974\n","step 500 , total_loss: 1.0775, data_loss: 1.0775\n","step 520 , total_loss: 1.0644, data_loss: 1.0644\n","step 540 , total_loss: 1.0871, data_loss: 1.0871\n","step 560 , total_loss: 1.1264, data_loss: 1.1264\n","step 580 , total_loss: 1.0383, data_loss: 1.0383\n","step 600 , total_loss: 1.0872, data_loss: 1.0872\n","step 620 , total_loss: 1.0785, data_loss: 1.0785\n","step 640 , total_loss: 1.0517, data_loss: 1.0517\n","step 660 , total_loss: 1.0797, data_loss: 1.0797\n","step 680 , total_loss: 1.0965, data_loss: 1.0965\n","step 700 , total_loss: 1.1073, data_loss: 1.1073\n","step 720 , total_loss: 1.0602, data_loss: 1.0602\n","step 740 , total_loss: 1.0908, data_loss: 1.0908\n","step 760 , total_loss: 1.0668, data_loss: 1.0668\n","eval valid at epoch 4: auc:0.7903,logloss:0.5515,mean_mrr:0.6984,ndcg@2:0.6637,ndcg@4:0.7686,ndcg@6:0.7748,group_auc:0.7896\n","step 20 , total_loss: 1.0548, data_loss: 1.0548\n","step 40 , total_loss: 1.1283, data_loss: 1.1283\n","step 60 , total_loss: 1.0700, data_loss: 1.0700\n","step 80 , total_loss: 1.1293, data_loss: 1.1293\n","step 100 , total_loss: 1.0802, data_loss: 1.0802\n","step 120 , total_loss: 0.9846, data_loss: 0.9846\n","step 140 , total_loss: 1.0719, data_loss: 1.0719\n","step 160 , total_loss: 1.1142, data_loss: 1.1142\n","step 180 , total_loss: 1.0700, data_loss: 1.0700\n","step 200 , total_loss: 1.0927, data_loss: 1.0927\n","step 220 , total_loss: 1.0414, data_loss: 1.0414\n","step 240 , total_loss: 1.0567, data_loss: 1.0567\n","step 260 , total_loss: 1.1640, data_loss: 1.1640\n","step 280 , total_loss: 1.0750, data_loss: 1.0750\n","step 300 , total_loss: 1.0267, data_loss: 1.0267\n","step 320 , total_loss: 1.0469, data_loss: 1.0469\n","step 340 , total_loss: 1.1573, data_loss: 1.1573\n","step 360 , total_loss: 1.0151, data_loss: 1.0151\n","step 380 , total_loss: 1.0536, data_loss: 1.0536\n","step 400 , total_loss: 1.0078, data_loss: 1.0078\n","step 420 , total_loss: 1.0879, data_loss: 1.0879\n","step 440 , total_loss: 1.0751, data_loss: 1.0751\n","step 460 , total_loss: 1.0864, data_loss: 1.0864\n","step 480 , total_loss: 1.0746, data_loss: 1.0746\n","step 500 , total_loss: 1.0563, data_loss: 1.0563\n","step 520 , total_loss: 1.1121, data_loss: 1.1121\n","step 540 , total_loss: 1.1765, data_loss: 1.1765\n","step 560 , total_loss: 1.0162, data_loss: 1.0162\n","step 580 , total_loss: 1.0797, data_loss: 1.0797\n","step 600 , total_loss: 1.1276, data_loss: 1.1276\n","step 620 , total_loss: 1.1048, data_loss: 1.1048\n","step 640 , total_loss: 0.9669, data_loss: 0.9669\n","step 660 , total_loss: 1.0875, data_loss: 1.0875\n","step 680 , total_loss: 1.0840, data_loss: 1.0840\n","step 700 , total_loss: 1.1023, data_loss: 1.1023\n","step 720 , total_loss: 1.0652, data_loss: 1.0652\n","step 740 , total_loss: 1.0601, data_loss: 1.0601\n","step 760 , total_loss: 1.0601, data_loss: 1.0601\n","eval valid at epoch 5: auc:0.7995,logloss:0.5599,mean_mrr:0.7082,ndcg@2:0.6791,ndcg@4:0.7772,ndcg@6:0.7822,group_auc:0.7992\n","step 20 , total_loss: 1.0917, data_loss: 1.0917\n","step 40 , total_loss: 1.0163, data_loss: 1.0163\n","step 60 , total_loss: 1.0750, data_loss: 1.0750\n","step 80 , total_loss: 1.1132, data_loss: 1.1132\n","step 100 , total_loss: 1.0063, data_loss: 1.0063\n","step 120 , total_loss: 1.0992, data_loss: 1.0992\n","step 140 , total_loss: 1.1156, data_loss: 1.1156\n","step 160 , total_loss: 1.0201, data_loss: 1.0201\n","step 180 , total_loss: 0.9804, data_loss: 0.9804\n","step 200 , total_loss: 1.0687, data_loss: 1.0687\n","step 220 , total_loss: 1.0447, data_loss: 1.0447\n","step 240 , total_loss: 1.1176, data_loss: 1.1176\n","step 260 , total_loss: 1.0545, data_loss: 1.0545\n","step 280 , total_loss: 1.0603, data_loss: 1.0603\n","step 300 , total_loss: 1.0762, data_loss: 1.0762\n","step 320 , total_loss: 1.0910, data_loss: 1.0910\n","step 340 , total_loss: 1.0959, data_loss: 1.0959\n","step 360 , total_loss: 1.0995, data_loss: 1.0995\n","step 380 , total_loss: 1.0373, data_loss: 1.0373\n","step 400 , total_loss: 1.0935, data_loss: 1.0935\n","step 420 , total_loss: 1.0803, data_loss: 1.0803\n","step 440 , total_loss: 1.0887, data_loss: 1.0887\n","step 460 , total_loss: 1.0262, data_loss: 1.0262\n","step 480 , total_loss: 1.0673, data_loss: 1.0673\n","step 500 , total_loss: 0.9917, data_loss: 0.9917\n","step 520 , total_loss: 1.0644, data_loss: 1.0644\n","step 540 , total_loss: 1.1003, data_loss: 1.1003\n","step 560 , total_loss: 1.0320, data_loss: 1.0320\n","step 580 , total_loss: 0.9484, data_loss: 0.9484\n","step 600 , total_loss: 0.9983, data_loss: 0.9983\n","step 620 , total_loss: 1.0879, data_loss: 1.0879\n","step 640 , total_loss: 1.0749, data_loss: 1.0749\n","step 660 , total_loss: 1.0748, data_loss: 1.0748\n","step 680 , total_loss: 1.0100, data_loss: 1.0100\n","step 700 , total_loss: 1.0379, data_loss: 1.0379\n","step 720 , total_loss: 1.0529, data_loss: 1.0529\n","step 740 , total_loss: 1.0507, data_loss: 1.0507\n","step 760 , total_loss: 1.0208, data_loss: 1.0208\n","eval valid at epoch 6: auc:0.8033,logloss:0.5454,mean_mrr:0.7099,ndcg@2:0.6817,ndcg@4:0.7786,ndcg@6:0.7835,group_auc:0.8014\n","step 20 , total_loss: 1.0349, data_loss: 1.0349\n","step 40 , total_loss: 1.1192, data_loss: 1.1192\n","step 60 , total_loss: 1.0500, data_loss: 1.0500\n","step 80 , total_loss: 1.0615, data_loss: 1.0615\n","step 100 , total_loss: 1.0208, data_loss: 1.0208\n","step 120 , total_loss: 1.0318, data_loss: 1.0318\n","step 140 , total_loss: 1.0753, data_loss: 1.0753\n","step 160 , total_loss: 1.0215, data_loss: 1.0215\n","step 180 , total_loss: 1.0148, data_loss: 1.0148\n","step 200 , total_loss: 1.0275, data_loss: 1.0275\n","step 220 , total_loss: 1.0944, data_loss: 1.0944\n","step 240 , total_loss: 1.0694, data_loss: 1.0694\n","step 260 , total_loss: 1.0174, data_loss: 1.0174\n","step 280 , total_loss: 1.0237, data_loss: 1.0237\n","step 300 , total_loss: 1.0798, data_loss: 1.0798\n","step 320 , total_loss: 0.9901, data_loss: 0.9901\n","step 340 , total_loss: 1.0649, data_loss: 1.0649\n","step 360 , total_loss: 0.9497, data_loss: 0.9497\n","step 380 , total_loss: 1.0614, data_loss: 1.0614\n","step 400 , total_loss: 1.1105, data_loss: 1.1105\n","step 420 , total_loss: 1.0656, data_loss: 1.0656\n","step 440 , total_loss: 0.9606, data_loss: 0.9606\n","step 460 , total_loss: 1.0688, data_loss: 1.0688\n","step 480 , total_loss: 1.0636, data_loss: 1.0636\n","step 500 , total_loss: 1.0064, data_loss: 1.0064\n","step 520 , total_loss: 1.1376, data_loss: 1.1376\n","step 540 , total_loss: 1.0050, data_loss: 1.0050\n","step 560 , total_loss: 1.0981, data_loss: 1.0981\n","step 580 , total_loss: 1.0490, data_loss: 1.0490\n","step 600 , total_loss: 1.0252, data_loss: 1.0252\n","step 620 , total_loss: 1.0288, data_loss: 1.0288\n","step 640 , total_loss: 1.0458, data_loss: 1.0458\n","step 660 , total_loss: 1.0510, data_loss: 1.0510\n","step 680 , total_loss: 1.0214, data_loss: 1.0214\n","step 700 , total_loss: 1.0818, data_loss: 1.0818\n","step 720 , total_loss: 1.0993, data_loss: 1.0993\n","step 740 , total_loss: 1.0830, data_loss: 1.0830\n","step 760 , total_loss: 1.0119, data_loss: 1.0119\n","eval valid at epoch 7: auc:0.8109,logloss:0.5607,mean_mrr:0.7169,ndcg@2:0.6917,ndcg@4:0.7843,ndcg@6:0.7888,group_auc:0.8085\n","step 20 , total_loss: 1.0934, data_loss: 1.0934\n","step 40 , total_loss: 0.9992, data_loss: 0.9992\n","step 60 , total_loss: 1.0080, data_loss: 1.0080\n","step 80 , total_loss: 1.0612, data_loss: 1.0612\n","step 100 , total_loss: 0.9811, data_loss: 0.9811\n","step 120 , total_loss: 1.0013, data_loss: 1.0013\n","step 140 , total_loss: 1.0870, data_loss: 1.0870\n","step 160 , total_loss: 1.0002, data_loss: 1.0002\n","step 180 , total_loss: 1.0873, data_loss: 1.0873\n","step 200 , total_loss: 1.0903, data_loss: 1.0903\n","step 220 , total_loss: 1.0823, data_loss: 1.0823\n","step 240 , total_loss: 1.0231, data_loss: 1.0231\n","step 260 , total_loss: 1.0398, data_loss: 1.0398\n","step 280 , total_loss: 1.0805, data_loss: 1.0805\n","step 300 , total_loss: 1.0180, data_loss: 1.0180\n","step 320 , total_loss: 0.9916, data_loss: 0.9916\n","step 340 , total_loss: 1.0526, data_loss: 1.0526\n","step 360 , total_loss: 1.0248, data_loss: 1.0248\n","step 380 , total_loss: 1.0339, data_loss: 1.0339\n","step 400 , total_loss: 0.9417, data_loss: 0.9417\n","step 420 , total_loss: 1.0411, data_loss: 1.0411\n","step 440 , total_loss: 1.0688, data_loss: 1.0688\n","step 460 , total_loss: 0.9877, data_loss: 0.9877\n","step 480 , total_loss: 1.0721, data_loss: 1.0721\n","step 500 , total_loss: 0.9515, data_loss: 0.9515\n","step 520 , total_loss: 1.0539, data_loss: 1.0539\n","step 540 , total_loss: 1.0685, data_loss: 1.0685\n","step 560 , total_loss: 0.9925, data_loss: 0.9925\n","step 580 , total_loss: 0.9955, data_loss: 0.9955\n","step 600 , total_loss: 1.0674, data_loss: 1.0674\n","step 620 , total_loss: 1.0156, data_loss: 1.0156\n","step 640 , total_loss: 1.0143, data_loss: 1.0143\n","step 660 , total_loss: 1.0942, data_loss: 1.0942\n","step 680 , total_loss: 1.0169, data_loss: 1.0169\n","step 700 , total_loss: 0.9719, data_loss: 0.9719\n","step 720 , total_loss: 1.0613, data_loss: 1.0613\n","step 740 , total_loss: 1.0329, data_loss: 1.0329\n","step 760 , total_loss: 0.9636, data_loss: 0.9636\n","eval valid at epoch 8: auc:0.8127,logloss:0.5771,mean_mrr:0.7196,ndcg@2:0.6932,ndcg@4:0.7868,ndcg@6:0.7908,group_auc:0.8096\n","step 20 , total_loss: 1.0473, data_loss: 1.0473\n","step 40 , total_loss: 1.0403, data_loss: 1.0403\n","step 60 , total_loss: 1.0519, data_loss: 1.0519\n","step 80 , total_loss: 0.9790, data_loss: 0.9790\n","step 100 , total_loss: 1.0481, data_loss: 1.0481\n","step 120 , total_loss: 0.9888, data_loss: 0.9888\n","step 140 , total_loss: 1.0315, data_loss: 1.0315\n","step 160 , total_loss: 1.0212, data_loss: 1.0212\n","step 180 , total_loss: 1.0046, data_loss: 1.0046\n","step 200 , total_loss: 1.0051, data_loss: 1.0051\n","step 220 , total_loss: 1.0108, data_loss: 1.0108\n","step 240 , total_loss: 1.0102, data_loss: 1.0102\n","step 260 , total_loss: 1.0310, data_loss: 1.0310\n","step 280 , total_loss: 0.9924, data_loss: 0.9924\n","step 300 , total_loss: 1.0088, data_loss: 1.0088\n","step 320 , total_loss: 0.9583, data_loss: 0.9583\n","step 340 , total_loss: 1.0617, data_loss: 1.0617\n","step 360 , total_loss: 1.0607, data_loss: 1.0607\n","step 380 , total_loss: 0.9661, data_loss: 0.9661\n","step 400 , total_loss: 1.0310, data_loss: 1.0310\n","step 420 , total_loss: 1.1005, data_loss: 1.1005\n","step 440 , total_loss: 1.0102, data_loss: 1.0102\n","step 460 , total_loss: 1.0528, data_loss: 1.0528\n","step 480 , total_loss: 1.0046, data_loss: 1.0046\n","step 500 , total_loss: 1.0144, data_loss: 1.0144\n","step 520 , total_loss: 1.0607, data_loss: 1.0607\n","step 540 , total_loss: 0.9948, data_loss: 0.9948\n","step 560 , total_loss: 0.9939, data_loss: 0.9939\n","step 580 , total_loss: 0.9743, data_loss: 0.9743\n","step 600 , total_loss: 0.9915, data_loss: 0.9915\n","step 620 , total_loss: 0.9646, data_loss: 0.9646\n","step 640 , total_loss: 1.0421, data_loss: 1.0421\n","step 660 , total_loss: 1.0600, data_loss: 1.0600\n","step 680 , total_loss: 1.0324, data_loss: 1.0324\n","step 700 , total_loss: 0.9889, data_loss: 0.9889\n","step 720 , total_loss: 0.9287, data_loss: 0.9287\n","step 740 , total_loss: 1.0110, data_loss: 1.0110\n","step 760 , total_loss: 0.9726, data_loss: 0.9726\n","eval valid at epoch 9: auc:0.8114,logloss:0.5892,mean_mrr:0.7172,ndcg@2:0.6918,ndcg@4:0.7852,ndcg@6:0.7891,group_auc:0.8089\n","step 20 , total_loss: 1.0542, data_loss: 1.0542\n","step 40 , total_loss: 0.9667, data_loss: 0.9667\n","step 60 , total_loss: 1.0391, data_loss: 1.0391\n","step 80 , total_loss: 0.9634, data_loss: 0.9634\n","step 100 , total_loss: 1.0032, data_loss: 1.0032\n","step 120 , total_loss: 0.9609, data_loss: 0.9609\n","step 140 , total_loss: 1.0501, data_loss: 1.0501\n","step 160 , total_loss: 1.0033, data_loss: 1.0033\n","step 180 , total_loss: 0.9540, data_loss: 0.9540\n","step 200 , total_loss: 1.0001, data_loss: 1.0001\n","step 220 , total_loss: 0.9944, data_loss: 0.9944\n","step 240 , total_loss: 1.0079, data_loss: 1.0079\n","step 260 , total_loss: 0.9827, data_loss: 0.9827\n","step 280 , total_loss: 1.0144, data_loss: 1.0144\n","step 300 , total_loss: 0.9329, data_loss: 0.9329\n","step 320 , total_loss: 1.0436, data_loss: 1.0436\n","step 340 , total_loss: 1.0439, data_loss: 1.0439\n","step 360 , total_loss: 1.1196, data_loss: 1.1196\n","step 380 , total_loss: 0.9934, data_loss: 0.9934\n","step 400 , total_loss: 0.9905, data_loss: 0.9905\n","step 420 , total_loss: 0.9964, data_loss: 0.9964\n","step 440 , total_loss: 1.0093, data_loss: 1.0093\n","step 460 , total_loss: 1.0249, data_loss: 1.0249\n","step 480 , total_loss: 1.0407, data_loss: 1.0407\n","step 500 , total_loss: 1.0384, data_loss: 1.0384\n","step 520 , total_loss: 1.0133, data_loss: 1.0133\n","step 540 , total_loss: 0.9880, data_loss: 0.9880\n","step 560 , total_loss: 1.1600, data_loss: 1.1600\n","step 580 , total_loss: 1.0181, data_loss: 1.0181\n","step 600 , total_loss: 1.0346, data_loss: 1.0346\n","step 620 , total_loss: 1.0309, data_loss: 1.0309\n","step 640 , total_loss: 0.9808, data_loss: 0.9808\n","step 660 , total_loss: 1.0405, data_loss: 1.0405\n","step 680 , total_loss: 0.9382, data_loss: 0.9382\n","step 700 , total_loss: 1.0223, data_loss: 1.0223\n","step 720 , total_loss: 0.9358, data_loss: 0.9358\n","step 740 , total_loss: 0.9709, data_loss: 0.9709\n","step 760 , total_loss: 1.1065, data_loss: 1.1065\n","eval valid at epoch 10: auc:0.8174,logloss:0.5863,mean_mrr:0.7261,ndcg@2:0.7035,ndcg@4:0.7918,ndcg@6:0.7958,group_auc:0.816\n","[(1, {'auc': 0.7495, 'logloss': 0.5481, 'mean_mrr': 0.6618, 'ndcg@2': 0.6174, 'ndcg@4': 0.735, 'ndcg@6': 0.747, 'group_auc': 0.7536}), (2, {'auc': 0.7679, 'logloss': 0.5203, 'mean_mrr': 0.6731, 'ndcg@2': 0.631, 'ndcg@4': 0.7465, 'ndcg@6': 0.7556, 'group_auc': 0.7654}), (3, {'auc': 0.7815, 'logloss': 0.5453, 'mean_mrr': 0.6895, 'ndcg@2': 0.6517, 'ndcg@4': 0.7604, 'ndcg@6': 0.768, 'group_auc': 0.7804}), (4, {'auc': 0.7903, 'logloss': 0.5515, 'mean_mrr': 0.6984, 'ndcg@2': 0.6637, 'ndcg@4': 0.7686, 'ndcg@6': 0.7748, 'group_auc': 0.7896}), (5, {'auc': 0.7995, 'logloss': 0.5599, 'mean_mrr': 0.7082, 'ndcg@2': 0.6791, 'ndcg@4': 0.7772, 'ndcg@6': 0.7822, 'group_auc': 0.7992}), (6, {'auc': 0.8033, 'logloss': 0.5454, 'mean_mrr': 0.7099, 'ndcg@2': 0.6817, 'ndcg@4': 0.7786, 'ndcg@6': 0.7835, 'group_auc': 0.8014}), (7, {'auc': 0.8109, 'logloss': 0.5607, 'mean_mrr': 0.7169, 'ndcg@2': 0.6917, 'ndcg@4': 0.7843, 'ndcg@6': 0.7888, 'group_auc': 0.8085}), (8, {'auc': 0.8127, 'logloss': 0.5771, 'mean_mrr': 0.7196, 'ndcg@2': 0.6932, 'ndcg@4': 0.7868, 'ndcg@6': 0.7908, 'group_auc': 0.8096}), (9, {'auc': 0.8114, 'logloss': 0.5892, 'mean_mrr': 0.7172, 'ndcg@2': 0.6918, 'ndcg@4': 0.7852, 'ndcg@6': 0.7891, 'group_auc': 0.8089}), (10, {'auc': 0.8174, 'logloss': 0.5863, 'mean_mrr': 0.7261, 'ndcg@2': 0.7035, 'ndcg@4': 0.7918, 'ndcg@6': 0.7958, 'group_auc': 0.816})]\n","best epoch: 10\n","Time cost for training is 38.74 mins\n"]}],"source":["with Timer() as train_time:\n","    model = model.fit(train_file, valid_file, valid_num_ngs=valid_num_ngs) \n","\n","# valid_num_ngs is the number of negative lines after each positive line in your valid_file \n","# we will evaluate the performance of model on valid_file every epoch\n","print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17488,"status":"ok","timestamp":1649950583730,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"gmm3DPjbiY9N","outputId":"c182caed-d64d-46a2-a247-712b1fddc16c"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'auc': 0.8113, 'logloss': 0.6181, 'mean_mrr': 0.5542, 'ndcg@2': 0.4703, 'ndcg@4': 0.6006, 'ndcg@6': 0.651, 'group_auc': 0.8094}\n"]}],"source":["res_syn = model.run_eval(test_file, num_ngs=test_num_ngs)\n","print(res_syn)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1649950725237,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"VB7MBFNkjl5e","outputId":"6b8716b5-6a53-4c94-dd34-1f40f609e2a0"},"outputs":[{"data":{"application/scrapbook.scrap.json+json":{"data":{"auc":0.8113,"group_auc":0.8094,"logloss":0.6181,"mean_mrr":0.5542,"ndcg@2":0.4703,"ndcg@4":0.6006,"ndcg@6":0.651},"encoder":"json","name":"res_syn","version":1}},"metadata":{"scrapbook":{"data":true,"display":false,"name":"res_syn"}},"output_type":"display_data"}],"source":["sb.glue(\"res_syn\", res_syn)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4777,"status":"ok","timestamp":1649950739673,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"h2uxYGfFjpL9"},"outputs":[],"source":["model = model.predict(test_file, output_file)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1983,"status":"ok","timestamp":1649950829170,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"wGZ26pt-ujeo","outputId":"612311bb-64ec-4bee-86ad-1b325a4fad92"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\base_model.py:701: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n","  curr_hidden_nn_layer = tf.compat.v1.layers.batch_normalization(\n","C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs, training=training)\n"]},{"name":"stdout","output_type":"stream","text":["loading saved model in resources/model\\a2svd/best_model\n"]}],"source":["model_best_trained = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n","path_best_trained = os.path.join(hparams.MODEL_DIR, \"best_model\")\n","print('loading saved model in {0}'.format(path_best_trained))\n","model_best_trained.load_model(path_best_trained)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30944,"status":"ok","timestamp":1649950883835,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"fKtBHxlGu5-K","outputId":"d06c44fd-7737-41cb-944b-d0e50a27bb7b"},"outputs":[{"data":{"text/plain":["{'auc': 0.8113,\n"," 'logloss': 0.6181,\n"," 'mean_mrr': 0.5542,\n"," 'ndcg@2': 0.4703,\n"," 'ndcg@4': 0.6006,\n"," 'ndcg@6': 0.651,\n"," 'group_auc': 0.8094}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["model_best_trained.run_eval(test_file, num_ngs=test_num_ngs)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4464,"status":"ok","timestamp":1649950901128,"user":{"displayName":"조예은","userId":"06018350812551678054"},"user_tz":-540},"id":"XH7L5VOQvARx","outputId":"a7b4e142-ba8b-49ab-b5ae-8362dc0118fa"},"outputs":[{"data":{"text/plain":["<recommenders.models.deeprec.models.sequential.asvd.A2SVDModel at 0x21dce4c0910>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model_best_trained.predict(test_file, output_file)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNgc+iagyrVe0GsNEd+o6Qh","collapsed_sections":[],"mount_file_id":"1PuuQmOQ1j7N7VGZU0cASgl1CYkF5Mi3f","name":"A2SVD.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"}},"nbformat":4,"nbformat_minor":0}
