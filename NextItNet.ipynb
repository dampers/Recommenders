{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sknnn2xs-AHi",
        "outputId": "a4f15d3b-23ff-42f1-8d49-ded97e42bf52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System version: 3.7.13 (default, Mar 16 2022, 17:37:17) \n",
            "[GCC 7.5.0]\n",
            "Tensorflow version: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import logging\n",
        "import papermill as pm\n",
        "import scrapbook as sb\n",
        "from tempfile import TemporaryDirectory\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.get_logger().setLevel('ERROR') # only show error messages\n",
        "\n",
        "from recommenders.utils.timer import Timer\n",
        "from recommenders.utils.constants import SEED\n",
        "from recommenders.models.deeprec.deeprec_utils import (\n",
        "    prepare_hparams\n",
        ")\n",
        "\n",
        "from resources.data_preprocessing import data_preprocessing\n",
        "# from recommenders.datasets.amazon_reviews import download_and_extract, data_preprocessing\n",
        "from recommenders.datasets.download_utils import maybe_download\n",
        "\n",
        "\n",
        "# from recommenders.models.deeprec.models.sequential.sli_rec import SLI_RECModel as SeqModel\n",
        "####  to use the other model, use one of the following lines:\n",
        "#from recommenders.models.deeprec.models.sequential.asvd import A2SVDModel as SeqModel\n",
        "# from recommenders.models.deeprec.models.sequential.caser import CaserModel as SeqModel\n",
        "# from recommenders.models.deeprec.models.sequential.gru4rec import GRU4RecModel as SeqModel\n",
        "# from recommenders.models.deeprec.models.sequential.sum import SUMModel as SeqModel\n",
        "\n",
        "from recommenders.models.deeprec.models.sequential.nextitnet import NextItNetModel\n",
        "\n",
        "# from recommenders.models.deeprec.io.sequential_iterator import SequentialIterator\n",
        "from recommenders.models.deeprec.io.nextitnet_iterator import NextItNetIterator\n",
        "\n",
        "print(\"System version: {}\".format(sys.version))\n",
        "print(\"Tensorflow version: {}\".format(tf.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sxtfUZfP-ZWR"
      },
      "outputs": [],
      "source": [
        "##  ATTENTION: change to the corresponding config file, e.g., caser.yaml for CaserModel, sum.yaml for SUMModel\n",
        "# yaml_file = '../../recommenders/models/deeprec/config/sli_rec.yaml'  \n",
        "yaml_file = './nextitnet.yaml'  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_NnzhN4h_rI5"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "BATCH_SIZE = 400\n",
        "RANDOM_SEED = SEED  # Set None for non-deterministic result\n",
        "\n",
        "data_path = os.path.join(\"resources/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0RAMNcI3AClc"
      },
      "outputs": [],
      "source": [
        "# for test\n",
        "train_file = os.path.join(data_path, r'train_data_next')\n",
        "valid_file = os.path.join(data_path, r'valid_data_next')\n",
        "test_file = os.path.join(data_path, r'test_data_next')\n",
        "user_vocab = os.path.join(data_path, r'user_vocab_next.pkl')\n",
        "item_vocab = os.path.join(data_path, r'item_vocab_next.pkl')\n",
        "cate_vocab = os.path.join(data_path, r'cate_vocab_next.pkl')\n",
        "output_file = os.path.join(data_path, r'output_nextitnet.txt')\n",
        "\n",
        "# reviews_name = 'json'\n",
        "# meta_name = 'json'\n",
        "# reviews_file = os.path.join(data_path, reviews_name)\n",
        "# meta_file = os.path.join(data_path, meta_name)\n",
        "train_num_ngs = 4 # number of negative instances with a positive instance for training\n",
        "valid_num_ngs = 4 # number of negative instances with a positive instance for validation\n",
        "test_num_ngs = 9 # number of negative instances with a positive instance for testing\n",
        "sample_rate = 0.01 # sample a small item set for training and testing here for fast example\n",
        "\n",
        "input_files = [data_path, train_file, valid_file, test_file, user_vocab, item_vocab, cate_vocab]\n",
        "\n",
        "if not os.path.exists(train_file):\n",
        "    # download_and_extract(reviews_name, reviews_file)\n",
        "    # download_and_extract(meta_name, meta_file)\n",
        "    # data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs)\n",
        "    #### uncomment this for the NextItNet model, because it does not need to unfold the user history\n",
        "    data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs, is_history_expanding=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rwTMO3WEWaCu"
      },
      "outputs": [],
      "source": [
        "### NOTE:  \n",
        "### remember to use `_create_vocab(train_file, user_vocab, item_vocab, cate_vocab)` to generate the user_vocab, item_vocab and cate_vocab files, if you are using your own dataset rather than using our demo Amazon dataset.\n",
        "hparams = prepare_hparams(yaml_file, \n",
        "                          embed_l2=0., \n",
        "                          layer_l2=0., \n",
        "                          learning_rate=0.001,  # set to 0.01 if batch normalization is disable\n",
        "                          epochs=EPOCHS,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          show_step=20,\n",
        "                          MODEL_DIR=os.path.join(data_path, \"model\", \"sum/\"),\n",
        "                          SUMMARIES_DIR=os.path.join(data_path, \"summary\", \"sum/\"),\n",
        "                          user_vocab=user_vocab,\n",
        "                          item_vocab=item_vocab,\n",
        "                          cate_vocab=cate_vocab,\n",
        "                          need_sample=True,\n",
        "                          train_num_ngs=train_num_ngs, # provides the number of negative instances for each positive instance for loss computation.\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4Rvq7gFluVPq"
      },
      "outputs": [],
      "source": [
        "input_creator = SequentialIterator\n",
        "#### uncomment this for the NextItNet model, because it needs a special data iterator for training\n",
        "#input_creator = NextItNetIterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFNfgcKNuaVv",
        "outputId": "2fa083f0-f73d-452a-efef-12151b40c7c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/recommenders/models/deeprec/models/sequential/gru4rec.py:71: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  GRUCell(self.hidden_size),\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:573: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  initializer=self._kernel_initializer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:579: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  tf.compat.v1.constant_initializer(1.0, dtype=self.dtype)))\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:583: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  initializer=self._kernel_initializer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:589: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  tf.compat.v1.zeros_initializer(dtype=self.dtype)))\n",
            "/usr/local/lib/python3.7/dist-packages/recommenders/models/deeprec/models/base_model.py:705: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  training=self.is_train_stage,\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs, training=training)\n"
          ]
        }
      ],
      "source": [
        "model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n",
        "\n",
        "## sometimes we don't want to train a model from scratch\n",
        "## then we can load a pre-trained model like this: \n",
        "#model.load_model(r'your_model_path')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AQxPlk-uheU",
        "outputId": "55a5328a-44bd-4213-b10c-96f26313586a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'auc': 0.5271, 'logloss': 0.6931, 'mean_mrr': 0.2863, 'ndcg@2': 0.1531, 'ndcg@4': 0.2484, 'ndcg@6': 0.3276, 'group_auc': 0.5282}\n"
          ]
        }
      ],
      "source": [
        "# test_num_ngs is the number of negative lines after each positive line in your test_file\n",
        "print(model.run_eval(test_file, num_ngs=test_num_ngs)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFKQu9rGu0jq",
        "outputId": "c93b6ebf-50cc-43ea-e620-418e4537ad31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 20 , total_loss: 1.4708, data_loss: 1.4708\n",
            "step 40 , total_loss: 1.3643, data_loss: 1.3643\n",
            "step 60 , total_loss: 1.3526, data_loss: 1.3526\n",
            "step 80 , total_loss: 1.3494, data_loss: 1.3494\n",
            "step 100 , total_loss: 1.2839, data_loss: 1.2839\n",
            "step 120 , total_loss: 1.2293, data_loss: 1.2293\n",
            "step 140 , total_loss: 1.3132, data_loss: 1.3132\n",
            "step 160 , total_loss: 1.3154, data_loss: 1.3154\n",
            "step 180 , total_loss: 1.2042, data_loss: 1.2042\n",
            "step 200 , total_loss: 1.3029, data_loss: 1.3029\n",
            "step 220 , total_loss: 1.2299, data_loss: 1.2299\n",
            "step 240 , total_loss: 1.3159, data_loss: 1.3159\n",
            "step 260 , total_loss: 1.1967, data_loss: 1.1967\n",
            "step 280 , total_loss: 1.2341, data_loss: 1.2341\n",
            "step 300 , total_loss: 1.2513, data_loss: 1.2513\n",
            "step 320 , total_loss: 1.2423, data_loss: 1.2423\n",
            "step 340 , total_loss: 1.2869, data_loss: 1.2869\n",
            "step 360 , total_loss: 1.2832, data_loss: 1.2832\n",
            "step 380 , total_loss: 1.2076, data_loss: 1.2076\n",
            "step 400 , total_loss: 1.2174, data_loss: 1.2174\n",
            "step 420 , total_loss: 1.2387, data_loss: 1.2387\n",
            "step 440 , total_loss: 1.1457, data_loss: 1.1457\n",
            "step 460 , total_loss: 1.1796, data_loss: 1.1796\n",
            "step 480 , total_loss: 1.2432, data_loss: 1.2432\n",
            "step 500 , total_loss: 1.1916, data_loss: 1.1916\n",
            "step 520 , total_loss: 1.1819, data_loss: 1.1819\n",
            "step 540 , total_loss: 1.1808, data_loss: 1.1808\n",
            "step 560 , total_loss: 1.2410, data_loss: 1.2410\n",
            "step 580 , total_loss: 1.1440, data_loss: 1.1440\n",
            "step 600 , total_loss: 1.1315, data_loss: 1.1315\n",
            "step 620 , total_loss: 1.2541, data_loss: 1.2541\n",
            "step 640 , total_loss: 1.2020, data_loss: 1.2020\n",
            "step 660 , total_loss: 1.2424, data_loss: 1.2424\n",
            "step 680 , total_loss: 1.1809, data_loss: 1.1809\n",
            "step 700 , total_loss: 1.2060, data_loss: 1.2060\n",
            "step 720 , total_loss: 1.1895, data_loss: 1.1895\n",
            "step 740 , total_loss: 1.1803, data_loss: 1.1803\n",
            "step 760 , total_loss: 1.1760, data_loss: 1.1760\n",
            "step 780 , total_loss: 1.1926, data_loss: 1.1926\n",
            "step 800 , total_loss: 1.1881, data_loss: 1.1881\n",
            "step 820 , total_loss: 1.0976, data_loss: 1.0976\n",
            "step 840 , total_loss: 1.1188, data_loss: 1.1188\n",
            "step 860 , total_loss: 1.1849, data_loss: 1.1849\n",
            "step 880 , total_loss: 1.1103, data_loss: 1.1103\n",
            "step 900 , total_loss: 1.1666, data_loss: 1.1666\n",
            "step 920 , total_loss: 1.1153, data_loss: 1.1153\n",
            "eval valid at epoch 1: auc:0.7502,logloss:0.7549,mean_mrr:0.6887,ndcg@2:0.6427,ndcg@4:0.7485,ndcg@6:0.7667,group_auc:0.7606\n",
            "step 20 , total_loss: 1.1726, data_loss: 1.1726\n",
            "step 40 , total_loss: 1.1072, data_loss: 1.1072\n",
            "step 60 , total_loss: 1.2298, data_loss: 1.2298\n",
            "step 80 , total_loss: 1.0983, data_loss: 1.0983\n",
            "step 100 , total_loss: 1.1509, data_loss: 1.1509\n",
            "step 120 , total_loss: 1.1300, data_loss: 1.1300\n",
            "step 140 , total_loss: 1.1417, data_loss: 1.1417\n",
            "step 160 , total_loss: 1.1725, data_loss: 1.1725\n",
            "step 180 , total_loss: 1.0625, data_loss: 1.0625\n",
            "step 200 , total_loss: 1.1143, data_loss: 1.1143\n",
            "step 220 , total_loss: 1.0702, data_loss: 1.0702\n",
            "step 240 , total_loss: 1.1616, data_loss: 1.1616\n",
            "step 260 , total_loss: 1.1462, data_loss: 1.1462\n",
            "step 280 , total_loss: 1.2220, data_loss: 1.2220\n",
            "step 300 , total_loss: 1.2153, data_loss: 1.2153\n",
            "step 320 , total_loss: 1.1766, data_loss: 1.1766\n",
            "step 340 , total_loss: 1.1337, data_loss: 1.1337\n",
            "step 360 , total_loss: 1.1315, data_loss: 1.1315\n",
            "step 380 , total_loss: 1.1301, data_loss: 1.1301\n",
            "step 400 , total_loss: 1.0858, data_loss: 1.0858\n",
            "step 420 , total_loss: 1.1229, data_loss: 1.1229\n",
            "step 440 , total_loss: 1.1723, data_loss: 1.1723\n",
            "step 460 , total_loss: 1.1460, data_loss: 1.1460\n",
            "step 480 , total_loss: 1.0465, data_loss: 1.0465\n",
            "step 500 , total_loss: 1.1544, data_loss: 1.1544\n",
            "step 520 , total_loss: 1.1556, data_loss: 1.1556\n",
            "step 540 , total_loss: 1.1231, data_loss: 1.1231\n",
            "step 560 , total_loss: 1.1111, data_loss: 1.1111\n",
            "step 580 , total_loss: 1.1621, data_loss: 1.1621\n",
            "step 600 , total_loss: 1.1572, data_loss: 1.1572\n",
            "step 620 , total_loss: 1.0925, data_loss: 1.0925\n",
            "step 640 , total_loss: 1.1817, data_loss: 1.1817\n",
            "step 660 , total_loss: 1.1124, data_loss: 1.1124\n",
            "step 680 , total_loss: 1.1619, data_loss: 1.1619\n",
            "step 700 , total_loss: 1.0745, data_loss: 1.0745\n",
            "step 720 , total_loss: 1.0934, data_loss: 1.0934\n",
            "step 740 , total_loss: 1.1433, data_loss: 1.1433\n",
            "step 760 , total_loss: 1.1789, data_loss: 1.1789\n",
            "step 780 , total_loss: 1.0681, data_loss: 1.0681\n",
            "step 800 , total_loss: 1.1470, data_loss: 1.1470\n",
            "step 820 , total_loss: 1.0977, data_loss: 1.0977\n",
            "step 840 , total_loss: 1.0749, data_loss: 1.0749\n",
            "step 860 , total_loss: 1.1126, data_loss: 1.1126\n",
            "step 880 , total_loss: 1.0959, data_loss: 1.0959\n",
            "step 900 , total_loss: 1.0858, data_loss: 1.0858\n",
            "step 920 , total_loss: 1.1037, data_loss: 1.1037\n",
            "eval valid at epoch 2: auc:0.7695,logloss:0.6114,mean_mrr:0.7049,ndcg@2:0.6624,ndcg@4:0.7629,ndcg@6:0.779,group_auc:0.7755\n",
            "step 20 , total_loss: 1.1339, data_loss: 1.1339\n",
            "step 40 , total_loss: 1.1088, data_loss: 1.1088\n",
            "step 60 , total_loss: 1.0757, data_loss: 1.0757\n",
            "step 80 , total_loss: 1.1241, data_loss: 1.1241\n",
            "step 100 , total_loss: 1.0915, data_loss: 1.0915\n",
            "step 120 , total_loss: 1.0821, data_loss: 1.0821\n",
            "step 140 , total_loss: 1.1210, data_loss: 1.1210\n",
            "step 160 , total_loss: 1.0713, data_loss: 1.0713\n",
            "step 180 , total_loss: 1.0920, data_loss: 1.0920\n",
            "step 200 , total_loss: 1.0398, data_loss: 1.0398\n",
            "step 220 , total_loss: 1.1564, data_loss: 1.1564\n",
            "step 240 , total_loss: 1.2102, data_loss: 1.2102\n",
            "step 260 , total_loss: 1.1305, data_loss: 1.1305\n",
            "step 280 , total_loss: 1.0536, data_loss: 1.0536\n",
            "step 300 , total_loss: 1.0800, data_loss: 1.0800\n",
            "step 320 , total_loss: 1.0582, data_loss: 1.0582\n",
            "step 340 , total_loss: 1.0687, data_loss: 1.0687\n",
            "step 360 , total_loss: 1.1760, data_loss: 1.1760\n",
            "step 380 , total_loss: 1.0788, data_loss: 1.0788\n",
            "step 400 , total_loss: 1.1630, data_loss: 1.1630\n",
            "step 420 , total_loss: 1.1267, data_loss: 1.1267\n",
            "step 440 , total_loss: 1.1276, data_loss: 1.1276\n",
            "step 460 , total_loss: 1.0765, data_loss: 1.0765\n",
            "step 480 , total_loss: 0.9593, data_loss: 0.9593\n",
            "step 500 , total_loss: 1.0636, data_loss: 1.0636\n",
            "step 520 , total_loss: 1.0957, data_loss: 1.0957\n",
            "step 540 , total_loss: 1.0310, data_loss: 1.0310\n",
            "step 560 , total_loss: 1.0714, data_loss: 1.0714\n",
            "step 580 , total_loss: 1.1340, data_loss: 1.1340\n",
            "step 600 , total_loss: 1.1699, data_loss: 1.1699\n",
            "step 620 , total_loss: 1.0638, data_loss: 1.0638\n",
            "step 640 , total_loss: 1.1341, data_loss: 1.1341\n",
            "step 660 , total_loss: 1.0405, data_loss: 1.0405\n",
            "step 680 , total_loss: 1.0340, data_loss: 1.0340\n",
            "step 700 , total_loss: 1.0469, data_loss: 1.0469\n",
            "step 720 , total_loss: 1.1254, data_loss: 1.1254\n",
            "step 740 , total_loss: 1.1160, data_loss: 1.1160\n",
            "step 760 , total_loss: 1.0932, data_loss: 1.0932\n",
            "step 780 , total_loss: 1.1236, data_loss: 1.1236\n",
            "step 800 , total_loss: 1.0700, data_loss: 1.0700\n",
            "step 820 , total_loss: 1.0542, data_loss: 1.0542\n",
            "step 840 , total_loss: 1.0689, data_loss: 1.0689\n",
            "step 860 , total_loss: 1.1333, data_loss: 1.1333\n",
            "step 880 , total_loss: 1.0685, data_loss: 1.0685\n",
            "step 900 , total_loss: 1.1063, data_loss: 1.1063\n",
            "step 920 , total_loss: 1.1885, data_loss: 1.1885\n",
            "eval valid at epoch 3: auc:0.7821,logloss:0.6078,mean_mrr:0.714,ndcg@2:0.6761,ndcg@4:0.7722,ndcg@6:0.7859,group_auc:0.7865\n",
            "step 20 , total_loss: 1.1578, data_loss: 1.1578\n",
            "step 40 , total_loss: 1.0687, data_loss: 1.0687\n",
            "step 60 , total_loss: 1.1811, data_loss: 1.1811\n",
            "step 80 , total_loss: 1.0955, data_loss: 1.0955\n",
            "step 100 , total_loss: 1.0471, data_loss: 1.0471\n",
            "step 120 , total_loss: 1.1057, data_loss: 1.1057\n",
            "step 140 , total_loss: 1.0525, data_loss: 1.0525\n",
            "step 160 , total_loss: 1.0957, data_loss: 1.0957\n",
            "step 180 , total_loss: 1.0991, data_loss: 1.0991\n",
            "step 200 , total_loss: 1.0445, data_loss: 1.0445\n",
            "step 220 , total_loss: 1.0349, data_loss: 1.0349\n",
            "step 240 , total_loss: 1.0552, data_loss: 1.0552\n",
            "step 260 , total_loss: 1.0981, data_loss: 1.0981\n",
            "step 280 , total_loss: 1.0741, data_loss: 1.0741\n",
            "step 300 , total_loss: 1.0608, data_loss: 1.0608\n",
            "step 320 , total_loss: 1.0744, data_loss: 1.0744\n",
            "step 340 , total_loss: 1.0775, data_loss: 1.0775\n",
            "step 360 , total_loss: 1.0338, data_loss: 1.0338\n",
            "step 380 , total_loss: 1.0970, data_loss: 1.0970\n",
            "step 400 , total_loss: 1.0639, data_loss: 1.0639\n",
            "step 420 , total_loss: 1.1316, data_loss: 1.1316\n",
            "step 440 , total_loss: 0.9905, data_loss: 0.9905\n",
            "step 460 , total_loss: 1.0694, data_loss: 1.0694\n",
            "step 480 , total_loss: 1.1663, data_loss: 1.1663\n",
            "step 500 , total_loss: 1.0154, data_loss: 1.0154\n",
            "step 520 , total_loss: 1.1115, data_loss: 1.1115\n",
            "step 540 , total_loss: 1.0428, data_loss: 1.0428\n",
            "step 560 , total_loss: 1.0662, data_loss: 1.0662\n",
            "step 580 , total_loss: 1.0450, data_loss: 1.0450\n",
            "step 600 , total_loss: 0.9608, data_loss: 0.9608\n",
            "step 620 , total_loss: 1.0192, data_loss: 1.0192\n",
            "step 640 , total_loss: 1.0922, data_loss: 1.0922\n",
            "step 660 , total_loss: 1.1203, data_loss: 1.1203\n",
            "step 680 , total_loss: 1.0703, data_loss: 1.0703\n",
            "step 700 , total_loss: 0.9521, data_loss: 0.9521\n",
            "step 720 , total_loss: 1.0437, data_loss: 1.0437\n",
            "step 740 , total_loss: 1.1311, data_loss: 1.1311\n",
            "step 760 , total_loss: 1.0467, data_loss: 1.0467\n",
            "step 780 , total_loss: 1.0407, data_loss: 1.0407\n",
            "step 800 , total_loss: 1.0861, data_loss: 1.0861\n",
            "step 820 , total_loss: 1.0785, data_loss: 1.0785\n",
            "step 840 , total_loss: 1.0791, data_loss: 1.0791\n",
            "step 860 , total_loss: 1.0286, data_loss: 1.0286\n",
            "step 880 , total_loss: 1.0594, data_loss: 1.0594\n",
            "step 900 , total_loss: 1.0925, data_loss: 1.0925\n",
            "step 920 , total_loss: 1.1247, data_loss: 1.1247\n",
            "eval valid at epoch 4: auc:0.7937,logloss:0.6048,mean_mrr:0.7196,ndcg@2:0.6841,ndcg@4:0.7786,ndcg@6:0.7902,group_auc:0.7936\n",
            "step 20 , total_loss: 1.0599, data_loss: 1.0599\n",
            "step 40 , total_loss: 1.0403, data_loss: 1.0403\n",
            "step 60 , total_loss: 1.0651, data_loss: 1.0651\n",
            "step 80 , total_loss: 1.0449, data_loss: 1.0449\n",
            "step 100 , total_loss: 1.0812, data_loss: 1.0812\n",
            "step 120 , total_loss: 1.1308, data_loss: 1.1308\n",
            "step 140 , total_loss: 1.0189, data_loss: 1.0189\n",
            "step 160 , total_loss: 1.0655, data_loss: 1.0655\n",
            "step 180 , total_loss: 1.0442, data_loss: 1.0442\n",
            "step 200 , total_loss: 0.9922, data_loss: 0.9922\n",
            "step 220 , total_loss: 1.0303, data_loss: 1.0303\n",
            "step 240 , total_loss: 1.0705, data_loss: 1.0705\n",
            "step 260 , total_loss: 1.0778, data_loss: 1.0778\n",
            "step 280 , total_loss: 1.0222, data_loss: 1.0222\n",
            "step 300 , total_loss: 1.0234, data_loss: 1.0234\n",
            "step 320 , total_loss: 1.0891, data_loss: 1.0891\n",
            "step 340 , total_loss: 1.0338, data_loss: 1.0338\n",
            "step 360 , total_loss: 1.0564, data_loss: 1.0564\n",
            "step 380 , total_loss: 1.0715, data_loss: 1.0715\n",
            "step 400 , total_loss: 1.0512, data_loss: 1.0512\n",
            "step 420 , total_loss: 1.0200, data_loss: 1.0200\n",
            "step 440 , total_loss: 1.0756, data_loss: 1.0756\n",
            "step 460 , total_loss: 1.1106, data_loss: 1.1106\n",
            "step 480 , total_loss: 1.1114, data_loss: 1.1114\n",
            "step 500 , total_loss: 1.0144, data_loss: 1.0144\n",
            "step 520 , total_loss: 0.9570, data_loss: 0.9570\n",
            "step 540 , total_loss: 0.9955, data_loss: 0.9955\n",
            "step 560 , total_loss: 0.9531, data_loss: 0.9531\n",
            "step 580 , total_loss: 1.1069, data_loss: 1.1069\n",
            "step 600 , total_loss: 1.0551, data_loss: 1.0551\n",
            "step 620 , total_loss: 0.9873, data_loss: 0.9873\n",
            "step 640 , total_loss: 1.1075, data_loss: 1.1075\n",
            "step 660 , total_loss: 1.0690, data_loss: 1.0690\n",
            "step 680 , total_loss: 0.9810, data_loss: 0.9810\n",
            "step 700 , total_loss: 1.0972, data_loss: 1.0972\n",
            "step 720 , total_loss: 1.0317, data_loss: 1.0317\n",
            "step 740 , total_loss: 1.0823, data_loss: 1.0823\n",
            "step 760 , total_loss: 1.0852, data_loss: 1.0852\n",
            "step 780 , total_loss: 1.0618, data_loss: 1.0618\n",
            "step 800 , total_loss: 1.0495, data_loss: 1.0495\n",
            "step 820 , total_loss: 1.0935, data_loss: 1.0935\n",
            "step 840 , total_loss: 1.1436, data_loss: 1.1436\n",
            "step 860 , total_loss: 1.0504, data_loss: 1.0504\n",
            "step 880 , total_loss: 1.0838, data_loss: 1.0838\n",
            "step 900 , total_loss: 0.9384, data_loss: 0.9384\n",
            "step 920 , total_loss: 1.0502, data_loss: 1.0502\n",
            "eval valid at epoch 5: auc:0.8009,logloss:0.6401,mean_mrr:0.7265,ndcg@2:0.6921,ndcg@4:0.7853,ndcg@6:0.7954,group_auc:0.8004\n",
            "step 20 , total_loss: 1.0080, data_loss: 1.0080\n",
            "step 40 , total_loss: 1.0734, data_loss: 1.0734\n",
            "step 60 , total_loss: 1.1011, data_loss: 1.1011\n",
            "step 80 , total_loss: 1.0854, data_loss: 1.0854\n",
            "step 100 , total_loss: 1.0432, data_loss: 1.0432\n",
            "step 120 , total_loss: 1.0713, data_loss: 1.0713\n",
            "step 140 , total_loss: 1.0633, data_loss: 1.0633\n",
            "step 160 , total_loss: 1.0937, data_loss: 1.0937\n",
            "step 180 , total_loss: 1.0654, data_loss: 1.0654\n",
            "step 200 , total_loss: 1.0146, data_loss: 1.0146\n",
            "step 220 , total_loss: 1.0205, data_loss: 1.0205\n",
            "step 240 , total_loss: 0.9950, data_loss: 0.9950\n",
            "step 260 , total_loss: 1.0455, data_loss: 1.0455\n",
            "step 280 , total_loss: 1.0132, data_loss: 1.0132\n",
            "step 300 , total_loss: 1.0203, data_loss: 1.0203\n",
            "step 320 , total_loss: 0.9684, data_loss: 0.9684\n",
            "step 340 , total_loss: 1.0538, data_loss: 1.0538\n",
            "step 360 , total_loss: 1.0411, data_loss: 1.0411\n",
            "step 380 , total_loss: 1.0733, data_loss: 1.0733\n",
            "step 400 , total_loss: 0.9785, data_loss: 0.9785\n",
            "step 420 , total_loss: 1.0909, data_loss: 1.0909\n",
            "step 440 , total_loss: 1.0205, data_loss: 1.0205\n",
            "step 460 , total_loss: 1.0197, data_loss: 1.0197\n",
            "step 480 , total_loss: 1.0807, data_loss: 1.0807\n",
            "step 500 , total_loss: 1.0426, data_loss: 1.0426\n",
            "step 520 , total_loss: 1.0191, data_loss: 1.0191\n",
            "step 540 , total_loss: 1.0335, data_loss: 1.0335\n",
            "step 560 , total_loss: 0.9589, data_loss: 0.9589\n",
            "step 580 , total_loss: 1.0524, data_loss: 1.0524\n",
            "step 600 , total_loss: 1.0477, data_loss: 1.0477\n",
            "step 620 , total_loss: 1.0134, data_loss: 1.0134\n",
            "step 640 , total_loss: 0.9640, data_loss: 0.9640\n",
            "step 660 , total_loss: 1.0332, data_loss: 1.0332\n",
            "step 680 , total_loss: 1.0485, data_loss: 1.0485\n",
            "step 700 , total_loss: 1.0335, data_loss: 1.0335\n",
            "step 720 , total_loss: 1.0054, data_loss: 1.0054\n",
            "step 740 , total_loss: 1.0571, data_loss: 1.0571\n",
            "step 760 , total_loss: 1.0498, data_loss: 1.0498\n",
            "step 780 , total_loss: 1.0237, data_loss: 1.0237\n",
            "step 800 , total_loss: 1.0472, data_loss: 1.0472\n",
            "step 820 , total_loss: 1.0286, data_loss: 1.0286\n",
            "step 840 , total_loss: 1.0118, data_loss: 1.0118\n",
            "step 860 , total_loss: 1.0751, data_loss: 1.0751\n",
            "step 880 , total_loss: 1.0540, data_loss: 1.0540\n",
            "step 900 , total_loss: 1.0309, data_loss: 1.0309\n",
            "step 920 , total_loss: 1.0579, data_loss: 1.0579\n",
            "eval valid at epoch 6: auc:0.8058,logloss:0.6517,mean_mrr:0.7308,ndcg@2:0.6983,ndcg@4:0.7887,ndcg@6:0.7987,group_auc:0.8044\n",
            "step 20 , total_loss: 1.0698, data_loss: 1.0698\n",
            "step 40 , total_loss: 0.9696, data_loss: 0.9696\n",
            "step 60 , total_loss: 1.0426, data_loss: 1.0426\n",
            "step 80 , total_loss: 0.9493, data_loss: 0.9493\n",
            "step 100 , total_loss: 1.0889, data_loss: 1.0889\n",
            "step 120 , total_loss: 1.0217, data_loss: 1.0217\n",
            "step 140 , total_loss: 1.0353, data_loss: 1.0353\n",
            "step 160 , total_loss: 0.9864, data_loss: 0.9864\n",
            "step 180 , total_loss: 0.9759, data_loss: 0.9759\n",
            "step 200 , total_loss: 1.0739, data_loss: 1.0739\n",
            "step 220 , total_loss: 1.1087, data_loss: 1.1087\n",
            "step 240 , total_loss: 0.9518, data_loss: 0.9518\n",
            "step 260 , total_loss: 1.0267, data_loss: 1.0267\n",
            "step 280 , total_loss: 1.0390, data_loss: 1.0390\n",
            "step 300 , total_loss: 1.0252, data_loss: 1.0252\n",
            "step 320 , total_loss: 1.0203, data_loss: 1.0203\n",
            "step 340 , total_loss: 1.0213, data_loss: 1.0213\n",
            "step 360 , total_loss: 0.9989, data_loss: 0.9989\n",
            "step 380 , total_loss: 0.9650, data_loss: 0.9650\n",
            "step 400 , total_loss: 1.0685, data_loss: 1.0685\n",
            "step 420 , total_loss: 0.9844, data_loss: 0.9844\n",
            "step 440 , total_loss: 0.9854, data_loss: 0.9854\n",
            "step 460 , total_loss: 1.0390, data_loss: 1.0390\n",
            "step 480 , total_loss: 1.0317, data_loss: 1.0317\n",
            "step 500 , total_loss: 1.0617, data_loss: 1.0617\n",
            "step 520 , total_loss: 0.9748, data_loss: 0.9748\n",
            "step 540 , total_loss: 1.0209, data_loss: 1.0209\n",
            "step 560 , total_loss: 0.9436, data_loss: 0.9436\n",
            "step 580 , total_loss: 0.9529, data_loss: 0.9529\n",
            "step 600 , total_loss: 1.0590, data_loss: 1.0590\n",
            "step 620 , total_loss: 1.0466, data_loss: 1.0466\n",
            "step 640 , total_loss: 1.0473, data_loss: 1.0473\n",
            "step 660 , total_loss: 1.0289, data_loss: 1.0289\n",
            "step 680 , total_loss: 0.9555, data_loss: 0.9555\n",
            "step 700 , total_loss: 0.9785, data_loss: 0.9785\n",
            "step 720 , total_loss: 1.0187, data_loss: 1.0187\n",
            "step 740 , total_loss: 0.9552, data_loss: 0.9552\n",
            "step 760 , total_loss: 1.0450, data_loss: 1.0450\n",
            "step 780 , total_loss: 1.0153, data_loss: 1.0153\n",
            "step 800 , total_loss: 1.0210, data_loss: 1.0210\n",
            "step 820 , total_loss: 0.9244, data_loss: 0.9244\n",
            "step 840 , total_loss: 1.0449, data_loss: 1.0449\n",
            "step 860 , total_loss: 1.0714, data_loss: 1.0714\n",
            "step 880 , total_loss: 1.0139, data_loss: 1.0139\n",
            "step 900 , total_loss: 1.0456, data_loss: 1.0456\n",
            "step 920 , total_loss: 1.0679, data_loss: 1.0679\n",
            "eval valid at epoch 7: auc:0.8059,logloss:0.6803,mean_mrr:0.7336,ndcg@2:0.7022,ndcg@4:0.7915,ndcg@6:0.8008,group_auc:0.8073\n",
            "step 20 , total_loss: 1.0632, data_loss: 1.0632\n",
            "step 40 , total_loss: 1.0281, data_loss: 1.0281\n",
            "step 60 , total_loss: 1.0779, data_loss: 1.0779\n",
            "step 80 , total_loss: 1.0851, data_loss: 1.0851\n",
            "step 100 , total_loss: 1.0363, data_loss: 1.0363\n",
            "step 120 , total_loss: 1.0025, data_loss: 1.0025\n",
            "step 140 , total_loss: 0.9991, data_loss: 0.9991\n",
            "step 160 , total_loss: 1.0007, data_loss: 1.0007\n",
            "step 180 , total_loss: 1.0215, data_loss: 1.0215\n",
            "step 200 , total_loss: 1.0092, data_loss: 1.0092\n",
            "step 220 , total_loss: 1.0595, data_loss: 1.0595\n",
            "step 240 , total_loss: 0.9891, data_loss: 0.9891\n",
            "step 260 , total_loss: 1.0141, data_loss: 1.0141\n",
            "step 280 , total_loss: 0.9310, data_loss: 0.9310\n",
            "step 300 , total_loss: 0.9879, data_loss: 0.9879\n",
            "step 320 , total_loss: 1.0421, data_loss: 1.0421\n",
            "step 340 , total_loss: 1.0712, data_loss: 1.0712\n",
            "step 360 , total_loss: 1.0833, data_loss: 1.0833\n",
            "step 380 , total_loss: 1.0010, data_loss: 1.0010\n",
            "step 400 , total_loss: 1.0156, data_loss: 1.0156\n",
            "step 420 , total_loss: 0.8890, data_loss: 0.8890\n",
            "step 440 , total_loss: 1.0488, data_loss: 1.0488\n",
            "step 460 , total_loss: 0.9457, data_loss: 0.9457\n",
            "step 480 , total_loss: 0.9416, data_loss: 0.9416\n",
            "step 500 , total_loss: 0.9837, data_loss: 0.9837\n",
            "step 520 , total_loss: 0.9645, data_loss: 0.9645\n",
            "step 540 , total_loss: 1.0308, data_loss: 1.0308\n",
            "step 560 , total_loss: 0.9729, data_loss: 0.9729\n",
            "step 580 , total_loss: 0.9636, data_loss: 0.9636\n",
            "step 600 , total_loss: 1.0437, data_loss: 1.0437\n",
            "step 620 , total_loss: 1.0945, data_loss: 1.0945\n",
            "step 640 , total_loss: 0.9621, data_loss: 0.9621\n",
            "step 660 , total_loss: 1.0906, data_loss: 1.0906\n",
            "step 680 , total_loss: 0.9058, data_loss: 0.9058\n",
            "step 700 , total_loss: 0.9926, data_loss: 0.9926\n",
            "step 720 , total_loss: 0.9366, data_loss: 0.9366\n",
            "step 740 , total_loss: 1.0054, data_loss: 1.0054\n",
            "step 760 , total_loss: 0.9893, data_loss: 0.9893\n",
            "step 780 , total_loss: 0.9943, data_loss: 0.9943\n",
            "step 800 , total_loss: 1.0668, data_loss: 1.0668\n",
            "step 820 , total_loss: 1.0251, data_loss: 1.0251\n",
            "step 840 , total_loss: 1.0183, data_loss: 1.0183\n",
            "step 860 , total_loss: 0.9457, data_loss: 0.9457\n",
            "step 880 , total_loss: 1.0290, data_loss: 1.0290\n",
            "step 900 , total_loss: 0.9375, data_loss: 0.9375\n",
            "step 920 , total_loss: 1.0356, data_loss: 1.0356\n",
            "eval valid at epoch 8: auc:0.813,logloss:0.6367,mean_mrr:0.7398,ndcg@2:0.7101,ndcg@4:0.7975,ndcg@6:0.8055,group_auc:0.8133\n",
            "step 20 , total_loss: 0.9325, data_loss: 0.9325\n",
            "step 40 , total_loss: 1.0096, data_loss: 1.0096\n",
            "step 60 , total_loss: 1.0535, data_loss: 1.0535\n",
            "step 80 , total_loss: 0.9952, data_loss: 0.9952\n",
            "step 100 , total_loss: 1.0132, data_loss: 1.0132\n",
            "step 120 , total_loss: 0.9109, data_loss: 0.9109\n",
            "step 140 , total_loss: 1.0584, data_loss: 1.0584\n",
            "step 160 , total_loss: 0.9667, data_loss: 0.9667\n",
            "step 180 , total_loss: 0.9903, data_loss: 0.9903\n",
            "step 200 , total_loss: 0.9922, data_loss: 0.9922\n",
            "step 220 , total_loss: 1.0071, data_loss: 1.0071\n",
            "step 240 , total_loss: 0.9378, data_loss: 0.9378\n",
            "step 260 , total_loss: 0.9511, data_loss: 0.9511\n",
            "step 280 , total_loss: 1.0012, data_loss: 1.0012\n",
            "step 300 , total_loss: 0.9148, data_loss: 0.9148\n",
            "step 320 , total_loss: 0.9769, data_loss: 0.9769\n",
            "step 340 , total_loss: 1.0827, data_loss: 1.0827\n",
            "step 360 , total_loss: 0.9978, data_loss: 0.9978\n",
            "step 380 , total_loss: 1.0075, data_loss: 1.0075\n",
            "step 400 , total_loss: 1.0385, data_loss: 1.0385\n",
            "step 420 , total_loss: 1.0560, data_loss: 1.0560\n",
            "step 440 , total_loss: 1.0009, data_loss: 1.0009\n",
            "step 460 , total_loss: 1.0247, data_loss: 1.0247\n",
            "step 480 , total_loss: 1.0147, data_loss: 1.0147\n",
            "step 500 , total_loss: 0.9537, data_loss: 0.9537\n",
            "step 520 , total_loss: 0.9775, data_loss: 0.9775\n",
            "step 540 , total_loss: 1.0407, data_loss: 1.0407\n",
            "step 560 , total_loss: 1.0098, data_loss: 1.0098\n",
            "step 580 , total_loss: 1.0451, data_loss: 1.0451\n",
            "step 600 , total_loss: 0.9254, data_loss: 0.9254\n",
            "step 620 , total_loss: 0.9954, data_loss: 0.9954\n",
            "step 640 , total_loss: 1.0255, data_loss: 1.0255\n",
            "step 660 , total_loss: 0.9533, data_loss: 0.9533\n",
            "step 680 , total_loss: 0.9247, data_loss: 0.9247\n",
            "step 700 , total_loss: 0.9611, data_loss: 0.9611\n",
            "step 720 , total_loss: 1.0143, data_loss: 1.0143\n",
            "step 740 , total_loss: 1.0351, data_loss: 1.0351\n",
            "step 760 , total_loss: 1.0299, data_loss: 1.0299\n",
            "step 780 , total_loss: 1.0153, data_loss: 1.0153\n",
            "step 800 , total_loss: 0.9099, data_loss: 0.9099\n",
            "step 820 , total_loss: 1.0689, data_loss: 1.0689\n",
            "step 840 , total_loss: 1.0011, data_loss: 1.0011\n",
            "step 860 , total_loss: 0.9366, data_loss: 0.9366\n",
            "step 880 , total_loss: 0.9377, data_loss: 0.9377\n",
            "step 900 , total_loss: 0.9486, data_loss: 0.9486\n",
            "step 920 , total_loss: 1.0500, data_loss: 1.0500\n",
            "eval valid at epoch 9: auc:0.8145,logloss:0.6836,mean_mrr:0.744,ndcg@2:0.7157,ndcg@4:0.8005,ndcg@6:0.8086,group_auc:0.8169\n",
            "step 20 , total_loss: 0.9940, data_loss: 0.9940\n",
            "step 40 , total_loss: 0.9239, data_loss: 0.9239\n",
            "step 60 , total_loss: 0.9202, data_loss: 0.9202\n",
            "step 80 , total_loss: 0.9475, data_loss: 0.9475\n",
            "step 100 , total_loss: 0.9213, data_loss: 0.9213\n",
            "step 120 , total_loss: 1.0137, data_loss: 1.0137\n",
            "step 140 , total_loss: 1.0281, data_loss: 1.0281\n",
            "step 160 , total_loss: 0.9437, data_loss: 0.9437\n",
            "step 180 , total_loss: 0.9985, data_loss: 0.9985\n",
            "step 200 , total_loss: 0.9343, data_loss: 0.9343\n",
            "step 220 , total_loss: 1.0651, data_loss: 1.0651\n",
            "step 240 , total_loss: 0.9791, data_loss: 0.9791\n",
            "step 260 , total_loss: 0.9860, data_loss: 0.9860\n",
            "step 280 , total_loss: 0.9532, data_loss: 0.9532\n",
            "step 300 , total_loss: 1.0277, data_loss: 1.0277\n",
            "step 320 , total_loss: 1.0200, data_loss: 1.0200\n",
            "step 340 , total_loss: 1.0348, data_loss: 1.0348\n",
            "step 360 , total_loss: 1.0340, data_loss: 1.0340\n",
            "step 380 , total_loss: 0.9393, data_loss: 0.9393\n",
            "step 400 , total_loss: 0.9697, data_loss: 0.9697\n",
            "step 420 , total_loss: 1.0001, data_loss: 1.0001\n",
            "step 440 , total_loss: 0.8908, data_loss: 0.8908\n",
            "step 460 , total_loss: 0.9530, data_loss: 0.9530\n",
            "step 480 , total_loss: 1.0798, data_loss: 1.0798\n",
            "step 500 , total_loss: 1.0114, data_loss: 1.0114\n",
            "step 520 , total_loss: 0.9797, data_loss: 0.9797\n",
            "step 540 , total_loss: 0.9805, data_loss: 0.9805\n",
            "step 560 , total_loss: 0.9736, data_loss: 0.9736\n",
            "step 580 , total_loss: 0.9649, data_loss: 0.9649\n",
            "step 600 , total_loss: 0.9602, data_loss: 0.9602\n",
            "step 620 , total_loss: 0.9584, data_loss: 0.9584\n",
            "step 640 , total_loss: 0.9391, data_loss: 0.9391\n",
            "step 660 , total_loss: 0.9803, data_loss: 0.9803\n",
            "step 680 , total_loss: 1.0039, data_loss: 1.0039\n",
            "step 700 , total_loss: 0.9915, data_loss: 0.9915\n",
            "step 720 , total_loss: 1.0667, data_loss: 1.0667\n",
            "step 740 , total_loss: 0.9897, data_loss: 0.9897\n",
            "step 760 , total_loss: 1.0890, data_loss: 1.0890\n",
            "step 780 , total_loss: 1.0279, data_loss: 1.0279\n",
            "step 800 , total_loss: 1.0299, data_loss: 1.0299\n",
            "step 820 , total_loss: 0.9310, data_loss: 0.9310\n",
            "step 840 , total_loss: 0.9458, data_loss: 0.9458\n",
            "step 860 , total_loss: 1.0330, data_loss: 1.0330\n",
            "step 880 , total_loss: 0.9893, data_loss: 0.9893\n",
            "step 900 , total_loss: 1.0463, data_loss: 1.0463\n",
            "step 920 , total_loss: 1.0084, data_loss: 1.0084\n",
            "eval valid at epoch 10: auc:0.8156,logloss:0.687,mean_mrr:0.7442,ndcg@2:0.7157,ndcg@4:0.8013,ndcg@6:0.8089,group_auc:0.8179\n",
            "[(1, {'auc': 0.7502, 'logloss': 0.7549, 'mean_mrr': 0.6887, 'ndcg@2': 0.6427, 'ndcg@4': 0.7485, 'ndcg@6': 0.7667, 'group_auc': 0.7606}), (2, {'auc': 0.7695, 'logloss': 0.6114, 'mean_mrr': 0.7049, 'ndcg@2': 0.6624, 'ndcg@4': 0.7629, 'ndcg@6': 0.779, 'group_auc': 0.7755}), (3, {'auc': 0.7821, 'logloss': 0.6078, 'mean_mrr': 0.714, 'ndcg@2': 0.6761, 'ndcg@4': 0.7722, 'ndcg@6': 0.7859, 'group_auc': 0.7865}), (4, {'auc': 0.7937, 'logloss': 0.6048, 'mean_mrr': 0.7196, 'ndcg@2': 0.6841, 'ndcg@4': 0.7786, 'ndcg@6': 0.7902, 'group_auc': 0.7936}), (5, {'auc': 0.8009, 'logloss': 0.6401, 'mean_mrr': 0.7265, 'ndcg@2': 0.6921, 'ndcg@4': 0.7853, 'ndcg@6': 0.7954, 'group_auc': 0.8004}), (6, {'auc': 0.8058, 'logloss': 0.6517, 'mean_mrr': 0.7308, 'ndcg@2': 0.6983, 'ndcg@4': 0.7887, 'ndcg@6': 0.7987, 'group_auc': 0.8044}), (7, {'auc': 0.8059, 'logloss': 0.6803, 'mean_mrr': 0.7336, 'ndcg@2': 0.7022, 'ndcg@4': 0.7915, 'ndcg@6': 0.8008, 'group_auc': 0.8073}), (8, {'auc': 0.813, 'logloss': 0.6367, 'mean_mrr': 0.7398, 'ndcg@2': 0.7101, 'ndcg@4': 0.7975, 'ndcg@6': 0.8055, 'group_auc': 0.8133}), (9, {'auc': 0.8145, 'logloss': 0.6836, 'mean_mrr': 0.744, 'ndcg@2': 0.7157, 'ndcg@4': 0.8005, 'ndcg@6': 0.8086, 'group_auc': 0.8169}), (10, {'auc': 0.8156, 'logloss': 0.687, 'mean_mrr': 0.7442, 'ndcg@2': 0.7157, 'ndcg@4': 0.8013, 'ndcg@6': 0.8089, 'group_auc': 0.8179})]\n",
            "best epoch: 10\n",
            "Time cost for training is 116.06 mins\n"
          ]
        }
      ],
      "source": [
        "with Timer() as train_time:\n",
        "    model = model.fit(train_file, valid_file, valid_num_ngs=valid_num_ngs) \n",
        "\n",
        "# valid_num_ngs is the number of negative lines after each positive line in your valid_file \n",
        "# we will evaluate the performance of model on valid_file every epoch\n",
        "print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmm3DPjbiY9N",
        "outputId": "6dbb1a1d-8b36-49b1-ef5e-f4a807dddfde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'auc': 0.8103, 'logloss': 0.7379, 'mean_mrr': 0.5931, 'ndcg@2': 0.5191, 'ndcg@4': 0.629, 'ndcg@6': 0.6715, 'group_auc': 0.8128}\n"
          ]
        }
      ],
      "source": [
        "res_syn = model.run_eval(test_file, num_ngs=test_num_ngs)\n",
        "print(res_syn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VB7MBFNkjl5e",
        "outputId": "12b143c9-1d98-4d99-9136-8c779de2d832"
      },
      "outputs": [
        {
          "data": {
            "application/scrapbook.scrap.json+json": {
              "data": {
                "auc": 0.8103,
                "group_auc": 0.8128,
                "logloss": 0.7379,
                "mean_mrr": 0.5931,
                "ndcg@2": 0.5191,
                "ndcg@4": 0.629,
                "ndcg@6": 0.6715
              },
              "encoder": "json",
              "name": "res_syn",
              "version": 1
            }
          },
          "metadata": {
            "scrapbook": {
              "data": true,
              "display": false,
              "name": "res_syn"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sb.glue(\"res_syn\", res_syn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "h2uxYGfFjpL9"
      },
      "outputs": [],
      "source": [
        "model = model.predict(test_file, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGZ26pt-ujeo",
        "outputId": "5cbe4b07-34e3-4891-c64b-40b2a70a6fa7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/recommenders/models/deeprec/models/sequential/gru4rec.py:71: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  GRUCell(self.hidden_size),\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:573: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  initializer=self._kernel_initializer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:579: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  tf.compat.v1.constant_initializer(1.0, dtype=self.dtype)))\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:583: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  initializer=self._kernel_initializer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:589: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  tf.compat.v1.zeros_initializer(dtype=self.dtype)))\n",
            "/usr/local/lib/python3.7/dist-packages/recommenders/models/deeprec/models/base_model.py:705: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  training=self.is_train_stage,\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs, training=training)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading saved model in resources/Recommenders/model/best_model\n"
          ]
        }
      ],
      "source": [
        "model_best_trained = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n",
        "path_best_trained = os.path.join(hparams.MODEL_DIR, \"best_model\")\n",
        "print('loading saved model in {0}'.format(path_best_trained))\n",
        "model_best_trained.load_model(path_best_trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKtBHxlGu5-K",
        "outputId": "d398f3b9-bbba-4707-fae1-7c1c817a7e66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'auc': 0.8103,\n",
              " 'group_auc': 0.8128,\n",
              " 'logloss': 0.7379,\n",
              " 'mean_mrr': 0.5931,\n",
              " 'ndcg@2': 0.5191,\n",
              " 'ndcg@4': 0.629,\n",
              " 'ndcg@6': 0.6715}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_best_trained.run_eval(test_file, num_ngs=test_num_ngs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH7L5VOQvARx",
        "outputId": "46721757-0218-4a41-8557-fcd7806b0852"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<recommenders.models.deeprec.models.sequential.gru4rec.GRU4RecModel at 0x7fd5ce182f50>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_best_trained.predict(test_file, output_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "GRU4REC.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
