{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sknnn2xs-AHi",
        "outputId": "a4f15d3b-23ff-42f1-8d49-ded97e42bf52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System version: 3.8.9 (tags/v3.8.9:a743f81, Apr  6 2021, 14:02:34) [MSC v.1928 64 bit (AMD64)]\n",
            "Tensorflow version: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import logging\n",
        "import papermill as pm\n",
        "import scrapbook as sb\n",
        "from tempfile import TemporaryDirectory\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.get_logger().setLevel('ERROR') # only show error messages\n",
        "\n",
        "from recommenders.utils.timer import Timer\n",
        "from recommenders.utils.constants import SEED\n",
        "from recommenders.models.deeprec.deeprec_utils import (\n",
        "    prepare_hparams\n",
        ")\n",
        "\n",
        "from resources.data_preprocessing import data_preprocessing\n",
        "# from recommenders.datasets.amazon_reviews import download_and_extract, data_preprocessing\n",
        "from recommenders.datasets.download_utils import maybe_download\n",
        "\n",
        "\n",
        "# from recommenders.models.deeprec.models.sequential.sli_rec import SLI_RECModel as SeqModel\n",
        "####  to use the other model, use one of the following lines:\n",
        "#from recommenders.models.deeprec.models.sequential.asvd import A2SVDModel as SeqModel\n",
        "# from recommenders.models.deeprec.models.sequential.caser import CaserModel as SeqModel\n",
        "# from recommenders.models.deeprec.models.sequential.gru4rec import GRU4RecModel as SeqModel\n",
        "from recommenders.models.deeprec.models.sequential.sum import SUMModel as SeqModel\n",
        "\n",
        "#from recommenders.models.deeprec.models.sequential.nextitnet import NextItNetModel\n",
        "\n",
        "from recommenders.models.deeprec.io.sequential_iterator import SequentialIterator\n",
        "#from recommenders.models.deeprec.io.nextitnet_iterator import NextItNetIterator\n",
        "\n",
        "print(\"System version: {}\".format(sys.version))\n",
        "print(\"Tensorflow version: {}\".format(tf.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sxtfUZfP-ZWR"
      },
      "outputs": [],
      "source": [
        "##  ATTENTION: change to the corresponding config file, e.g., caser.yaml for CaserModel, sum.yaml for SUMModel\n",
        "# yaml_file = '../../recommenders/models/deeprec/config/sli_rec.yaml'  \n",
        "yaml_file = './sum.yaml'  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_NnzhN4h_rI5"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "BATCH_SIZE = 400\n",
        "RANDOM_SEED = SEED  # Set None for non-deterministic result\n",
        "\n",
        "data_path = os.path.join(\"resources/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0RAMNcI3AClc"
      },
      "outputs": [],
      "source": [
        "# for test\n",
        "train_file = os.path.join(data_path, r'train_data')\n",
        "valid_file = os.path.join(data_path, r'valid_data')\n",
        "test_file = os.path.join(data_path, r'test_data')\n",
        "user_vocab = os.path.join(data_path, r'user_vocab.pkl')\n",
        "item_vocab = os.path.join(data_path, r'item_vocab.pkl')\n",
        "cate_vocab = os.path.join(data_path, r'cate_vocab.pkl')\n",
        "output_file = os.path.join(data_path, r'output_sum.txt')\n",
        "\n",
        "# reviews_name = 'json'\n",
        "# meta_name = 'json'\n",
        "# reviews_file = os.path.join(data_path, reviews_name)\n",
        "# meta_file = os.path.join(data_path, meta_name)\n",
        "train_num_ngs = 4 # number of negative instances with a positive instance for training\n",
        "valid_num_ngs = 4 # number of negative instances with a positive instance for validation\n",
        "test_num_ngs = 9 # number of negative instances with a positive instance for testing\n",
        "sample_rate = 0.01 # sample a small item set for training and testing here for fast example\n",
        "\n",
        "input_files = [data_path, train_file, valid_file, test_file, user_vocab, item_vocab, cate_vocab]\n",
        "\n",
        "if not os.path.exists(train_file):\n",
        "    # download_and_extract(reviews_name, reviews_file)\n",
        "    # download_and_extract(meta_name, meta_file)\n",
        "    data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs)\n",
        "    #### uncomment this for the NextItNet model, because it does not need to unfold the user history\n",
        "    # data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs, is_history_expanding=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rwTMO3WEWaCu"
      },
      "outputs": [],
      "source": [
        "### NOTE:  \n",
        "### remember to use `_create_vocab(train_file, user_vocab, item_vocab, cate_vocab)` to generate the user_vocab, item_vocab and cate_vocab files, if you are using your own dataset rather than using our demo Amazon dataset.\n",
        "hparams = prepare_hparams(yaml_file, \n",
        "                          embed_l2=0., \n",
        "                          layer_l2=0., \n",
        "                          learning_rate=0.001,  # set to 0.01 if batch normalization is disable\n",
        "                          epochs=EPOCHS,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          show_step=20,\n",
        "                          MODEL_DIR=os.path.join(data_path, \"model\", \"sum/\"),\n",
        "                          SUMMARIES_DIR=os.path.join(data_path, \"summary\", \"sum/\"),\n",
        "                          user_vocab=user_vocab,\n",
        "                          item_vocab=item_vocab,\n",
        "                          cate_vocab=cate_vocab,\n",
        "                          need_sample=True,\n",
        "                          train_num_ngs=train_num_ngs, # provides the number of negative instances for each positive instance for loss computation.\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4Rvq7gFluVPq"
      },
      "outputs": [],
      "source": [
        "input_creator = SequentialIterator\n",
        "#### uncomment this for the NextItNet model, because it needs a special data iterator for training\n",
        "#input_creator = NextItNetIterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFNfgcKNuaVv",
        "outputId": "2fa083f0-f73d-452a-efef-12151b40c7c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:78: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._erase_W = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:81: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._erase_b = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:91: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._reset_W = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:94: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._reset_b = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:104: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._add_W = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:107: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._add_b = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:116: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self.heads = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:120: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._beta = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:127: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._alpha = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\base_model.py:701: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  curr_hidden_nn_layer = tf.compat.v1.layers.batch_normalization(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs, training=training)\n"
          ]
        }
      ],
      "source": [
        "model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n",
        "\n",
        "## sometimes we don't want to train a model from scratch\n",
        "## then we can load a pre-trained model like this: \n",
        "#model.load_model(r'your_model_path')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AQxPlk-uheU",
        "outputId": "55a5328a-44bd-4213-b10c-96f26313586a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'auc': 0.5034, 'logloss': 0.6932, 'mean_mrr': 0.2824, 'ndcg@2': 0.1467, 'ndcg@4': 0.2445, 'ndcg@6': 0.319, 'group_auc': 0.5034}\n"
          ]
        }
      ],
      "source": [
        "# test_num_ngs is the number of negative lines after each positive line in your test_file\n",
        "print(model.run_eval(test_file, num_ngs=test_num_ngs)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFKQu9rGu0jq",
        "outputId": "c93b6ebf-50cc-43ea-e620-418e4537ad31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 20 , total_loss: 1.5022, data_loss: 1.5022\n",
            "step 40 , total_loss: 1.4078, data_loss: 1.4078\n",
            "step 60 , total_loss: 1.3560, data_loss: 1.3560\n",
            "step 80 , total_loss: 1.3733, data_loss: 1.3733\n",
            "step 100 , total_loss: 1.2930, data_loss: 1.2930\n",
            "step 120 , total_loss: 1.2456, data_loss: 1.2456\n",
            "step 140 , total_loss: 1.3020, data_loss: 1.3020\n",
            "step 160 , total_loss: 1.3483, data_loss: 1.3483\n",
            "step 180 , total_loss: 1.2271, data_loss: 1.2271\n",
            "step 200 , total_loss: 1.2689, data_loss: 1.2689\n",
            "step 220 , total_loss: 1.2495, data_loss: 1.2495\n",
            "step 240 , total_loss: 1.3215, data_loss: 1.3215\n",
            "step 260 , total_loss: 1.2066, data_loss: 1.2066\n",
            "step 280 , total_loss: 1.2452, data_loss: 1.2452\n",
            "step 300 , total_loss: 1.2855, data_loss: 1.2855\n",
            "step 320 , total_loss: 1.2453, data_loss: 1.2453\n",
            "step 340 , total_loss: 1.2696, data_loss: 1.2696\n",
            "step 360 , total_loss: 1.2773, data_loss: 1.2773\n",
            "step 380 , total_loss: 1.1904, data_loss: 1.1904\n",
            "step 400 , total_loss: 1.1971, data_loss: 1.1971\n",
            "step 420 , total_loss: 1.2519, data_loss: 1.2519\n",
            "step 440 , total_loss: 1.1596, data_loss: 1.1596\n",
            "step 460 , total_loss: 1.1536, data_loss: 1.1536\n",
            "step 480 , total_loss: 1.2016, data_loss: 1.2016\n",
            "step 500 , total_loss: 1.1759, data_loss: 1.1759\n",
            "step 520 , total_loss: 1.1545, data_loss: 1.1545\n",
            "step 540 , total_loss: 1.1582, data_loss: 1.1582\n",
            "step 560 , total_loss: 1.2127, data_loss: 1.2127\n",
            "step 580 , total_loss: 1.1177, data_loss: 1.1177\n",
            "step 600 , total_loss: 1.0874, data_loss: 1.0874\n",
            "step 620 , total_loss: 1.1918, data_loss: 1.1918\n",
            "step 640 , total_loss: 1.2109, data_loss: 1.2109\n",
            "step 660 , total_loss: 1.1784, data_loss: 1.1784\n",
            "step 680 , total_loss: 1.1311, data_loss: 1.1311\n",
            "step 700 , total_loss: 1.1716, data_loss: 1.1716\n",
            "step 720 , total_loss: 1.1390, data_loss: 1.1390\n",
            "step 740 , total_loss: 1.1382, data_loss: 1.1382\n",
            "step 760 , total_loss: 1.1454, data_loss: 1.1454\n",
            "step 780 , total_loss: 1.1950, data_loss: 1.1950\n",
            "step 800 , total_loss: 1.1542, data_loss: 1.1542\n",
            "step 820 , total_loss: 1.0898, data_loss: 1.0898\n",
            "step 840 , total_loss: 1.1560, data_loss: 1.1560\n",
            "step 860 , total_loss: 1.1498, data_loss: 1.1498\n",
            "step 880 , total_loss: 1.0814, data_loss: 1.0814\n",
            "step 900 , total_loss: 1.1442, data_loss: 1.1442\n",
            "step 920 , total_loss: 1.1168, data_loss: 1.1168\n",
            "eval valid at epoch 1: auc:0.6912,logloss:0.8115,mean_mrr:0.6308,ndcg@2:0.5634,ndcg@4:0.6986,ndcg@6:0.7229,group_auc:0.7062\n",
            "step 20 , total_loss: 1.1345, data_loss: 1.1345\n",
            "step 40 , total_loss: 1.0709, data_loss: 1.0709\n",
            "step 60 , total_loss: 1.1358, data_loss: 1.1358\n",
            "step 80 , total_loss: 1.0650, data_loss: 1.0650\n",
            "step 100 , total_loss: 1.1231, data_loss: 1.1231\n",
            "step 120 , total_loss: 1.0403, data_loss: 1.0403\n",
            "step 140 , total_loss: 1.1056, data_loss: 1.1056\n",
            "step 160 , total_loss: 1.1339, data_loss: 1.1339\n",
            "step 180 , total_loss: 1.0259, data_loss: 1.0259\n",
            "step 200 , total_loss: 1.0841, data_loss: 1.0841\n",
            "step 220 , total_loss: 1.0030, data_loss: 1.0030\n",
            "step 240 , total_loss: 1.1244, data_loss: 1.1244\n",
            "step 260 , total_loss: 1.0884, data_loss: 1.0884\n",
            "step 280 , total_loss: 1.1658, data_loss: 1.1658\n",
            "step 300 , total_loss: 1.1671, data_loss: 1.1671\n",
            "step 320 , total_loss: 1.1006, data_loss: 1.1006\n",
            "step 340 , total_loss: 1.1154, data_loss: 1.1154\n",
            "step 360 , total_loss: 1.0544, data_loss: 1.0544\n",
            "step 380 , total_loss: 1.0716, data_loss: 1.0716\n",
            "step 400 , total_loss: 1.0380, data_loss: 1.0380\n",
            "step 420 , total_loss: 1.0555, data_loss: 1.0555\n",
            "step 440 , total_loss: 1.1283, data_loss: 1.1283\n",
            "step 460 , total_loss: 1.1273, data_loss: 1.1273\n",
            "step 480 , total_loss: 0.9579, data_loss: 0.9579\n",
            "step 500 , total_loss: 1.1159, data_loss: 1.1159\n",
            "step 520 , total_loss: 1.0945, data_loss: 1.0945\n",
            "step 540 , total_loss: 1.0858, data_loss: 1.0858\n",
            "step 560 , total_loss: 1.0481, data_loss: 1.0481\n",
            "step 580 , total_loss: 1.0908, data_loss: 1.0908\n",
            "step 600 , total_loss: 1.0611, data_loss: 1.0611\n",
            "step 620 , total_loss: 1.0650, data_loss: 1.0650\n",
            "step 640 , total_loss: 1.1159, data_loss: 1.1159\n",
            "step 660 , total_loss: 1.0282, data_loss: 1.0282\n",
            "step 680 , total_loss: 1.0700, data_loss: 1.0700\n",
            "step 700 , total_loss: 1.0250, data_loss: 1.0250\n",
            "step 720 , total_loss: 1.0512, data_loss: 1.0512\n",
            "step 740 , total_loss: 1.1053, data_loss: 1.1053\n",
            "step 760 , total_loss: 1.1130, data_loss: 1.1130\n",
            "step 780 , total_loss: 1.0320, data_loss: 1.0320\n",
            "step 800 , total_loss: 1.0542, data_loss: 1.0542\n",
            "step 820 , total_loss: 1.0327, data_loss: 1.0327\n",
            "step 840 , total_loss: 1.0101, data_loss: 1.0101\n",
            "step 860 , total_loss: 1.0661, data_loss: 1.0661\n",
            "step 880 , total_loss: 0.9924, data_loss: 0.9924\n",
            "step 900 , total_loss: 1.0436, data_loss: 1.0436\n",
            "step 920 , total_loss: 1.0682, data_loss: 1.0682\n",
            "eval valid at epoch 2: auc:0.6322,logloss:0.6381,mean_mrr:0.6521,ndcg@2:0.5958,ndcg@4:0.7178,ndcg@6:0.7391,group_auc:0.729\n",
            "step 20 , total_loss: 1.0431, data_loss: 1.0431\n",
            "step 40 , total_loss: 1.0801, data_loss: 1.0801\n",
            "step 60 , total_loss: 0.9906, data_loss: 0.9906\n",
            "step 80 , total_loss: 1.0520, data_loss: 1.0520\n",
            "step 100 , total_loss: 0.9926, data_loss: 0.9926\n",
            "step 120 , total_loss: 1.0606, data_loss: 1.0606\n",
            "step 140 , total_loss: 1.0969, data_loss: 1.0969\n",
            "step 160 , total_loss: 1.0235, data_loss: 1.0235\n",
            "step 180 , total_loss: 1.0032, data_loss: 1.0032\n",
            "step 200 , total_loss: 0.9653, data_loss: 0.9653\n",
            "step 220 , total_loss: 1.0974, data_loss: 1.0974\n",
            "step 240 , total_loss: 1.1479, data_loss: 1.1479\n",
            "step 260 , total_loss: 1.0333, data_loss: 1.0333\n",
            "step 280 , total_loss: 0.9821, data_loss: 0.9821\n",
            "step 300 , total_loss: 0.9889, data_loss: 0.9889\n",
            "step 320 , total_loss: 0.9929, data_loss: 0.9929\n",
            "step 340 , total_loss: 1.0453, data_loss: 1.0453\n",
            "step 360 , total_loss: 1.1150, data_loss: 1.1150\n",
            "step 380 , total_loss: 1.0216, data_loss: 1.0216\n",
            "step 400 , total_loss: 1.0956, data_loss: 1.0956\n",
            "step 420 , total_loss: 1.0193, data_loss: 1.0193\n",
            "step 440 , total_loss: 1.0138, data_loss: 1.0138\n",
            "step 460 , total_loss: 0.9567, data_loss: 0.9567\n",
            "step 480 , total_loss: 0.9305, data_loss: 0.9305\n",
            "step 500 , total_loss: 0.9960, data_loss: 0.9960\n",
            "step 520 , total_loss: 1.0626, data_loss: 1.0626\n",
            "step 540 , total_loss: 0.9352, data_loss: 0.9352\n",
            "step 560 , total_loss: 1.0157, data_loss: 1.0157\n",
            "step 580 , total_loss: 1.0680, data_loss: 1.0680\n",
            "step 600 , total_loss: 1.0864, data_loss: 1.0864\n",
            "step 620 , total_loss: 1.0030, data_loss: 1.0030\n",
            "step 640 , total_loss: 1.1118, data_loss: 1.1118\n",
            "step 660 , total_loss: 0.9603, data_loss: 0.9603\n",
            "step 680 , total_loss: 0.9833, data_loss: 0.9833\n",
            "step 700 , total_loss: 0.9838, data_loss: 0.9838\n",
            "step 720 , total_loss: 1.0317, data_loss: 1.0317\n",
            "step 740 , total_loss: 1.0333, data_loss: 1.0333\n",
            "step 760 , total_loss: 1.0156, data_loss: 1.0156\n",
            "step 780 , total_loss: 1.0960, data_loss: 1.0960\n",
            "step 800 , total_loss: 0.9707, data_loss: 0.9707\n",
            "step 820 , total_loss: 0.9986, data_loss: 0.9986\n",
            "step 840 , total_loss: 1.0279, data_loss: 1.0279\n",
            "step 860 , total_loss: 1.0227, data_loss: 1.0227\n",
            "step 880 , total_loss: 1.0402, data_loss: 1.0402\n",
            "step 900 , total_loss: 1.0454, data_loss: 1.0454\n",
            "step 920 , total_loss: 1.1609, data_loss: 1.1609\n",
            "eval valid at epoch 3: auc:0.7697,logloss:0.6716,mean_mrr:0.7118,ndcg@2:0.675,ndcg@4:0.7697,ndcg@6:0.7843,group_auc:0.7859\n",
            "step 20 , total_loss: 1.0678, data_loss: 1.0678\n",
            "step 40 , total_loss: 0.9637, data_loss: 0.9637\n",
            "step 60 , total_loss: 1.0766, data_loss: 1.0766\n",
            "step 80 , total_loss: 1.0139, data_loss: 1.0139\n",
            "step 100 , total_loss: 0.9827, data_loss: 0.9827\n",
            "step 120 , total_loss: 1.0322, data_loss: 1.0322\n",
            "step 140 , total_loss: 1.0103, data_loss: 1.0103\n",
            "step 160 , total_loss: 1.0252, data_loss: 1.0252\n",
            "step 180 , total_loss: 1.0514, data_loss: 1.0514\n",
            "step 200 , total_loss: 0.9946, data_loss: 0.9946\n",
            "step 220 , total_loss: 0.9301, data_loss: 0.9301\n",
            "step 240 , total_loss: 1.0008, data_loss: 1.0008\n",
            "step 260 , total_loss: 0.9831, data_loss: 0.9831\n",
            "step 280 , total_loss: 0.9380, data_loss: 0.9380\n",
            "step 300 , total_loss: 1.0138, data_loss: 1.0138\n",
            "step 320 , total_loss: 1.0365, data_loss: 1.0365\n",
            "step 340 , total_loss: 1.0405, data_loss: 1.0405\n",
            "step 360 , total_loss: 0.9486, data_loss: 0.9486\n",
            "step 380 , total_loss: 0.9944, data_loss: 0.9944\n",
            "step 400 , total_loss: 1.0063, data_loss: 1.0063\n",
            "step 420 , total_loss: 1.0848, data_loss: 1.0848\n",
            "step 440 , total_loss: 0.9786, data_loss: 0.9786\n",
            "step 460 , total_loss: 1.0408, data_loss: 1.0408\n",
            "step 480 , total_loss: 1.0804, data_loss: 1.0804\n",
            "step 500 , total_loss: 0.9470, data_loss: 0.9470\n",
            "step 520 , total_loss: 1.0159, data_loss: 1.0159\n",
            "step 540 , total_loss: 0.9588, data_loss: 0.9588\n",
            "step 560 , total_loss: 1.0184, data_loss: 1.0184\n",
            "step 580 , total_loss: 1.0260, data_loss: 1.0260\n",
            "step 600 , total_loss: 0.8603, data_loss: 0.8603\n",
            "step 620 , total_loss: 0.9093, data_loss: 0.9093\n",
            "step 640 , total_loss: 1.0063, data_loss: 1.0063\n",
            "step 660 , total_loss: 1.0492, data_loss: 1.0492\n",
            "step 680 , total_loss: 1.0263, data_loss: 1.0263\n",
            "step 700 , total_loss: 0.9271, data_loss: 0.9271\n",
            "step 720 , total_loss: 0.9458, data_loss: 0.9458\n",
            "step 740 , total_loss: 1.0703, data_loss: 1.0703\n",
            "step 760 , total_loss: 0.9597, data_loss: 0.9597\n",
            "step 780 , total_loss: 0.9008, data_loss: 0.9008\n",
            "step 800 , total_loss: 1.0371, data_loss: 1.0371\n",
            "step 820 , total_loss: 0.9604, data_loss: 0.9604\n",
            "step 840 , total_loss: 0.9902, data_loss: 0.9902\n",
            "step 860 , total_loss: 0.9260, data_loss: 0.9260\n",
            "step 880 , total_loss: 0.9439, data_loss: 0.9439\n",
            "step 900 , total_loss: 1.0385, data_loss: 1.0385\n",
            "step 920 , total_loss: 0.9942, data_loss: 0.9942\n",
            "eval valid at epoch 4: auc:0.7836,logloss:0.9284,mean_mrr:0.7175,ndcg@2:0.6792,ndcg@4:0.7777,ndcg@6:0.7886,group_auc:0.7915\n",
            "step 20 , total_loss: 0.9468, data_loss: 0.9468\n",
            "step 40 , total_loss: 0.9267, data_loss: 0.9267\n",
            "step 60 , total_loss: 0.9639, data_loss: 0.9639\n",
            "step 80 , total_loss: 0.9668, data_loss: 0.9668\n",
            "step 100 , total_loss: 0.9776, data_loss: 0.9776\n",
            "step 120 , total_loss: 1.0246, data_loss: 1.0246\n",
            "step 140 , total_loss: 0.8870, data_loss: 0.8870\n",
            "step 160 , total_loss: 0.9552, data_loss: 0.9552\n",
            "step 180 , total_loss: 0.9532, data_loss: 0.9532\n",
            "step 200 , total_loss: 0.9466, data_loss: 0.9466\n",
            "step 220 , total_loss: 0.9629, data_loss: 0.9629\n",
            "step 240 , total_loss: 1.0054, data_loss: 1.0054\n",
            "step 260 , total_loss: 1.0082, data_loss: 1.0082\n",
            "step 280 , total_loss: 0.9760, data_loss: 0.9760\n",
            "step 300 , total_loss: 0.9391, data_loss: 0.9391\n",
            "step 320 , total_loss: 1.0402, data_loss: 1.0402\n",
            "step 340 , total_loss: 0.9720, data_loss: 0.9720\n",
            "step 360 , total_loss: 0.9742, data_loss: 0.9742\n",
            "step 380 , total_loss: 1.0038, data_loss: 1.0038\n",
            "step 400 , total_loss: 0.9688, data_loss: 0.9688\n",
            "step 420 , total_loss: 0.9282, data_loss: 0.9282\n",
            "step 440 , total_loss: 0.9585, data_loss: 0.9585\n",
            "step 460 , total_loss: 1.0101, data_loss: 1.0101\n",
            "step 480 , total_loss: 0.9934, data_loss: 0.9934\n",
            "step 500 , total_loss: 0.9278, data_loss: 0.9278\n",
            "step 520 , total_loss: 0.8484, data_loss: 0.8484\n",
            "step 540 , total_loss: 0.9279, data_loss: 0.9279\n",
            "step 560 , total_loss: 0.8649, data_loss: 0.8649\n",
            "step 580 , total_loss: 1.0021, data_loss: 1.0021\n",
            "step 600 , total_loss: 0.9952, data_loss: 0.9952\n",
            "step 620 , total_loss: 0.9604, data_loss: 0.9604\n",
            "step 640 , total_loss: 0.9790, data_loss: 0.9790\n",
            "step 660 , total_loss: 1.0014, data_loss: 1.0014\n",
            "step 680 , total_loss: 0.8829, data_loss: 0.8829\n",
            "step 700 , total_loss: 0.9593, data_loss: 0.9593\n",
            "step 720 , total_loss: 0.8955, data_loss: 0.8955\n",
            "step 740 , total_loss: 0.9826, data_loss: 0.9826\n",
            "step 760 , total_loss: 1.0139, data_loss: 1.0139\n",
            "step 780 , total_loss: 0.9638, data_loss: 0.9638\n",
            "step 800 , total_loss: 0.9324, data_loss: 0.9324\n",
            "step 820 , total_loss: 0.9652, data_loss: 0.9652\n",
            "step 840 , total_loss: 1.0224, data_loss: 1.0224\n",
            "step 860 , total_loss: 0.9742, data_loss: 0.9742\n",
            "step 880 , total_loss: 1.0087, data_loss: 1.0087\n",
            "step 900 , total_loss: 0.8943, data_loss: 0.8943\n",
            "step 920 , total_loss: 0.8998, data_loss: 0.8998\n",
            "eval valid at epoch 5: auc:0.7876,logloss:0.7179,mean_mrr:0.7221,ndcg@2:0.6862,ndcg@4:0.7814,ndcg@6:0.7921,group_auc:0.7967\n",
            "step 20 , total_loss: 0.8929, data_loss: 0.8929\n",
            "step 40 , total_loss: 0.9626, data_loss: 0.9626\n",
            "step 60 , total_loss: 0.9693, data_loss: 0.9693\n",
            "step 80 , total_loss: 0.9617, data_loss: 0.9617\n",
            "step 100 , total_loss: 0.9695, data_loss: 0.9695\n",
            "step 120 , total_loss: 0.9590, data_loss: 0.9590\n",
            "step 140 , total_loss: 1.0008, data_loss: 1.0008\n",
            "step 160 , total_loss: 0.9129, data_loss: 0.9129\n",
            "step 180 , total_loss: 0.9172, data_loss: 0.9172\n",
            "step 200 , total_loss: 0.9194, data_loss: 0.9194\n",
            "step 220 , total_loss: 0.9417, data_loss: 0.9417\n",
            "step 240 , total_loss: 0.9430, data_loss: 0.9430\n",
            "step 260 , total_loss: 0.9593, data_loss: 0.9593\n",
            "step 280 , total_loss: 0.9584, data_loss: 0.9584\n",
            "step 300 , total_loss: 0.9324, data_loss: 0.9324\n",
            "step 320 , total_loss: 0.8573, data_loss: 0.8573\n",
            "step 340 , total_loss: 0.9702, data_loss: 0.9702\n",
            "step 360 , total_loss: 0.9877, data_loss: 0.9877\n",
            "step 380 , total_loss: 0.9671, data_loss: 0.9671\n",
            "step 400 , total_loss: 0.9218, data_loss: 0.9218\n",
            "step 420 , total_loss: 0.8777, data_loss: 0.8777\n",
            "step 440 , total_loss: 0.8965, data_loss: 0.8965\n",
            "step 460 , total_loss: 0.8837, data_loss: 0.8837\n",
            "step 480 , total_loss: 1.0070, data_loss: 1.0070\n",
            "step 500 , total_loss: 0.8902, data_loss: 0.8902\n",
            "step 520 , total_loss: 0.8948, data_loss: 0.8948\n",
            "step 540 , total_loss: 0.9434, data_loss: 0.9434\n",
            "step 560 , total_loss: 0.8458, data_loss: 0.8458\n",
            "step 580 , total_loss: 0.9475, data_loss: 0.9475\n",
            "step 600 , total_loss: 0.9056, data_loss: 0.9056\n",
            "step 620 , total_loss: 0.8638, data_loss: 0.8638\n",
            "step 640 , total_loss: 0.8939, data_loss: 0.8939\n",
            "step 660 , total_loss: 0.8829, data_loss: 0.8829\n",
            "step 680 , total_loss: 0.8594, data_loss: 0.8594\n",
            "step 700 , total_loss: 0.8498, data_loss: 0.8498\n",
            "step 720 , total_loss: 0.8997, data_loss: 0.8997\n",
            "step 740 , total_loss: 0.9313, data_loss: 0.9313\n",
            "step 760 , total_loss: 0.9268, data_loss: 0.9268\n",
            "step 780 , total_loss: 0.8494, data_loss: 0.8494\n",
            "step 800 , total_loss: 0.9396, data_loss: 0.9396\n",
            "step 820 , total_loss: 0.8713, data_loss: 0.8713\n",
            "step 840 , total_loss: 0.8708, data_loss: 0.8708\n",
            "step 860 , total_loss: 0.9334, data_loss: 0.9334\n",
            "step 880 , total_loss: 0.9331, data_loss: 0.9331\n",
            "step 900 , total_loss: 0.9275, data_loss: 0.9275\n",
            "step 920 , total_loss: 0.9701, data_loss: 0.9701\n",
            "eval valid at epoch 6: auc:0.813,logloss:0.7126,mean_mrr:0.741,ndcg@2:0.7139,ndcg@4:0.7999,ndcg@6:0.8066,group_auc:0.8183\n",
            "step 20 , total_loss: 0.9327, data_loss: 0.9327\n",
            "step 40 , total_loss: 0.8657, data_loss: 0.8657\n",
            "step 60 , total_loss: 0.9112, data_loss: 0.9112\n",
            "step 80 , total_loss: 0.8544, data_loss: 0.8544\n",
            "step 100 , total_loss: 0.9038, data_loss: 0.9038\n",
            "step 120 , total_loss: 0.9270, data_loss: 0.9270\n",
            "step 140 , total_loss: 0.9298, data_loss: 0.9298\n",
            "step 160 , total_loss: 0.8755, data_loss: 0.8755\n",
            "step 180 , total_loss: 0.8734, data_loss: 0.8734\n",
            "step 200 , total_loss: 0.8965, data_loss: 0.8965\n",
            "step 220 , total_loss: 0.9201, data_loss: 0.9201\n",
            "step 240 , total_loss: 0.8604, data_loss: 0.8604\n",
            "step 260 , total_loss: 0.8810, data_loss: 0.8810\n",
            "step 280 , total_loss: 0.8798, data_loss: 0.8798\n",
            "step 300 , total_loss: 0.8778, data_loss: 0.8778\n",
            "step 320 , total_loss: 0.9033, data_loss: 0.9033\n",
            "step 340 , total_loss: 0.8658, data_loss: 0.8658\n",
            "step 360 , total_loss: 0.8873, data_loss: 0.8873\n",
            "step 380 , total_loss: 0.8380, data_loss: 0.8380\n",
            "step 400 , total_loss: 0.9330, data_loss: 0.9330\n",
            "step 420 , total_loss: 0.8594, data_loss: 0.8594\n",
            "step 440 , total_loss: 0.8910, data_loss: 0.8910\n",
            "step 460 , total_loss: 0.9402, data_loss: 0.9402\n",
            "step 480 , total_loss: 0.9053, data_loss: 0.9053\n",
            "step 500 , total_loss: 0.9169, data_loss: 0.9169\n",
            "step 520 , total_loss: 0.8613, data_loss: 0.8613\n",
            "step 540 , total_loss: 0.8728, data_loss: 0.8728\n",
            "step 560 , total_loss: 0.7588, data_loss: 0.7588\n",
            "step 580 , total_loss: 0.8277, data_loss: 0.8277\n",
            "step 600 , total_loss: 0.8736, data_loss: 0.8736\n",
            "step 620 , total_loss: 0.9023, data_loss: 0.9023\n",
            "step 640 , total_loss: 0.8987, data_loss: 0.8987\n",
            "step 660 , total_loss: 0.9077, data_loss: 0.9077\n",
            "step 680 , total_loss: 0.8268, data_loss: 0.8268\n",
            "step 700 , total_loss: 0.8758, data_loss: 0.8758\n",
            "step 720 , total_loss: 0.8436, data_loss: 0.8436\n",
            "step 740 , total_loss: 0.8320, data_loss: 0.8320\n",
            "step 760 , total_loss: 0.8473, data_loss: 0.8473\n",
            "step 780 , total_loss: 0.8652, data_loss: 0.8652\n",
            "step 800 , total_loss: 0.9085, data_loss: 0.9085\n",
            "step 820 , total_loss: 0.7677, data_loss: 0.7677\n",
            "step 840 , total_loss: 0.9265, data_loss: 0.9265\n",
            "step 860 , total_loss: 0.9383, data_loss: 0.9383\n",
            "step 880 , total_loss: 0.8790, data_loss: 0.8790\n",
            "step 900 , total_loss: 0.9276, data_loss: 0.9276\n",
            "step 920 , total_loss: 0.9962, data_loss: 0.9962\n",
            "eval valid at epoch 7: auc:0.8191,logloss:0.8465,mean_mrr:0.7415,ndcg@2:0.7144,ndcg@4:0.8007,ndcg@6:0.807,group_auc:0.8193\n",
            "step 20 , total_loss: 0.9405, data_loss: 0.9405\n",
            "step 40 , total_loss: 0.8485, data_loss: 0.8485\n",
            "step 60 , total_loss: 0.9205, data_loss: 0.9205\n",
            "step 80 , total_loss: 0.9283, data_loss: 0.9283\n",
            "step 100 , total_loss: 0.8939, data_loss: 0.8939\n",
            "step 120 , total_loss: 0.8340, data_loss: 0.8340\n",
            "step 140 , total_loss: 0.8522, data_loss: 0.8522\n",
            "step 160 , total_loss: 0.8001, data_loss: 0.8001\n",
            "step 180 , total_loss: 0.8760, data_loss: 0.8760\n",
            "step 200 , total_loss: 0.8816, data_loss: 0.8816\n",
            "step 220 , total_loss: 0.9050, data_loss: 0.9050\n",
            "step 240 , total_loss: 0.8592, data_loss: 0.8592\n",
            "step 260 , total_loss: 0.8564, data_loss: 0.8564\n",
            "step 280 , total_loss: 0.7874, data_loss: 0.7874\n",
            "step 300 , total_loss: 0.8448, data_loss: 0.8448\n",
            "step 320 , total_loss: 0.9160, data_loss: 0.9160\n",
            "step 340 , total_loss: 0.9456, data_loss: 0.9456\n",
            "step 360 , total_loss: 0.9407, data_loss: 0.9407\n",
            "step 380 , total_loss: 0.9028, data_loss: 0.9028\n",
            "step 400 , total_loss: 0.8688, data_loss: 0.8688\n",
            "step 420 , total_loss: 0.7719, data_loss: 0.7719\n",
            "step 440 , total_loss: 0.8791, data_loss: 0.8791\n",
            "step 460 , total_loss: 0.8435, data_loss: 0.8435\n",
            "step 480 , total_loss: 0.8076, data_loss: 0.8076\n",
            "step 500 , total_loss: 0.7915, data_loss: 0.7915\n",
            "step 520 , total_loss: 0.8417, data_loss: 0.8417\n",
            "step 540 , total_loss: 0.8672, data_loss: 0.8672\n",
            "step 560 , total_loss: 0.8092, data_loss: 0.8092\n",
            "step 580 , total_loss: 0.7821, data_loss: 0.7821\n",
            "step 600 , total_loss: 0.9032, data_loss: 0.9032\n",
            "step 620 , total_loss: 0.8650, data_loss: 0.8650\n",
            "step 640 , total_loss: 0.8319, data_loss: 0.8319\n",
            "step 660 , total_loss: 0.9316, data_loss: 0.9316\n",
            "step 680 , total_loss: 0.7662, data_loss: 0.7662\n",
            "step 700 , total_loss: 0.7927, data_loss: 0.7927\n",
            "step 720 , total_loss: 0.8077, data_loss: 0.8077\n",
            "step 740 , total_loss: 0.8537, data_loss: 0.8537\n",
            "step 760 , total_loss: 0.8217, data_loss: 0.8217\n",
            "step 780 , total_loss: 0.8313, data_loss: 0.8313\n",
            "step 800 , total_loss: 0.8856, data_loss: 0.8856\n",
            "step 820 , total_loss: 0.8180, data_loss: 0.8180\n",
            "step 840 , total_loss: 0.8304, data_loss: 0.8304\n",
            "step 860 , total_loss: 0.8008, data_loss: 0.8008\n",
            "step 880 , total_loss: 0.8858, data_loss: 0.8858\n",
            "step 900 , total_loss: 0.8099, data_loss: 0.8099\n",
            "step 920 , total_loss: 0.8563, data_loss: 0.8563\n",
            "eval valid at epoch 8: auc:0.8435,logloss:0.7396,mean_mrr:0.7673,ndcg@2:0.7483,ndcg@4:0.8224,ndcg@6:0.8264,group_auc:0.8421\n",
            "step 20 , total_loss: 0.7415, data_loss: 0.7415\n",
            "step 40 , total_loss: 0.8533, data_loss: 0.8533\n",
            "step 60 , total_loss: 0.8473, data_loss: 0.8473\n",
            "step 80 , total_loss: 0.7968, data_loss: 0.7968\n",
            "step 100 , total_loss: 0.8149, data_loss: 0.8149\n",
            "step 120 , total_loss: 0.7388, data_loss: 0.7388\n",
            "step 140 , total_loss: 0.8532, data_loss: 0.8532\n",
            "step 160 , total_loss: 0.7506, data_loss: 0.7506\n",
            "step 180 , total_loss: 0.8146, data_loss: 0.8146\n",
            "step 200 , total_loss: 0.8042, data_loss: 0.8042\n",
            "step 220 , total_loss: 0.8433, data_loss: 0.8433\n",
            "step 240 , total_loss: 0.8276, data_loss: 0.8276\n",
            "step 260 , total_loss: 0.7649, data_loss: 0.7649\n",
            "step 280 , total_loss: 0.8524, data_loss: 0.8524\n",
            "step 300 , total_loss: 0.7685, data_loss: 0.7685\n",
            "step 320 , total_loss: 0.7949, data_loss: 0.7949\n",
            "step 340 , total_loss: 0.9130, data_loss: 0.9130\n",
            "step 360 , total_loss: 0.8365, data_loss: 0.8365\n",
            "step 380 , total_loss: 0.8193, data_loss: 0.8193\n",
            "step 400 , total_loss: 0.8691, data_loss: 0.8691\n",
            "step 420 , total_loss: 0.9183, data_loss: 0.9183\n",
            "step 440 , total_loss: 0.8658, data_loss: 0.8658\n",
            "step 460 , total_loss: 0.8885, data_loss: 0.8885\n",
            "step 480 , total_loss: 0.8585, data_loss: 0.8585\n",
            "step 500 , total_loss: 0.7424, data_loss: 0.7424\n",
            "step 520 , total_loss: 0.7958, data_loss: 0.7958\n",
            "step 540 , total_loss: 0.8667, data_loss: 0.8667\n",
            "step 560 , total_loss: 0.7983, data_loss: 0.7983\n",
            "step 580 , total_loss: 0.8592, data_loss: 0.8592\n",
            "step 600 , total_loss: 0.8130, data_loss: 0.8130\n",
            "step 620 , total_loss: 0.8034, data_loss: 0.8034\n",
            "step 640 , total_loss: 0.7914, data_loss: 0.7914\n",
            "step 660 , total_loss: 0.7903, data_loss: 0.7903\n",
            "step 680 , total_loss: 0.7883, data_loss: 0.7883\n",
            "step 700 , total_loss: 0.7971, data_loss: 0.7971\n",
            "step 720 , total_loss: 0.8810, data_loss: 0.8810\n",
            "step 740 , total_loss: 0.8193, data_loss: 0.8193\n",
            "step 760 , total_loss: 0.8602, data_loss: 0.8602\n",
            "step 780 , total_loss: 0.8586, data_loss: 0.8586\n",
            "step 800 , total_loss: 0.8172, data_loss: 0.8172\n",
            "step 820 , total_loss: 0.8700, data_loss: 0.8700\n",
            "step 840 , total_loss: 0.7913, data_loss: 0.7913\n",
            "step 860 , total_loss: 0.7999, data_loss: 0.7999\n",
            "step 880 , total_loss: 0.7622, data_loss: 0.7622\n",
            "step 900 , total_loss: 0.7586, data_loss: 0.7586\n",
            "step 920 , total_loss: 0.9074, data_loss: 0.9074\n",
            "eval valid at epoch 9: auc:0.8492,logloss:0.7977,mean_mrr:0.7726,ndcg@2:0.7567,ndcg@4:0.8267,ndcg@6:0.8305,group_auc:0.8477\n",
            "step 20 , total_loss: 0.8038, data_loss: 0.8038\n",
            "step 40 , total_loss: 0.7917, data_loss: 0.7917\n",
            "step 60 , total_loss: 0.6865, data_loss: 0.6865\n",
            "step 80 , total_loss: 0.8043, data_loss: 0.8043\n",
            "step 100 , total_loss: 0.7894, data_loss: 0.7894\n",
            "step 120 , total_loss: 0.8177, data_loss: 0.8177\n",
            "step 140 , total_loss: 0.8864, data_loss: 0.8864\n",
            "step 160 , total_loss: 0.7853, data_loss: 0.7853\n",
            "step 180 , total_loss: 0.8142, data_loss: 0.8142\n",
            "step 200 , total_loss: 0.7650, data_loss: 0.7650\n",
            "step 220 , total_loss: 0.8736, data_loss: 0.8736\n",
            "step 240 , total_loss: 0.8013, data_loss: 0.8013\n",
            "step 260 , total_loss: 0.8072, data_loss: 0.8072\n",
            "step 280 , total_loss: 0.7598, data_loss: 0.7598\n",
            "step 300 , total_loss: 0.8419, data_loss: 0.8419\n",
            "step 320 , total_loss: 0.8703, data_loss: 0.8703\n",
            "step 340 , total_loss: 0.8036, data_loss: 0.8036\n",
            "step 360 , total_loss: 0.8714, data_loss: 0.8714\n",
            "step 380 , total_loss: 0.7553, data_loss: 0.7553\n",
            "step 400 , total_loss: 0.8373, data_loss: 0.8373\n",
            "step 420 , total_loss: 0.8516, data_loss: 0.8516\n",
            "step 440 , total_loss: 0.7204, data_loss: 0.7204\n",
            "step 460 , total_loss: 0.7714, data_loss: 0.7714\n",
            "step 480 , total_loss: 0.8797, data_loss: 0.8797\n",
            "step 500 , total_loss: 0.7869, data_loss: 0.7869\n",
            "step 520 , total_loss: 0.7830, data_loss: 0.7830\n",
            "step 540 , total_loss: 0.8116, data_loss: 0.8116\n",
            "step 560 , total_loss: 0.7999, data_loss: 0.7999\n",
            "step 580 , total_loss: 0.7701, data_loss: 0.7701\n",
            "step 600 , total_loss: 0.7946, data_loss: 0.7946\n",
            "step 620 , total_loss: 0.7392, data_loss: 0.7392\n",
            "step 640 , total_loss: 0.7370, data_loss: 0.7370\n",
            "step 660 , total_loss: 0.7956, data_loss: 0.7956\n",
            "step 680 , total_loss: 0.8490, data_loss: 0.8490\n",
            "step 700 , total_loss: 0.8075, data_loss: 0.8075\n",
            "step 720 , total_loss: 0.8878, data_loss: 0.8878\n",
            "step 740 , total_loss: 0.7971, data_loss: 0.7971\n",
            "step 760 , total_loss: 0.8665, data_loss: 0.8665\n",
            "step 780 , total_loss: 0.8147, data_loss: 0.8147\n",
            "step 800 , total_loss: 0.8461, data_loss: 0.8461\n",
            "step 820 , total_loss: 0.7703, data_loss: 0.7703\n",
            "step 840 , total_loss: 0.7732, data_loss: 0.7732\n",
            "step 860 , total_loss: 0.8558, data_loss: 0.8558\n",
            "step 880 , total_loss: 0.8374, data_loss: 0.8374\n",
            "step 900 , total_loss: 0.7747, data_loss: 0.7747\n",
            "step 920 , total_loss: 0.8335, data_loss: 0.8335\n",
            "eval valid at epoch 10: auc:0.8533,logloss:0.7512,mean_mrr:0.7777,ndcg@2:0.7636,ndcg@4:0.8309,ndcg@6:0.8343,group_auc:0.8526\n",
            "[(1, {'auc': 0.6912, 'logloss': 0.8115, 'mean_mrr': 0.6308, 'ndcg@2': 0.5634, 'ndcg@4': 0.6986, 'ndcg@6': 0.7229, 'group_auc': 0.7062}), (2, {'auc': 0.6322, 'logloss': 0.6381, 'mean_mrr': 0.6521, 'ndcg@2': 0.5958, 'ndcg@4': 0.7178, 'ndcg@6': 0.7391, 'group_auc': 0.729}), (3, {'auc': 0.7697, 'logloss': 0.6716, 'mean_mrr': 0.7118, 'ndcg@2': 0.675, 'ndcg@4': 0.7697, 'ndcg@6': 0.7843, 'group_auc': 0.7859}), (4, {'auc': 0.7836, 'logloss': 0.9284, 'mean_mrr': 0.7175, 'ndcg@2': 0.6792, 'ndcg@4': 0.7777, 'ndcg@6': 0.7886, 'group_auc': 0.7915}), (5, {'auc': 0.7876, 'logloss': 0.7179, 'mean_mrr': 0.7221, 'ndcg@2': 0.6862, 'ndcg@4': 0.7814, 'ndcg@6': 0.7921, 'group_auc': 0.7967}), (6, {'auc': 0.813, 'logloss': 0.7126, 'mean_mrr': 0.741, 'ndcg@2': 0.7139, 'ndcg@4': 0.7999, 'ndcg@6': 0.8066, 'group_auc': 0.8183}), (7, {'auc': 0.8191, 'logloss': 0.8465, 'mean_mrr': 0.7415, 'ndcg@2': 0.7144, 'ndcg@4': 0.8007, 'ndcg@6': 0.807, 'group_auc': 0.8193}), (8, {'auc': 0.8435, 'logloss': 0.7396, 'mean_mrr': 0.7673, 'ndcg@2': 0.7483, 'ndcg@4': 0.8224, 'ndcg@6': 0.8264, 'group_auc': 0.8421}), (9, {'auc': 0.8492, 'logloss': 0.7977, 'mean_mrr': 0.7726, 'ndcg@2': 0.7567, 'ndcg@4': 0.8267, 'ndcg@6': 0.8305, 'group_auc': 0.8477}), (10, {'auc': 0.8533, 'logloss': 0.7512, 'mean_mrr': 0.7777, 'ndcg@2': 0.7636, 'ndcg@4': 0.8309, 'ndcg@6': 0.8343, 'group_auc': 0.8526})]\n",
            "best epoch: 10\n",
            "Time cost for training is 317.09 mins\n"
          ]
        }
      ],
      "source": [
        "with Timer() as train_time:\n",
        "    model = model.fit(train_file, valid_file, valid_num_ngs=valid_num_ngs) \n",
        "\n",
        "# valid_num_ngs is the number of negative lines after each positive line in your valid_file \n",
        "# we will evaluate the performance of model on valid_file every epoch\n",
        "print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmm3DPjbiY9N",
        "outputId": "6dbb1a1d-8b36-49b1-ef5e-f4a807dddfde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'auc': 0.851, 'logloss': 0.8249, 'mean_mrr': 0.6315, 'ndcg@2': 0.5702, 'ndcg@4': 0.6789, 'ndcg@6': 0.713, 'group_auc': 0.8495}\n"
          ]
        }
      ],
      "source": [
        "res_syn = model.run_eval(test_file, num_ngs=test_num_ngs)\n",
        "print(res_syn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VB7MBFNkjl5e",
        "outputId": "12b143c9-1d98-4d99-9136-8c779de2d832"
      },
      "outputs": [
        {
          "data": {
            "application/scrapbook.scrap.json+json": {
              "data": {
                "auc": 0.851,
                "group_auc": 0.8495,
                "logloss": 0.8249,
                "mean_mrr": 0.6315,
                "ndcg@2": 0.5702,
                "ndcg@4": 0.6789,
                "ndcg@6": 0.713
              },
              "encoder": "json",
              "name": "res_syn",
              "version": 1
            }
          },
          "metadata": {
            "scrapbook": {
              "data": true,
              "display": false,
              "name": "res_syn"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sb.glue(\"res_syn\", res_syn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h2uxYGfFjpL9"
      },
      "outputs": [],
      "source": [
        "model = model.predict(test_file, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGZ26pt-ujeo",
        "outputId": "5cbe4b07-34e3-4891-c64b-40b2a70a6fa7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:78: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._erase_W = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:81: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._erase_b = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:91: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._reset_W = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:94: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._reset_b = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:104: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._add_W = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:107: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._add_b = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:116: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self.heads = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:120: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._beta = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\sequential\\sum_cells.py:127: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  self._alpha = self.add_variable(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\deeprec\\models\\base_model.py:701: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  curr_hidden_nn_layer = tf.compat.v1.layers.batch_normalization(\n",
            "C:\\Users\\조예은\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs, training=training)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading saved model in resources/model\\sum/best_model\n"
          ]
        }
      ],
      "source": [
        "model_best_trained = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n",
        "path_best_trained = os.path.join(hparams.MODEL_DIR, \"best_model\")\n",
        "print('loading saved model in {0}'.format(path_best_trained))\n",
        "model_best_trained.load_model(path_best_trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKtBHxlGu5-K",
        "outputId": "d398f3b9-bbba-4707-fae1-7c1c817a7e66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'auc': 0.851,\n",
              " 'logloss': 0.8249,\n",
              " 'mean_mrr': 0.6315,\n",
              " 'ndcg@2': 0.5702,\n",
              " 'ndcg@4': 0.6789,\n",
              " 'ndcg@6': 0.713,\n",
              " 'group_auc': 0.8495}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_best_trained.run_eval(test_file, num_ngs=test_num_ngs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH7L5VOQvARx",
        "outputId": "46721757-0218-4a41-8557-fcd7806b0852"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<recommenders.models.deeprec.models.sequential.sum.SUMModel at 0x13706548f10>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_best_trained.predict(test_file, output_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "GRU4REC.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
